{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.getcwd()","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:36:29.484859Z","iopub.execute_input":"2023-02-13T08:36:29.485228Z","iopub.status.idle":"2023-02-13T08:36:29.494850Z","shell.execute_reply.started":"2023-02-13T08:36:29.485196Z","shell.execute_reply":"2023-02-13T08:36:29.493784Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"# src/res50_backbone.py\n\nimport torch.nn as nn\nimport torch\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n                               kernel_size=1, stride=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channel)\n\n        # -----------------------------------------\n\n        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n                               kernel_size=3, stride=stride, bias=False, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channel)\n\n        # -----------------------------------------\n\n        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion,\n                               kernel_size=1, stride=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n\n    def forward(self, x):\n        identity = x\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, blocks_num, num_classes=1000, include_top=True):\n        super(ResNet, self).__init__()\n        self.include_top = include_top\n        self.in_channel = 64\n        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n                               padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channel)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n\n        # 输出层\n        if self.include_top:\n            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n            self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        # 参数初始化\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n\n    def _make_layer(self, block, channel, block_num, stride=1):\n        \"\"\"\n            构建模块\n        \"\"\"\n        downsample = None\n\n        if stride != 1 or self.in_channel != channel * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(channel * block.expansion))\n\n        layers = []\n        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n        self.in_channel = channel * block.expansion\n\n        for _ in range(1, block_num):\n            layers.append(block(self.in_channel, channel))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        # 最终输出\n        if self.include_top:\n            x = self.avgpool(x)\n            x = torch.flatten(x, 1)\n            x = self.fc(x)\n\n        return x\n\n\ndef resnet50(num_classes=1000, include_top=True):\n    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:36:29.496979Z","iopub.execute_input":"2023-02-13T08:36:29.497653Z","iopub.status.idle":"2023-02-13T08:36:30.997261Z","shell.execute_reply.started":"2023-02-13T08:36:29.497615Z","shell.execute_reply":"2023-02-13T08:36:30.996271Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# src/utils.py\n\nfrom math import sqrt\nimport itertools\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.jit.annotations import Tuple, List\nfrom torch import nn, Tensor\nimport numpy as np\n\ndef box_area(boxes):\n    \"\"\"\n    Computes the area of a set of bounding boxes, which are specified by its\n    (x1, y1, x2, y2) coordinates.\n\n    Arguments:\n        boxes (Tensor[N, 4]): boxes for which the area will be computed. They\n            are expected to be in (x1, y1, x2, y2) format\n\n    Returns:\n        area (Tensor[N]): area for each box\n    \"\"\"\n    return (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n\n\ndef calc_iou_tensor(boxes1, boxes2):\n    \"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n\n    Arguments:\n        boxes1 (Tensor[N, 4])\n        boxes2 (Tensor[M, 4])\n\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise\n            IoU values for every element in boxes1 and boxes2\n    \"\"\"\n    area1 = box_area(boxes1)\n    area2 = box_area(boxes2)\n\n    #  When the shapes do not match,\n    #  the shape of the returned output tensor follows the broadcasting rules\n    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # left-top [N,M,2]\n    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # right-bottom [N,M,2]\n\n    wh = (rb - lt).clamp(min=0)  # [N,M,2]\n    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n\n    iou = inter / (area1[:, None] + area2 - inter)\n    return iou\n\n# This function is from https://github.com/kuangliu/pytorch-ssd.\nclass Encoder(object):\n    \"\"\"\n        Inspired by https://github.com/kuangliu/pytorch-src\n        Transform between (bboxes, lables) <-> SSD output\n\n        dboxes: default boxes in size 8732 x 4,\n            encoder: input ltrb format, output xywh format\n            decoder: input xywh format, output ltrb format\n\n        encode:\n            input  : bboxes_in (Tensor nboxes x 4), labels_in (Tensor nboxes)\n            output : bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)\n            criteria : IoU threshold of bboexes\n\n        decode:\n            input  : bboxes_in (Tensor 8732 x 4), scores_in (Tensor 8732 x nitems)\n            output : bboxes_out (Tensor nboxes x 4), labels_out (Tensor nboxes)\n            criteria : IoU threshold of bboexes\n            max_output : maximum number of output bboxes\n    \"\"\"\n    def __init__(self, dboxes):\n        self.dboxes = dboxes(order='ltrb')\n        self.dboxes_xywh = dboxes(order='xywh').unsqueeze(dim=0)\n        self.nboxes = self.dboxes.size(0)  # default boxes的数量\n        self.scale_xy = dboxes.scale_xy\n        self.scale_wh = dboxes.scale_wh\n\n    def encode(self, bboxes_in, labels_in, criteria=0.5):\n        \"\"\"\n        encode:\n            input  : bboxes_in (Tensor nboxes x 4), labels_in (Tensor nboxes)\n            output : bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)\n            criteria : IoU threshold of bboexes\n        \"\"\"\n        # [nboxes, 8732]\n        ious = calc_iou_tensor(bboxes_in, self.dboxes)  # 计算每个GT与default box的iou\n        # [8732,]    每个锚框最可能的类型\n        best_dbox_ious, best_dbox_idx = ious.max(dim=0)  # 寻找每个default box匹配到的最大IoU\n        # [nboxes,]  每个类型对应的最佳锚框\n        best_bbox_ious, best_bbox_idx = ious.max(dim=1)  # 寻找每个GT匹配到的最大IoU\n\n        # 将每个GT匹配到的最佳default box设置为正样本（对应论文中Matching strategy的第一条）\n        # set best ious 2.0\n        best_dbox_ious.index_fill_(0, best_bbox_idx, 2.0)  # dim, index, value\n        # 将相应default box匹配最大IOU的GT索引进行替换\n        idx = torch.arange(0, best_bbox_idx.size(0), dtype=torch.int64)\n        best_dbox_idx[best_bbox_idx[idx]] = idx\n\n        # filter IoU > 0.5\n        # 寻找与GT iou大于0.5的default box,对应论文中Matching strategy的第二条(这里包括了第一条匹配到的信息)\n        masks = best_dbox_ious > criteria\n        # [8732,]\n        labels_out = torch.zeros(self.nboxes, dtype=torch.int64)\n        labels_out[masks] = labels_in[best_dbox_idx[masks]]\n        # 将default box匹配到正样本的位置设置成对应GT的box信息\n        bboxes_out = self.dboxes.clone()\n        bboxes_out[masks, :] = bboxes_in[best_dbox_idx[masks], :]\n\n        # Transform format to xywh format\n        x = 0.5 * (bboxes_out[:, 0] + bboxes_out[:, 2])  # x\n        y = 0.5 * (bboxes_out[:, 1] + bboxes_out[:, 3])  # y\n        w = bboxes_out[:, 2] - bboxes_out[:, 0]  # w\n        h = bboxes_out[:, 3] - bboxes_out[:, 1]  # h\n        bboxes_out[:, 0] = x\n        bboxes_out[:, 1] = y\n        bboxes_out[:, 2] = w\n        bboxes_out[:, 3] = h\n        return bboxes_out, labels_out\n\n    def scale_back_batch(self, bboxes_in, scores_in):\n        \"\"\"\n            将box格式从xywh转换回ltrb, 将预测目标score通过softmax处理\n            Do scale and transform from xywh to ltrb\n            suppose input N x 4 x num_bbox | N x label_num x num_bbox\n\n            bboxes_in: 是网络预测的xywh回归参数\n            scores_in: 是预测的每个default box的各目标概率\n        \"\"\"\n        if bboxes_in.device == torch.device(\"cpu\"):\n            self.dboxes = self.dboxes.cpu()\n            self.dboxes_xywh = self.dboxes_xywh.cpu()\n        else:\n            self.dboxes = self.dboxes.cuda()\n            self.dboxes_xywh = self.dboxes_xywh.cuda()\n\n        # Returns a view of the original tensor with its dimensions permuted.\n        bboxes_in = bboxes_in.permute(0, 2, 1)\n        scores_in = scores_in.permute(0, 2, 1)\n        # print(bboxes_in.is_contiguous())\n\n        bboxes_in[:, :, :2] = self.scale_xy * bboxes_in[:, :, :2]   # 预测的x, y回归参数\n        bboxes_in[:, :, 2:] = self.scale_wh * bboxes_in[:, :, 2:]   # 预测的w, h回归参数\n\n        # 将预测的回归参数叠加到default box上得到最终的预测边界框\n        bboxes_in[:, :, :2] = bboxes_in[:, :, :2] * self.dboxes_xywh[:, :, 2:] + self.dboxes_xywh[:, :, :2]\n        bboxes_in[:, :, 2:] = bboxes_in[:, :, 2:].exp() * self.dboxes_xywh[:, :, 2:]\n\n        # transform format to ltrb\n        l = bboxes_in[:, :, 0] - 0.5 * bboxes_in[:, :, 2]\n        t = bboxes_in[:, :, 1] - 0.5 * bboxes_in[:, :, 3]\n        r = bboxes_in[:, :, 0] + 0.5 * bboxes_in[:, :, 2]\n        b = bboxes_in[:, :, 1] + 0.5 * bboxes_in[:, :, 3]\n\n        bboxes_in[:, :, 0] = l  # xmin\n        bboxes_in[:, :, 1] = t  # ymin\n        bboxes_in[:, :, 2] = r  # xmax\n        bboxes_in[:, :, 3] = b  # ymax\n\n        return bboxes_in, F.softmax(scores_in, dim=-1)\n\n    def decode_batch(self, bboxes_in, scores_in, criteria=0.45, max_output=200):\n        # 将box格式从xywh转换回ltrb（方便后面非极大值抑制时求iou）, 将预测目标score通过softmax处理\n        bboxes, probs = self.scale_back_batch(bboxes_in, scores_in)\n\n        outputs = []\n        # 遍历一个batch中的每张image数据\n        for bbox, prob in zip(bboxes.split(1, 0), probs.split(1, 0)):\n            bbox = bbox.squeeze(0)\n            prob = prob.squeeze(0)\n            outputs.append(self.decode_single_new(bbox, prob, criteria, max_output))\n        return outputs\n\n    def decode_single_new(self, bboxes_in, scores_in, criteria, num_output=200):\n        \"\"\"\n        decode:\n            input  : bboxes_in (Tensor 8732 x 4), scores_in (Tensor 8732 x nitems)\n            output : bboxes_out (Tensor nboxes x 4), labels_out (Tensor nboxes)\n            criteria : IoU threshold of bboexes\n            max_output : maximum number of output bboxes\n        \"\"\"\n        device = bboxes_in.device\n        num_classes = scores_in.shape[-1]\n\n        # 对越界的bbox进行裁剪\n        bboxes_in = bboxes_in.clamp(min=0, max=1)\n\n        # [8732, 4] -> [8732, 21, 4]\n        bboxes_in = bboxes_in.repeat(1, num_classes).reshape(scores_in.shape[0], -1, 4)\n\n        # create labels for each prediction\n        labels = torch.arange(num_classes, device=device)\n        labels = labels.view(1, -1).expand_as(scores_in)\n\n        # remove prediction with the background label\n        # 移除归为背景类别的概率信息\n        bboxes_in = bboxes_in[:, 1:, :]\n        scores_in = scores_in[:, 1:]\n        labels = labels[:, 1:]\n\n        # batch everything, by making every class prediction be a separate instance\n        bboxes_in = bboxes_in.reshape(-1, 4)\n        scores_in = scores_in.reshape(-1)\n        labels = labels.reshape(-1)\n\n        # remove low scoring boxes\n        # 移除低概率目标，self.scores_thresh=0.05\n        inds = torch.nonzero(scores_in > 0.05, as_tuple=False).squeeze(1)\n        bboxes_in, scores_in, labels = bboxes_in[inds], scores_in[inds], labels[inds]\n\n        # remove empty boxes\n        ws, hs = bboxes_in[:, 2] - bboxes_in[:, 0], bboxes_in[:, 3] - bboxes_in[:, 1]\n        keep = (ws >= 0.1 / 300) & (hs >= 0.1 / 300)\n        keep = keep.nonzero(as_tuple=False).squeeze(1)\n        bboxes_in, scores_in, labels = bboxes_in[keep], scores_in[keep], labels[keep]\n\n        # non-maximum suppression\n        keep = batched_nms(bboxes_in, scores_in, labels, iou_threshold=criteria)\n\n        # keep only topk scoring predictions\n        keep = keep[:num_output]\n        bboxes_out = bboxes_in[keep, :]\n        scores_out = scores_in[keep]\n        labels_out = labels[keep]\n\n        return bboxes_out, labels_out, scores_out\n\n    # perform non-maximum suppression\n    def decode_single(self, bboxes_in, scores_in, criteria, max_output, max_num=200):\n        \"\"\"\n        decode:\n            input  : bboxes_in (Tensor 8732 x 4), scores_in (Tensor 8732 x nitems)\n            output : bboxes_out (Tensor nboxes x 4), labels_out (Tensor nboxes)\n            criteria : IoU threshold of bboexes\n            max_output : maximum number of output bboxes\n        \"\"\"\n        # Reference to https://github.com/amdegroot/ssd.pytorch\n        bboxes_out = []\n        scores_out = []\n        labels_out = []\n\n        # 非极大值抑制算法\n        # scores_in (Tensor 8732 x nitems), 遍历返回每一列数据，即8732个目标的同一类别的概率\n        for i, score in enumerate(scores_in.split(1, 1)):\n            # skip background\n            if i == 0:\n                continue\n\n            # [8732, 1] -> [8732]\n            score = score.squeeze(1)\n\n            # 虑除预测概率小于0.05的目标\n            mask = score > 0.05\n            bboxes, score = bboxes_in[mask, :], score[mask]\n            if score.size(0) == 0:\n                continue\n\n            # 按照分数从小到大排序\n            score_sorted, score_idx_sorted = score.sort(dim=0)\n\n            # select max_output indices\n            score_idx_sorted = score_idx_sorted[-max_num:]\n            candidates = []\n\n            while score_idx_sorted.numel() > 0:\n                idx = score_idx_sorted[-1].item()\n                # 获取排名前score_idx_sorted名的bboxes信息 Tensor:[score_idx_sorted, 4]\n                bboxes_sorted = bboxes[score_idx_sorted, :]\n                # 获取排名第一的bboxes信息 Tensor:[4]\n                bboxes_idx = bboxes[idx, :].unsqueeze(dim=0)\n                # 计算前score_idx_sorted名的bboxes与第一名的bboxes的iou\n                iou_sorted = calc_iou_tensor(bboxes_sorted, bboxes_idx).squeeze()\n\n                # we only need iou < criteria\n                # 丢弃与第一名iou > criteria的所有目标(包括自己本身)\n                score_idx_sorted = score_idx_sorted[iou_sorted < criteria]\n                # 保存第一名的索引信息\n                candidates.append(idx)\n\n            # 保存该类别通过非极大值抑制后的目标信息\n            bboxes_out.append(bboxes[candidates, :])   # bbox坐标信息\n            scores_out.append(score[candidates])       # score信息\n            labels_out.extend([i] * len(candidates))   # 标签信息\n\n        if not bboxes_out:  # 如果为空的话，返回空tensor，注意boxes对应的空tensor size，防止验证时出错\n            return [torch.empty(size=(0, 4)), torch.empty(size=(0,), dtype=torch.int64), torch.empty(size=(0,))]\n\n        bboxes_out = torch.cat(bboxes_out, dim=0).contiguous()\n        scores_out = torch.cat(scores_out, dim=0).contiguous()\n        labels_out = torch.as_tensor(labels_out, dtype=torch.long)\n\n        # 对所有目标的概率进行排序（无论是什 么类别）,取前max_num个目标\n        _, max_ids = scores_out.sort(dim=0)\n        max_ids = max_ids[-max_output:]\n        return bboxes_out[max_ids, :], labels_out[max_ids], scores_out[max_ids]\n\n\n# figsize = 300  # 输入网络的图像大小\n# feat_size = [38, 19, 10, 5, 3, 1]   # 每个预测层的feature map尺寸\n# steps = [8, 16, 32, 64, 100, 300]   # 每个特征层上的一个cell在原图上的跨度\n# scales = [21, 45, 99, 153, 207, 261, 315]  # 每个特征层上预测的default box的scale\n# aspect_ratios = [[2], [2, 3], [2, 3], [2, 3], [2], [2]]  # 每个预测特征层上预测的default box的ratios\nclass DefaultBoxes(object):\n    def __init__(self, fig_size, feat_size, steps, scales, aspect_ratios, scale_xy=0.1, scale_wh=0.2):\n        self.fig_size = fig_size   # 输入网络的图像大小 300\n        # [38, 19, 10, 5, 3, 1]\n        self.feat_size = feat_size  # 每个预测层的feature map尺寸\n\n        self.scale_xy_ = scale_xy\n\n        self.scale_wh_ = scale_wh\n\n        # [8, 16, 32, 64, 100, 300]\n        self.steps = steps    # 每个特征层上的一个cell在原图上的跨度\n\n        # [21, 45, 99, 153, 207, 261, 315]\n        self.scales = scales  # 每个特征层上预测的default box的scale\n\n        fk = fig_size / np.array(steps)     # 计算每层特征层的fk\n\n        # [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n        self.aspect_ratios = aspect_ratios  # 每个预测特征层上预测的default box的ratios\n\n        self.default_boxes = []\n        # size of feature and number of feature\n        # 遍历每层特征层，计算default box\n        for idx, sfeat in enumerate(self.feat_size):\n            sk1 = scales[idx] / fig_size  # scale转为相对值[0-1]\n            sk2 = scales[idx + 1] / fig_size  # scale转为相对值[0-1]\n            sk3 = sqrt(sk1 * sk2)\n            # 先添加两个1:1比例的default box宽和高\n            all_sizes = [(sk1, sk1), (sk3, sk3)]\n\n            # 再将剩下不同比例的default box宽和高添加到all_sizes中\n            for alpha in aspect_ratios[idx]:\n                w, h = sk1 * sqrt(alpha), sk1 / sqrt(alpha)\n                all_sizes.append((w, h))\n                all_sizes.append((h, w))\n\n            # 计算当前特征层对应原图上的所有default box\n            for w, h in all_sizes:\n                for i, j in itertools.product(range(sfeat), repeat=2):  # i -> 行（y）， j -> 列（x）\n                    # 计算每个default box的中心坐标（范围是在0-1之间）\n                    cx, cy = (j + 0.5) / fk[idx], (i + 0.5) / fk[idx]\n                    self.default_boxes.append((cx, cy, w, h))\n\n        # 将default_boxes转为tensor格式\n        self.dboxes = torch.as_tensor(self.default_boxes, dtype=torch.float32)  # 这里不转类型会报错\n        self.dboxes.clamp_(min=0, max=1)  # 将坐标（x, y, w, h）都限制在0-1之间\n\n        # For IoU calculation\n        # ltrb is left top coordinate and right bottom coordinate\n        # 将(x, y, w, h)转换成(xmin, ymin, xmax, ymax)，方便后续计算IoU(匹配正负样本时)\n        self.dboxes_ltrb = self.dboxes.clone()\n        self.dboxes_ltrb[:, 0] = self.dboxes[:, 0] - 0.5 * self.dboxes[:, 2]   # xmin\n        self.dboxes_ltrb[:, 1] = self.dboxes[:, 1] - 0.5 * self.dboxes[:, 3]   # ymin\n        self.dboxes_ltrb[:, 2] = self.dboxes[:, 0] + 0.5 * self.dboxes[:, 2]   # xmax\n        self.dboxes_ltrb[:, 3] = self.dboxes[:, 1] + 0.5 * self.dboxes[:, 3]   # ymax\n\n    @property\n    def scale_xy(self):\n        return self.scale_xy_\n\n    @property\n    def scale_wh(self):\n        return self.scale_wh_\n\n    def __call__(self, order='ltrb'):\n        # 根据需求返回对应格式的default box\n        if order == 'ltrb':\n            return self.dboxes_ltrb\n\n        if order == 'xywh':\n            return self.dboxes\n\n\ndef dboxes300_coco():\n    figsize = 300  # 输入网络的图像大小\n    feat_size = [38, 19, 10, 5, 3, 1]   # 每个预测层的feature map尺寸\n    steps = [8, 16, 32, 64, 100, 300]   # 每个特征层上的一个cell在原图上的跨度\n    scales = [21, 45, 99, 153, 207, 261, 315]  # 每个特征层上预测的default box的scale\n    aspect_ratios = [[2], [2, 3], [2, 3], [2, 3], [2], [2]]  # 每个预测特征层上预测的default box的ratios\n    dboxes = DefaultBoxes(figsize, feat_size, steps, scales, aspect_ratios)\n    return dboxes\n\n\ndef nms(boxes, scores, iou_threshold):\n    # type: (Tensor, Tensor, float) -> Tensor\n    \"\"\"\n    Performs non-maximum suppression (NMS) on the boxes according\n    to their intersection-over-union (IoU).\n\n    NMS iteratively removes lower scoring boxes which have an\n    IoU greater than iou_threshold with another (higher scoring)\n    box.\n\n    Parameters\n    ----------\n    boxes : Tensor[N, 4])\n        boxes to perform NMS on. They\n        are expected to be in (x1, y1, x2, y2) format\n    scores : Tensor[N]\n        scores for each one of the boxes\n    iou_threshold : float\n        discards all overlapping\n        boxes with IoU < iou_threshold\n\n    Returns\n    -------\n    keep : Tensor\n        int64 tensor with the indices\n        of the elements that have been kept\n        by NMS, sorted in decreasing order of scores\n    \"\"\"\n    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n\n\ndef batched_nms(boxes, scores, idxs, iou_threshold):\n    # type: (Tensor, Tensor, Tensor, float) -> Tensor\n    \"\"\"\n    Performs non-maximum suppression in a batched fashion.\n\n    Each index value correspond to a category, and NMS\n    will not be applied between elements of different categories.\n\n    Parameters\n    ----------\n    boxes : Tensor[N, 4]\n        boxes where NMS will be performed. They\n        are expected to be in (x1, y1, x2, y2) format\n    scores : Tensor[N]\n        scores for each one of the boxes\n    idxs : Tensor[N]\n        indices of the categories for each one of the boxes.\n    iou_threshold : float\n        discards all overlapping boxes\n        with IoU < iou_threshold\n\n    Returns\n    -------\n    keep : Tensor\n        int64 tensor with the indices of\n        the elements that have been kept by NMS, sorted\n        in decreasing order of scores\n    \"\"\"\n    if boxes.numel() == 0:\n        return torch.empty((0,), dtype=torch.int64, device=boxes.device)\n\n    # strategy: in order to perform NMS independently per class.\n    # we add an offset to all the boxes. The offset is dependent\n    # only on the class idx, and is large enough so that boxes\n    # from different classes do not overlap\n    # 获取所有boxes中最大的坐标值（xmin, ymin, xmax, ymax）\n    max_coordinate = boxes.max()\n\n    # to(): Performs Tensor dtype and/or device conversion\n    # 为每一个类别生成一个很大的偏移量\n    # 这里的to只是让生成tensor的dytpe和device与boxes保持一致\n    offsets = idxs.to(boxes) * (max_coordinate + 1)\n    # boxes加上对应层的偏移量后，保证不同类别之间boxes不会有重合的现象\n    boxes_for_nms = boxes + offsets[:, None]\n    keep = nms(boxes_for_nms, scores, iou_threshold)\n    return keep\n\n\nclass PostProcess(nn.Module):\n    def __init__(self, dboxes):\n        super(PostProcess, self).__init__()\n        # [num_anchors, 4] -> [1, num_anchors, 4]\n        self.dboxes_xywh = nn.Parameter(dboxes(order='xywh').unsqueeze(dim=0),\n                                        requires_grad=False)\n        self.scale_xy = dboxes.scale_xy  # 0.1\n        self.scale_wh = dboxes.scale_wh  # 0.2\n\n        self.criteria = 0.5\n        self.max_output = 100\n\n    def scale_back_batch(self, bboxes_in, scores_in):\n        # type: (Tensor, Tensor) -> Tuple[Tensor, Tensor]\n        \"\"\"\n            1）通过预测的boxes回归参数得到最终预测坐标\n            2）将box格式从xywh转换回ltrb\n            3）将预测目标score通过softmax处理\n            Do scale and transform from xywh to ltrb\n            suppose input N x 4 x num_bbox | N x label_num x num_bbox\n\n            bboxes_in: [N, 4, 8732]是网络预测的xywh回归参数\n            scores_in: [N, label_num, 8732]是预测的每个default box的各目标概率\n        \"\"\"\n\n        # Returns a view of the original tensor with its dimensions permuted.\n        # [batch, 4, 8732] -> [batch, 8732, 4]\n        bboxes_in = bboxes_in.permute(0, 2, 1)\n        # [batch, label_num, 8732] -> [batch, 8732, label_num]\n        scores_in = scores_in.permute(0, 2, 1)\n        # print(bboxes_in.is_contiguous())\n\n        bboxes_in[:, :, :2] = self.scale_xy * bboxes_in[:, :, :2]   # 预测的x, y回归参数\n        bboxes_in[:, :, 2:] = self.scale_wh * bboxes_in[:, :, 2:]   # 预测的w, h回归参数\n\n        # 将预测的回归参数叠加到default box上得到最终的预测边界框\n        bboxes_in[:, :, :2] = bboxes_in[:, :, :2] * self.dboxes_xywh[:, :, 2:] + self.dboxes_xywh[:, :, :2]\n        bboxes_in[:, :, 2:] = bboxes_in[:, :, 2:].exp() * self.dboxes_xywh[:, :, 2:]\n\n        # transform format to ltrb\n        l = bboxes_in[:, :, 0] - 0.5 * bboxes_in[:, :, 2]\n        t = bboxes_in[:, :, 1] - 0.5 * bboxes_in[:, :, 3]\n        r = bboxes_in[:, :, 0] + 0.5 * bboxes_in[:, :, 2]\n        b = bboxes_in[:, :, 1] + 0.5 * bboxes_in[:, :, 3]\n\n        bboxes_in[:, :, 0] = l  # xmin\n        bboxes_in[:, :, 1] = t  # ymin\n        bboxes_in[:, :, 2] = r  # xmax\n        bboxes_in[:, :, 3] = b  # ymax\n\n        # scores_in: [batch, 8732, label_num]\n        return bboxes_in, F.softmax(scores_in, dim=-1)\n\n    def decode_single_new(self, bboxes_in, scores_in, criteria, num_output):\n        # type: (Tensor, Tensor, float, int) -> Tuple[Tensor, Tensor, Tensor]\n        \"\"\"\n        decode:\n            input  : bboxes_in (Tensor 8732 x 4), scores_in (Tensor 8732 x nitems)\n            output : bboxes_out (Tensor nboxes x 4), labels_out (Tensor nboxes)\n            criteria : IoU threshold of bboexes\n            max_output : maximum number of output bboxes\n        \"\"\"\n        device = bboxes_in.device\n        num_classes = scores_in.shape[-1]\n\n        # 对越界的bbox进行裁剪\n        bboxes_in = bboxes_in.clamp(min=0, max=1)\n\n        # [8732, 4] -> [8732, 21, 4]\n        bboxes_in = bboxes_in.repeat(1, num_classes).reshape(scores_in.shape[0], -1, 4)\n\n        # create labels for each prediction\n        labels = torch.arange(num_classes, device=device)\n        # [num_classes] -> [8732, num_classes]\n        labels = labels.view(1, -1).expand_as(scores_in)\n\n        # remove prediction with the background label\n        # 移除归为背景类别的概率信息\n        bboxes_in = bboxes_in[:, 1:, :]  # [8732, 21, 4] -> [8732, 20, 4]\n        scores_in = scores_in[:, 1:]  # [8732, 21] -> [8732, 20]\n        labels = labels[:, 1:]  # [8732, 21] -> [8732, 20]\n\n        # batch everything, by making every class prediction be a separate instance\n        bboxes_in = bboxes_in.reshape(-1, 4)  # [8732, 20, 4] -> [8732x20, 4]\n        scores_in = scores_in.reshape(-1)  # [8732, 20] -> [8732x20]\n        labels = labels.reshape(-1)  # [8732, 20] -> [8732x20]\n\n        # remove low scoring boxes\n        # 移除低概率目标，self.scores_thresh=0.05\n        # inds = torch.nonzero(scores_in > 0.05).squeeze(1)\n        inds = torch.where(torch.gt(scores_in, 0.05))[0]\n        bboxes_in, scores_in, labels = bboxes_in[inds, :], scores_in[inds], labels[inds]\n\n        # remove empty boxes\n        ws, hs = bboxes_in[:, 2] - bboxes_in[:, 0], bboxes_in[:, 3] - bboxes_in[:, 1]\n        keep = (ws >= 1 / 300) & (hs >= 1 / 300)\n        # keep = keep.nonzero().squeeze(1)\n        keep = torch.where(keep)[0]\n        bboxes_in, scores_in, labels = bboxes_in[keep], scores_in[keep], labels[keep]\n\n        # non-maximum suppression\n        keep = batched_nms(bboxes_in, scores_in, labels, iou_threshold=criteria)\n\n        # keep only topk scoring predictions\n        keep = keep[:num_output]\n        bboxes_out = bboxes_in[keep, :]\n        scores_out = scores_in[keep]\n        labels_out = labels[keep]\n\n        return bboxes_out, labels_out, scores_out\n\n    def forward(self, bboxes_in, scores_in):\n        # 通过预测的boxes回归参数得到最终预测坐标, 将预测目标score通过softmax处理\n        bboxes, probs = self.scale_back_batch(bboxes_in, scores_in)\n\n        outputs = torch.jit.annotate(List[Tuple[Tensor, Tensor, Tensor]], [])\n        # 遍历一个batch中的每张image数据\n        # bboxes: [batch, 8732, 4]\n        for bbox, prob in zip(bboxes.split(1, 0), probs.split(1, 0)):  # split_size, split_dim\n            # bbox: [1, 8732, 4]\n            bbox = bbox.squeeze(0)\n            prob = prob.squeeze(0)\n            outputs.append(self.decode_single_new(bbox, prob, self.criteria, self.max_output))\n        return outputs","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-02-13T08:36:30.999722Z","iopub.execute_input":"2023-02-13T08:36:31.000103Z","iopub.status.idle":"2023-02-13T08:36:31.080407Z","shell.execute_reply.started":"2023-02-13T08:36:31.000047Z","shell.execute_reply":"2023-02-13T08:36:31.079327Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# src/ssd_model.py\n\nimport torch\nfrom torch import nn, Tensor\nfrom torch.jit.annotations import List\n\n# from .res50_backbone import resnet50\n# from .utils import dboxes300_coco, Encoder, PostProcess\n\n\nclass Backbone(nn.Module):\n    \"\"\"\n        定义一个backbone\n    \"\"\"\n\n    def __init__(self, pretrain_path=None):\n        super(Backbone, self).__init__()\n\n        # 定义一个resnet50\n        net = resnet50()\n\n        # 后续的通道数\n        self.out_channels = [1024, 512, 512, 256, 256, 256]\n\n        # 加载预训练模型\n        if pretrain_path is not None:\n            net.load_state_dict(torch.load(pretrain_path))\n\n        # 截取特征提出部分\n        self.feature_extractor = nn.Sequential(*list(net.children())[:7])\n\n        # 修改其中的属性\n        conv4_block1 = self.feature_extractor[-1][0]\n        # 修改conv4_block1的stride，从2->1\n        conv4_block1.conv1.stride = (1, 1)\n        conv4_block1.conv2.stride = (1, 1)\n        conv4_block1.downsample[0].stride = (1, 1)\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        return x\n\n\n# 主模型\nclass SSD300(nn.Module):\n    \"\"\"\n        SSD300主模型\n    \"\"\"\n\n    def __init__(self, backbone=None, num_classes=21):\n        \"\"\"\n            设置分类的数量\n\n        \"\"\"\n        super(SSD300, self).__init__()\n\n        # 参数校验\n        if backbone is None:\n            raise Exception(\"backbone is None\")\n\n        if not hasattr(backbone, \"out_channels\"):\n            raise Exception(\"the backbone not has attribute: out_channel\")\n\n        self.feature_extractor = backbone\n\n        self.num_classes = num_classes\n\n        # 构建自定义的特征层\n        # out_channels = [1024, 512, 512, 256, 256, 256] for resnet50\n        self._build_additional_features(self.feature_extractor.out_channels)\n\n        # 每个特征层上每个特征点对应的锚框数量\n        self.num_defaults = [4, 6, 6, 6, 4, 4]\n\n        location_extractors = []\n        confidence_extractors = []\n\n        # out_channels = [1024, 512, 512, 256, 256, 256] for resnet50\n        for nd, oc in zip(self.num_defaults, self.feature_extractor.out_channels):\n            # nd is number_default_boxes, oc is output_channel\n            location_extractors.append(nn.Conv2d(oc, nd * 4, kernel_size=3, padding=1))\n            confidence_extractors.append(nn.Conv2d(oc, nd * self.num_classes, kernel_size=3, padding=1))\n\n        self.loc = nn.ModuleList(location_extractors)\n        self.conf = nn.ModuleList(confidence_extractors)\n        self._init_weights()\n\n        # 模型锚框的生成策略\n        default_box = dboxes300_coco()\n\n        # 下面三个是核心\n        self.compute_loss = Loss(default_box)\n        self.encoder = Encoder(default_box)\n        self.postprocess = PostProcess(default_box)\n\n    def _build_additional_features(self, input_size):\n        \"\"\"\n        为backbone(resnet50)添加额外的一系列卷积层，得到相应的一系列特征提取器\n        :param input_size:\n        :return:\n        \"\"\"\n        additional_blocks = []\n        # input_size = [1024, 512, 512, 256, 256, 256] for resnet50\n        # input_size[:-1]： [1024, 512, 512, 256, 256]\n        # middle_channels： [256,  256, 128, 128, 128]\n        # input_size[1:]：  [512,  512, 256, 256, 256]\n        middle_channels = [256, 256, 128, 128, 128]\n        for i, (input_ch, output_ch, middle_ch) in enumerate(zip(input_size[:-1], input_size[1:], middle_channels)):\n            padding, stride = (1, 2) if i < 3 else (0, 1)\n            layer = nn.Sequential(\n                nn.Conv2d(input_ch, middle_ch, kernel_size=1, bias=False),\n                nn.BatchNorm2d(middle_ch),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(middle_ch, output_ch, kernel_size=3, padding=padding, stride=stride, bias=False),\n                nn.BatchNorm2d(output_ch),\n                nn.ReLU(inplace=True),\n            )\n            additional_blocks.append(layer)\n        self.additional_blocks = nn.ModuleList(additional_blocks)\n\n    def _init_weights(self):\n        \"\"\"\n            要不要自己去初始化权重？？？\n        \"\"\"\n        layers = [*self.additional_blocks, *self.loc, *self.conf]\n        for layer in layers:\n            for param in layer.parameters():\n                if param.dim() > 1:\n                    nn.init.xavier_uniform_(param)\n\n    # Shape the classifier to the view of bboxes\n    def bbox_view(self, features, loc_extractor, conf_extractor):\n        locs = []\n        confs = []\n        for f, l, c in zip(features, loc_extractor, conf_extractor):\n            # [batch, n*4, feat_size, feat_size] -> [batch, 4, -1]\n            locs.append(l(f).view(f.size(0), 4, -1))\n            # [batch, n*classes, feat_size, feat_size] -> [batch, classes, -1]\n            confs.append(c(f).view(f.size(0), self.num_classes, -1))\n\n        locs, confs = torch.cat(locs, 2).contiguous(), torch.cat(confs, 2).contiguous()\n        return locs, confs\n\n    def forward(self, image, targets=None):\n\n        x = self.feature_extractor(image)\n\n        # Feature Map 38x38x1024, 19x19x512, 10x10x512, 5x5x256, 3x3x256, 1x1x256\n        detection_features = torch.jit.annotate(List[Tensor], [])  # [x]\n\n        detection_features.append(x)\n\n        for layer in self.additional_blocks:\n            x = layer(x)\n            detection_features.append(x)\n\n        # Feature Map 38x38x4, 19x19x6, 10x10x6, 5x5x6, 3x3x4, 1x1x4\n        locs, confs = self.bbox_view(detection_features, self.loc, self.conf)\n\n        # For SSD 300, shall return nbatch x 8732 x {nlabels, nlocs} results\n        # 38x38x4 + 19x19x6 + 10x10x6 + 5x5x6 + 3x3x4 + 1x1x4 = 8732\n\n        if self.training:\n            if targets is None:\n                raise ValueError(\"In training mode, targets should be passed\")\n            # bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)\n            bboxes_out = targets['boxes']\n            bboxes_out = bboxes_out.transpose(1, 2).contiguous()\n            # print(bboxes_out.is_contiguous())\n            labels_out = targets['labels']\n            # print(labels_out.is_contiguous())\n\n            # ploc, plabel, gloc, glabel\n            loss = self.compute_loss(locs, confs, bboxes_out, labels_out)\n            return {\"total_losses\": loss}\n\n        # 将预测回归参数叠加到default box上得到最终预测box，并执行非极大值抑制虑除重叠框\n        # results = self.encoder.decode_batch(locs, confs)\n        results = self.postprocess(locs, confs)\n        return results\n\n\nclass Loss(nn.Module):\n    \"\"\"\n        Implements the loss as the sum of the followings:\n        1. Confidence Loss: All labels, with hard negative mining\n        2. Localization Loss: Only on positive labels\n        Suppose input dboxes has the shape 8732x4\n    \"\"\"\n\n    def __init__(self, dboxes):\n        super(Loss, self).__init__()\n        # Two factor are from following links\n        # http://jany.st/post/2017-11-05-single-shot-detector-ssd-from-scratch-in-tensorflow.html\n        self.scale_xy = 1.0 / dboxes.scale_xy  # 10\n        self.scale_wh = 1.0 / dboxes.scale_wh  # 5\n\n        self.location_loss = nn.SmoothL1Loss(reduction='none')\n        # [num_anchors, 4] -> [4, num_anchors] -> [1, 4, num_anchors]\n        self.dboxes = nn.Parameter(dboxes(order=\"xywh\").transpose(0, 1).unsqueeze(dim=0),\n                                   requires_grad=False)\n\n        self.confidence_loss = nn.CrossEntropyLoss(reduction='none')\n\n    def _location_vec(self, loc):\n        # type: (Tensor) -> Tensor\n        \"\"\"\n        Generate Location Vectors\n        计算ground truth相对anchors的回归参数\n        :param loc: anchor匹配到的对应GTBOX Nx4x8732\n        :return:\n        \"\"\"\n        gxy = self.scale_xy * (loc[:, :2, :] - self.dboxes[:, :2, :]) / self.dboxes[:, 2:, :]  # Nx2x8732\n        gwh = self.scale_wh * (loc[:, 2:, :] / self.dboxes[:, 2:, :]).log()  # Nx2x8732\n        return torch.cat((gxy, gwh), dim=1).contiguous()\n\n    def forward(self, ploc, plabel, gloc, glabel):\n        # type: (Tensor, Tensor, Tensor, Tensor) -> Tensor\n        \"\"\"\n            ploc, plabel: Nx4x8732, Nxlabel_numx8732\n                predicted location and labels\n\n            gloc, glabel: Nx4x8732, Nx8732\n                ground truth location and labels\n        \"\"\"\n        # 获取正样本的mask  Tensor: [N, 8732]\n        mask = torch.gt(glabel, 0)  # (gt: >)\n        # mask1 = torch.nonzero(glabel)\n        # 计算一个batch中的每张图片的正样本个数 Tensor: [N]\n        pos_num = mask.sum(dim=1)\n\n        # 计算gt的location回归参数 Tensor: [N, 4, 8732]\n        vec_gd = self._location_vec(gloc)\n\n        # sum on four coordinates, and mask\n        # 计算定位损失(只有正样本)\n        loc_loss = self.location_loss(ploc, vec_gd).sum(dim=1)  # Tensor: [N, 8732]\n        loc_loss = (mask.float() * loc_loss).sum(dim=1)  # Tenosr: [N]\n\n        # hard negative mining Tenosr: [N, 8732]\n        con = self.confidence_loss(plabel, glabel)\n\n        # positive mask will never selected\n        # 获取负样本\n        con_neg = con.clone()\n        con_neg[mask] = 0.0\n        # 按照confidence_loss降序排列 con_idx(Tensor: [N, 8732])\n        _, con_idx = con_neg.sort(dim=1, descending=True)\n        # 第一次降序sort，置信度越高者，排在越前面,\n        # 第二次对con_idx做升序排列，则排序结果又恢复为con_neg中的原有排序顺序，而每个位置对应在con_rank的值，\n        # 记录的是其在con_idx的排序顺序，也就是元素序列值越小，confidence值越大，这样就可以直接mask con_neg，\n        # 获取指定位置的元素, 比如：\n        # >>> mask = torch.as_tensor([[True, False, False, True], [True, False, False, False]])\n        # >>> mask\n        # tensor([[True, False, False, True],\n        #         [True, False, False, False]])\n        # >>> con[mask]\n        # tensor([0.2000, 0.3400, 0.5000])\n        # >>> con_neg = con.clone()\n        # >>> con_neg\n        # tensor([[0.2000, 0.3000, 0.1200, 0.3400],\n        #         [0.5000, 0.2000, 0.6000, 0.7000]])\n        # >>> con_neg = con[mask]\n        # >>> con_neg\n        # tensor([0.2000, 0.3400, 0.5000])\n        # >>> con_neg = con.clone()\n        # >>> con_neg\n        # tensor([[0.2000, 0.3000, 0.1200, 0.3400],\n        #         [0.5000, 0.2000, 0.6000, 0.7000]])\n        # >>> con_neg[mask] = 0\n        # >>> con_neg\n        # tensor([[0.0000, 0.3000, 0.1200, 0.0000],\n        #         [0.0000, 0.2000, 0.6000, 0.7000]])\n        # >>> _, con_idx = torch.sort(con_neg, descending=True)\n        # >>> _\n        # tensor([[0.3000, 0.1200, 0.0000, 0.0000],\n        #         [0.7000, 0.6000, 0.2000, 0.0000]])\n        # >>> con_idx\n        # tensor([[1, 2, 0, 3],\n        #         [3, 2, 1, 0]])\n        # >>> _, con_rank = torch.sort(con_idx)\n        # >>> _\n        # tensor([[0, 1, 2, 3],\n        #         [0, 1, 2, 3]])\n        # >>> con_rank\n        # tensor([[2, 0, 1, 3],\n        #         [3, 2, 1, 0]])\n        # >>> con * torch.lt(con_rank, 2)\n        # tensor([[0.0000, 0.3000, 0.1200, 0.0000],\n        #         [0.0000, 0.0000, 0.6000, 0.7000]])\n        _, con_rank = con_idx.sort(dim=1)  # 这个步骤比较巧妙\n\n        # number of negative three times positive\n        # 用于损失计算的负样本数是正样本的3倍（在原论文Hard negative mining部分），\n        # 但不能超过总样本数8732\n        neg_num = torch.clamp(3 * pos_num, max=mask.size(1)).unsqueeze(-1)\n        neg_mask = torch.lt(con_rank, neg_num)  # (lt: <) Tensor [N, 8732]\n\n        # confidence最终loss使用选取的正样本loss+选取的负样本loss\n        con_loss = (con * (mask.float() + neg_mask.float())).sum(dim=1)  # Tensor [N]\n\n        # avoid no object detected\n        # 避免出现图像中没有GTBOX的情况\n        total_loss = loc_loss + con_loss\n        # eg. [15, 3, 5, 0] -> [1.0, 1.0, 1.0, 0.0]\n        num_mask = torch.gt(pos_num, 0).float()  # 统计一个batch中的每张图像中是否存在正样本\n        pos_num = pos_num.float().clamp(min=1e-6)  # 防止出现分母为零的情况\n        ret = (total_loss * num_mask / pos_num).mean(dim=0)  # 只计算存在正样本的图像损失\n        return ret","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:36:31.083735Z","iopub.execute_input":"2023-02-13T08:36:31.084084Z","iopub.status.idle":"2023-02-13T08:36:31.119686Z","shell.execute_reply.started":"2023-02-13T08:36:31.084056Z","shell.execute_reply":"2023-02-13T08:36:31.118622Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# train_utils/distributed_utils.py\n\nfrom collections import defaultdict, deque\nimport datetime\nimport pickle\nimport time\nimport errno\nimport os\n\nimport torch\nimport torch.distributed as dist\n\n\nclass SmoothedValue(object):\n    \"\"\"Track a series of values and provide access to smoothed values over a\n    window or the global series average.\n    \"\"\"\n    def __init__(self, window_size=20, fmt=None):\n        if fmt is None:\n            fmt = \"{value:.4f} ({global_avg:.4f}) hist: {all_hist_data}\"\n        self.deque = deque(maxlen=window_size)  # deque简单理解成加强版list\n        self.total = 0.0\n        self.count = 0\n        self.fmt = fmt\n\n    def update(self, value, n=1):\n        self.deque.append(value)\n        self.count += n\n        self.total += value * n\n\n    def synchronize_between_processes(self):\n        \"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"\n        if not is_dist_avail_and_initialized():\n            return\n        t = torch.tensor([self.count, self.total], dtype=torch.float64, device=\"cuda\")\n        dist.barrier()\n        dist.all_reduce(t)\n        t = t.tolist()\n        self.count = int(t[0])\n        self.total = t[1]\n\n    @property\n    def median(self):  # @property 是装饰器，这里可简单理解为增加median属性(只读)\n        d = torch.tensor(list(self.deque))\n        return d.median().item()\n\n    @property\n    def avg(self):\n        d = torch.tensor(list(self.deque), dtype=torch.float32)\n        return d.mean().item()\n\n    @property\n    def global_avg(self):\n        return self.total / self.count\n\n    @property\n    def max(self):\n        return max(self.deque)\n\n    @property\n    def value(self):\n        return self.deque[-1]\n\n    @property\n    def all_hist_data(self):\n        delimiter = \" \"\n        hist_data = []\n        for data in self.deque:\n            hist_data.append(\"{:.2f}\".format(data))\n\n        return \"[\" + delimiter.join(hist_data) + \"]\"\n\n    def __str__(self):\n        return self.fmt.format(\n            median=self.median,\n            avg=self.avg,\n            global_avg=self.global_avg,\n            max=self.max,\n            value=self.value,\n            all_hist_data=self.all_hist_data)\n\n\ndef all_gather(data):\n    \"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"\n    world_size = get_world_size()\n    if world_size == 1:\n        return [data]\n\n    # serialized to a Tensor\n    buffer = pickle.dumps(data)\n    storage = torch.ByteStorage.from_buffer(buffer)\n    tensor = torch.ByteTensor(storage).to(\"cuda\")\n\n    # obtain Tensor size of each rank\n    local_size = torch.tensor([tensor.numel()], device=\"cuda\")\n    size_list = [torch.tensor([0], device=\"cuda\") for _ in range(world_size)]\n    dist.all_gather(size_list, local_size)\n    size_list = [int(size.item()) for size in size_list]\n    max_size = max(size_list)\n\n    # receiving Tensor from all ranks\n    # we pad the tensor because torch all_gather does not support\n    # gathering tensors of different shapes\n    tensor_list = []\n    for _ in size_list:\n        tensor_list.append(torch.empty((max_size,), dtype=torch.uint8, device=\"cuda\"))\n    if local_size != max_size:\n        padding = torch.empty(size=(max_size - local_size,), dtype=torch.uint8, device=\"cuda\")\n        tensor = torch.cat((tensor, padding), dim=0)\n    dist.all_gather(tensor_list, tensor)\n\n    data_list = []\n    for size, tensor in zip(size_list, tensor_list):\n        buffer = tensor.cpu().numpy().tobytes()[:size]\n        data_list.append(pickle.loads(buffer))\n\n    return data_list\n\n\ndef reduce_dict(input_dict, average=True):\n    \"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that all processes\n    have the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"\n    world_size = get_world_size()\n    if world_size < 2:  # 单GPU的情况\n        return input_dict\n    with torch.no_grad():  # 多GPU的情况\n        names = []\n        values = []\n        # sort the keys so that they are consistent across processes\n        for k in sorted(input_dict.keys()):\n            names.append(k)\n            values.append(input_dict[k])\n        values = torch.stack(values, dim=0)\n        dist.all_reduce(values)\n        if average:\n            values /= world_size\n\n        reduced_dict = {k: v for k, v in zip(names, values)}\n        return reduced_dict\n\n\nclass MetricLogger(object):\n    def __init__(self, delimiter=\"\\t\"):\n        self.meters = defaultdict(SmoothedValue)\n        self.delimiter = delimiter\n\n    def update(self, **kwargs):\n        for k, v in kwargs.items():\n            if isinstance(v, torch.Tensor):\n                v = v.item()\n            assert isinstance(v, (float, int))\n            self.meters[k].update(v)\n\n    def __getattr__(self, attr):\n        if attr in self.meters:\n            return self.meters[attr]\n        if attr in self.__dict__:\n            return self.__dict__[attr]\n        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n            type(self).__name__, attr))\n\n    def __str__(self):\n        loss_str = []\n        for name, meter in self.meters.items():\n            loss_str.append(\n                \"{}: {}\".format(name, str(meter))\n            )\n        return self.delimiter.join(loss_str)\n\n    def synchronize_between_processes(self):\n        for meter in self.meters.values():\n            meter.synchronize_between_processes()\n\n    def add_meter(self, name, meter):\n        self.meters[name] = meter\n\n    def log_every(self, iterable, print_freq, header=None):\n        i = 0\n        if not header:\n            header = \"\"\n        start_time = time.time()\n        end = time.time()\n        iter_time = SmoothedValue(fmt='{avg:.4f}')\n        data_time = SmoothedValue(fmt='{avg:.4f}')\n        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n        if torch.cuda.is_available():\n            log_msg = self.delimiter.join([header,\n                                           '[{0' + space_fmt + '}/{1}]',\n                                           'eta: {eta}',\n                                           '{meters}',\n                                           'time: {time}',\n                                           'data: {data}',\n                                           'max mem: {memory:.0f}'])\n        else:\n            log_msg = self.delimiter.join([header,\n                                           '[{0' + space_fmt + '}/{1}]',\n                                           'eta: {eta}',\n                                           '{meters}',\n                                           'time: {time}',\n                                           'data: {data}'])\n        MB = 1024.0 * 1024.0\n        for obj in iterable:\n            data_time.update(time.time() - end)\n            yield obj\n            iter_time.update(time.time() - end)\n            if i % print_freq == 0 or i == len(iterable) - 1:\n                eta_second = iter_time.global_avg * (len(iterable) - i)\n                eta_string = str(datetime.timedelta(seconds=eta_second))\n                if torch.cuda.is_available():\n                    print(log_msg.format(i, len(iterable),\n                                         eta=eta_string,\n                                         meters=str(self),\n                                         time=str(iter_time),\n                                         data=str(data_time),\n                                         memory=torch.cuda.max_memory_allocated() / MB))\n                else:\n                    print(log_msg.format(i, len(iterable),\n                                         eta=eta_string,\n                                         meters=str(self),\n                                         time=str(iter_time),\n                                         data=str(data_time)))\n            i += 1\n            end = time.time()\n        total_time = time.time() - start_time\n        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n        print('{} Total time: {} ({:.4f} s / it)'.format(header,\n                                                         total_time_str,\n\n                                                         total_time / len(iterable)))\n\n\ndef warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n\n    def f(x):\n        \"\"\"根据step数返回一个学习率倍率因子\"\"\"\n        if x >= warmup_iters:  # 当迭代数大于给定的warmup_iters时，倍率因子为1\n            return 1\n        alpha = float(x) / warmup_iters\n        # 迭代过程中倍率因子从warmup_factor -> 1\n        return warmup_factor * (1 - alpha) + alpha\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=f)\n\n\ndef mkdir(path):\n    try:\n        os.makedirs(path)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n\ndef setup_for_distributed(is_master):\n    \"\"\"\n    This function disables when not in master process\n    \"\"\"\n    import builtins as __builtin__\n    builtin_print = __builtin__.print\n\n    def print(*args, **kwargs):\n        force = kwargs.pop('force', False)\n        if is_master or force:\n            builtin_print(*args, **kwargs)\n\n    __builtin__.print = print\n\n\ndef is_dist_avail_and_initialized():\n    \"\"\"检查是否支持分布式环境\"\"\"\n    if not dist.is_available():\n        return False\n    if not dist.is_initialized():\n        return False\n    return True\n\n\ndef get_world_size():\n    if not is_dist_avail_and_initialized():\n        return 1\n    return dist.get_world_size()\n\n\ndef get_rank():\n    if not is_dist_avail_and_initialized():\n        return 0\n    return dist.get_rank()\n\n\ndef is_main_process():\n    return get_rank() == 0\n\n\ndef save_on_master(*args, **kwargs):\n    if is_main_process():\n        torch.save(*args, **kwargs)\n\n\ndef init_distributed_mode(args):\n    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n        args.rank = int(os.environ[\"RANK\"])\n        args.world_size = int(os.environ['WORLD_SIZE'])\n        args.gpu = int(os.environ['LOCAL_RANK'])\n    elif 'SLURM_PROCID' in os.environ:\n        args.rank = int(os.environ['SLURM_PROCID'])\n        args.gpu = args.rank % torch.cuda.device_count()\n    else:\n        print('Not using distributed mode')\n        args.distributed = False\n        return\n\n    args.distributed = True\n\n    torch.cuda.set_device(args.gpu)\n    args.dist_backend = 'nccl'\n    print('| distributed init (rank {}): {}'.format(\n        args.rank, args.dist_url), flush=True)\n    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                         world_size=args.world_size, rank=args.rank)\n    torch.distributed.barrier()\n    setup_for_distributed(args.rank == 0)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:36:31.122834Z","iopub.execute_input":"2023-02-13T08:36:31.123684Z","iopub.status.idle":"2023-02-13T08:36:31.167909Z","shell.execute_reply.started":"2023-02-13T08:36:31.123643Z","shell.execute_reply":"2023-02-13T08:36:31.166697Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install pycocotools","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-13T08:36:31.170533Z","iopub.execute_input":"2023-02-13T08:36:31.171203Z","iopub.status.idle":"2023-02-13T08:37:10.368504Z","shell.execute_reply.started":"2023-02-13T08:36:31.171154Z","shell.execute_reply":"2023-02-13T08:37:10.367254Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pycocotools) (1.21.6)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.5.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (23.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (9.1.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (4.33.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.15.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp37-cp37m-linux_x86_64.whl size=373765 sha256=4b11284a0055ae1e9d7e65f8c56b16f9d195da54bf6f0fd5b76fb6be0cbd70f5\n  Stored in directory: /root/.cache/pip/wheels/06/f6/f9/9cc49c6de8e3cf27dfddd91bf46595a057141d4583a2adaf03\nSuccessfully built pycocotools\nInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# train_utils/coco_eval.py\nimport json\nimport copy\nfrom collections import defaultdict\n\nimport numpy as np\nimport torch\nimport torch._six\n\nfrom pycocotools.cocoeval import COCOeval\nfrom pycocotools.coco import COCO\nimport pycocotools.mask as mask_util\n\n# from train_utils.distributed_utils import all_gather\n\n\nclass CocoEvaluator(object):\n    def __init__(self, coco_gt, iou_types):\n        assert isinstance(iou_types, (list, tuple))\n        coco_gt = copy.deepcopy(coco_gt)\n        self.coco_gt = coco_gt\n\n        self.iou_types = iou_types\n        self.coco_eval = {}\n        for iou_type in iou_types:\n            self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)\n\n        self.img_ids = []\n        self.eval_imgs = {k: [] for k in iou_types}\n\n    def update(self, predictions):\n        img_ids = list(np.unique(list(predictions.keys())))\n        self.img_ids.extend(img_ids)\n\n        for iou_type in self.iou_types:\n            results = self.prepare(predictions, iou_type)\n            coco_dt = loadRes(self.coco_gt, results) if results else COCO()\n            coco_eval = self.coco_eval[iou_type]\n\n            coco_eval.cocoDt = coco_dt\n            coco_eval.params.imgIds = list(img_ids)\n            img_ids, eval_imgs = evaluate_inner(coco_eval)\n\n            self.eval_imgs[iou_type].append(eval_imgs)\n\n    def synchronize_between_processes(self):\n        for iou_type in self.iou_types:\n            self.eval_imgs[iou_type] = np.concatenate(self.eval_imgs[iou_type], 2)\n            create_common_coco_eval(self.coco_eval[iou_type], self.img_ids, self.eval_imgs[iou_type])\n\n    def accumulate(self):\n        for coco_eval in self.coco_eval.values():\n            coco_eval.accumulate()\n\n    def summarize(self):\n        for iou_type, coco_eval in self.coco_eval.items():\n            print(\"IoU metric: {}\".format(iou_type))\n            coco_eval.summarize()\n\n    def prepare(self, predictions, iou_type):\n        if iou_type == \"bbox\":\n            return self.prepare_for_coco_detection(predictions)\n        elif iou_type == \"segm\":\n            return self.prepare_for_coco_segmentation(predictions)\n        elif iou_type == \"keypoints\":\n            return self.prepare_for_coco_keypoint(predictions)\n        else:\n            raise ValueError(\"Unknown iou type {}\".format(iou_type))\n\n    def prepare_for_coco_detection(self, predictions):\n        coco_results = []\n        for original_id, prediction in predictions.items():\n            if len(prediction) == 0:\n                continue\n\n            # xmin, ymin, xmax, ymax\n            boxes = prediction[\"boxes\"]\n            boxes = convert_to_xywh(boxes)\n            boxes = boxes.tolist()\n            scores = prediction[\"scores\"].tolist()\n            labels = prediction[\"labels\"].tolist()\n\n            coco_results.extend(\n                [\n                    {\n                        \"image_id\": original_id,\n                        \"category_id\": labels[k],\n                        \"bbox\": box,\n                        \"score\": scores[k],\n                    }\n                    for k, box in enumerate(boxes)\n                ]\n            )\n        return coco_results\n\n    def prepare_for_coco_segmentation(self, predictions):\n        coco_results = []\n        for original_id, prediction in predictions.items():\n            if len(prediction) == 0:\n                continue\n\n            scores = prediction[\"scores\"]\n            labels = prediction[\"labels\"]\n            masks = prediction[\"masks\"]\n\n            masks = masks > 0.5\n\n            scores = prediction[\"scores\"].tolist()\n            labels = prediction[\"labels\"].tolist()\n\n            rles = [\n                mask_util.encode(np.array(mask[0, :, :, np.newaxis], dtype=np.uint8, order=\"F\"))[0]\n                for mask in masks\n            ]\n            for rle in rles:\n                rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n\n            coco_results.extend(\n                [\n                    {\n                        \"image_id\": original_id,\n                        \"category_id\": labels[k],\n                        \"segmentation\": rle,\n                        \"score\": scores[k],\n                    }\n                    for k, rle in enumerate(rles)\n                ]\n            )\n        return coco_results\n\n    def prepare_for_coco_keypoint(self, predictions):\n        coco_results = []\n        for original_id, prediction in predictions.items():\n            if len(prediction) == 0:\n                continue\n\n            boxes = prediction[\"boxes\"]\n            boxes = convert_to_xywh(boxes).tolist()\n            scores = prediction[\"scores\"].tolist()\n            labels = prediction[\"labels\"].tolist()\n            keypoints = prediction[\"keypoints\"]\n            keypoints = keypoints.flatten(start_dim=1).tolist()\n\n            coco_results.extend(\n                [\n                    {\n                        \"image_id\": original_id,\n                        \"category_id\": labels[k],\n                        'keypoints': keypoint,\n                        \"score\": scores[k],\n                    }\n                    for k, keypoint in enumerate(keypoints)\n                ]\n            )\n        return coco_results\n\n\ndef convert_to_xywh(boxes):\n    xmin, ymin, xmax, ymax = boxes.unbind(1)\n    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n\n\ndef merge(img_ids, eval_imgs):\n    all_img_ids = all_gather(img_ids)\n    all_eval_imgs = all_gather(eval_imgs)\n\n    merged_img_ids = []\n    for p in all_img_ids:\n        merged_img_ids.extend(p)\n\n    merged_eval_imgs = []\n    for p in all_eval_imgs:\n        merged_eval_imgs.append(p)\n\n    merged_img_ids = np.array(merged_img_ids)\n    merged_eval_imgs = np.concatenate(merged_eval_imgs, 2)\n\n    # keep only unique (and in sorted order) images\n    merged_img_ids, idx = np.unique(merged_img_ids, return_index=True)\n    merged_eval_imgs = merged_eval_imgs[..., idx]\n\n    return merged_img_ids, merged_eval_imgs\n\n\ndef create_common_coco_eval(coco_eval, img_ids, eval_imgs):\n    img_ids, eval_imgs = merge(img_ids, eval_imgs)\n    img_ids = list(img_ids)\n    eval_imgs = list(eval_imgs.flatten())\n\n    coco_eval.evalImgs = eval_imgs\n    coco_eval.params.imgIds = img_ids\n    coco_eval._paramsEval = copy.deepcopy(coco_eval.params)\n\n\n#################################################################\n# From pycocotools, just removed the prints and fixed\n# a Python3 bug about unicode not defined\n#################################################################\n\n# Ideally, pycocotools wouldn't have hard-coded prints\n# so that we could avoid copy-pasting those two functions\n\ndef createIndex(self):\n    # create index\n    # print('creating index...')\n    anns, cats, imgs = {}, {}, {}\n    imgToAnns, catToImgs = defaultdict(list), defaultdict(list)\n    if 'annotations' in self.dataset:\n        for ann in self.dataset['annotations']:\n            imgToAnns[ann['image_id']].append(ann)\n            anns[ann['id']] = ann\n\n    if 'images' in self.dataset:\n        for img in self.dataset['images']:\n            imgs[img['id']] = img\n\n    if 'categories' in self.dataset:\n        for cat in self.dataset['categories']:\n            cats[cat['id']] = cat\n\n    if 'annotations' in self.dataset and 'categories' in self.dataset:\n        for ann in self.dataset['annotations']:\n            catToImgs[ann['category_id']].append(ann['image_id'])\n\n    # print('index created!')\n\n    # create class members\n    self.anns = anns\n    self.imgToAnns = imgToAnns\n    self.catToImgs = catToImgs\n    self.imgs = imgs\n    self.cats = cats\n\n\nmaskUtils = mask_util\n\n\ndef loadRes(self, resFile):\n    \"\"\"\n    Load result file and return a result api object.\n    :param   resFile (str)     : file name of result file\n    :return: res (obj)         : result api object\n    \"\"\"\n    res = COCO()\n    res.dataset['images'] = [img for img in self.dataset['images']]\n\n    # print('Loading and preparing results...')\n    # tic = time.time()\n    if isinstance(resFile, torch._six.string_classes):\n        anns = json.load(open(resFile))\n    elif type(resFile) == np.ndarray:\n        anns = self.loadNumpyAnnotations(resFile)\n    else:\n        anns = resFile\n    assert type(anns) == list, 'results in not an array of objects'\n    annsImgIds = [ann['image_id'] for ann in anns]\n    assert set(annsImgIds) == (set(annsImgIds) & set(self.getImgIds())), \\\n        'Results do not correspond to current coco set'\n    if 'caption' in anns[0]:\n        imgIds = set([img['id'] for img in res.dataset['images']]) & set([ann['image_id'] for ann in anns])\n        res.dataset['images'] = [img for img in res.dataset['images'] if img['id'] in imgIds]\n        for id, ann in enumerate(anns):\n            ann['id'] = id + 1\n    elif 'bbox' in anns[0] and not anns[0]['bbox'] == []:\n        res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n        for id, ann in enumerate(anns):\n            bb = ann['bbox']\n            x1, x2, y1, y2 = [bb[0], bb[0] + bb[2], bb[1], bb[1] + bb[3]]\n            if 'segmentation' not in ann:\n                ann['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n            ann['area'] = bb[2] * bb[3]\n            ann['id'] = id + 1\n            ann['iscrowd'] = 0\n    elif 'segmentation' in anns[0]:\n        res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n        for id, ann in enumerate(anns):\n            # now only support compressed RLE format as segmentation results\n            ann['area'] = maskUtils.area(ann['segmentation'])\n            if 'bbox' not in ann:\n                ann['bbox'] = maskUtils.toBbox(ann['segmentation'])\n            ann['id'] = id + 1\n            ann['iscrowd'] = 0\n    elif 'keypoints' in anns[0]:\n        res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n        for id, ann in enumerate(anns):\n            s = ann['keypoints']\n            x = s[0::3]\n            y = s[1::3]\n            x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)\n            ann['area'] = (x2 - x1) * (y2 - y1)\n            ann['id'] = id + 1\n            ann['bbox'] = [x1, y1, x2 - x1, y2 - y1]\n    # print('DONE (t={:0.2f}s)'.format(time.time()- tic))\n\n    res.dataset['annotations'] = anns\n    createIndex(res)\n    return res\n\n\ndef evaluate_inner(self):\n    '''\n    Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n    :return: None\n    '''\n    # tic = time.time()\n    # print('Running per image evaluation...')\n    p = self.params\n    # add backward compatibility if useSegm is specified in params\n    if p.useSegm is not None:\n        p.iouType = 'segm' if p.useSegm == 1 else 'bbox'\n        print('useSegm (deprecated) is not None. Running {} evaluation'.format(p.iouType))\n    # print('Evaluate annotation type *{}*'.format(p.iouType))\n    p.imgIds = list(np.unique(p.imgIds))\n    if p.useCats:\n        p.catIds = list(np.unique(p.catIds))\n    p.maxDets = sorted(p.maxDets)\n    self.params = p\n\n    self._prepare()\n    # loop through images, area range, max detection number\n    catIds = p.catIds if p.useCats else [-1]\n\n    if p.iouType == 'segm' or p.iouType == 'bbox':\n        computeIoU = self.computeIoU\n    elif p.iouType == 'keypoints':\n        computeIoU = self.computeOks\n    self.ious = {\n        (imgId, catId): computeIoU(imgId, catId)\n        for imgId in p.imgIds\n        for catId in catIds}\n\n    evaluateImg = self.evaluateImg\n    maxDet = p.maxDets[-1]\n    evalImgs = [\n        evaluateImg(imgId, catId, areaRng, maxDet)\n        for catId in catIds\n        for areaRng in p.areaRng\n        for imgId in p.imgIds\n    ]\n    # this is NOT in the pycocotools code, but could be done outside\n    evalImgs = np.asarray(evalImgs).reshape(len(catIds), len(p.areaRng), len(p.imgIds))\n    self._paramsEval = copy.deepcopy(self.params)\n    # toc = time.time()\n    # print('DONE (t={:0.2f}s).'.format(toc-tic))\n    return p.imgIds, evalImgs\n\n#################################################################\n# end of straight copy from pycocotools, just removing the prints\n#################################################################","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.370689Z","iopub.execute_input":"2023-02-13T08:37:10.371019Z","iopub.status.idle":"2023-02-13T08:37:10.431332Z","shell.execute_reply.started":"2023-02-13T08:37:10.370988Z","shell.execute_reply":"2023-02-13T08:37:10.430177Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train_utils/coco_utils.py\n\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torch.utils.data\nfrom pycocotools.coco import COCO\n\n\ndef convert_to_coco_api(ds):\n    coco_ds = COCO()\n    # annotation IDs need to start at 1, not 0\n    ann_id = 1\n    dataset = {'images': [], 'categories': [], 'annotations': []}\n    categories = set()\n    for img_idx in range(len(ds)):\n        # find better way to get target\n        targets = ds.coco_index(img_idx)\n        if not targets:\n            continue\n        image_id = targets[\"image_id\"].item()\n        img_dict = {}\n        img_dict['id'] = image_id\n        # img_dict['height'] = img.shape[-2]\n        # img_dict['width'] = img.shape[-1]\n        img_dict['height'] = targets[\"height_width\"][0]\n        img_dict['width'] = targets[\"height_width\"][1]\n        dataset['images'].append(img_dict)\n\n        # xmin, ymin, xmax, ymax\n        bboxes = targets[\"boxes\"]\n\n        # (xmin, ymin, xmax, ymax) to (xmin, ymin, w, h)\n        bboxes[:, 2:] -= bboxes[:, :2]\n        # 将box的相对坐标信息（0-1）转为绝对值坐标\n        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] * img_dict[\"width\"]\n        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] * img_dict[\"height\"]\n        bboxes = bboxes.tolist()\n        labels = targets['labels'].tolist()\n        # 注意这里的boxes area也要进行转换，否则导致(small, medium, large)计算错误\n        areas = (targets['area'] * img_dict[\"width\"] * img_dict[\"height\"]).tolist()\n        iscrowd = targets['iscrowd'].tolist()\n        num_objs = len(bboxes)\n        for i in range(num_objs):\n            ann = {}\n            ann['image_id'] = image_id\n            ann['bbox'] = bboxes[i]\n            ann['category_id'] = labels[i]\n            categories.add(labels[i])\n            ann['area'] = areas[i]\n            ann['iscrowd'] = iscrowd[i]\n            ann['id'] = ann_id\n            dataset['annotations'].append(ann)\n            ann_id += 1\n    dataset['categories'] = [{'id': i} for i in sorted(categories)]\n    coco_ds.dataset = dataset\n    coco_ds.createIndex()\n    return coco_ds\n\n\ndef get_coco_api_from_dataset(dataset):\n    for _ in range(10):\n        if isinstance(dataset, torchvision.datasets.CocoDetection):\n            break\n        if isinstance(dataset, torch.utils.data.Subset):\n            dataset = dataset.dataset\n    if isinstance(dataset, torchvision.datasets.CocoDetection):\n        return dataset.coco\n    return convert_to_coco_api(dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.433472Z","iopub.execute_input":"2023-02-13T08:37:10.433902Z","iopub.status.idle":"2023-02-13T08:37:10.635257Z","shell.execute_reply.started":"2023-02-13T08:37:10.433861Z","shell.execute_reply":"2023-02-13T08:37:10.634303Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# group_by_aspect_ratio.py\n\nimport bisect\nfrom collections import defaultdict\nimport copy\nfrom itertools import repeat, chain\nimport math\nimport numpy as np\n\nimport torch\nimport torch.utils.data\nfrom torch.utils.data.sampler import BatchSampler, Sampler\nfrom torch.utils.model_zoo import tqdm\nimport torchvision\n\nfrom PIL import Image\n\n\ndef _repeat_to_at_least(iterable, n):\n    repeat_times = math.ceil(n / len(iterable))\n    repeated = chain.from_iterable(repeat(iterable, repeat_times))\n    return list(repeated)\n\n\nclass GroupedBatchSampler(BatchSampler):\n    \"\"\"\n    Wraps another sampler to yield a mini-batch of indices.\n    It enforces that the batch only contain elements from the same group.\n    It also tries to provide mini-batches which follows an ordering which is\n    as close as possible to the ordering from the original sampler.\n    Arguments:\n        sampler (Sampler): Base sampler.\n        group_ids (list[int]): If the sampler produces indices in range [0, N),\n            `group_ids` must be a list of `N` ints which contains the group id of each sample.\n            The group ids must be a continuous set of integers starting from\n            0, i.e. they must be in the range [0, num_groups).\n        batch_size (int): Size of mini-batch.\n    \"\"\"\n    def __init__(self, sampler, group_ids, batch_size):\n        if not isinstance(sampler, Sampler):\n            raise ValueError(\n                \"sampler should be an instance of \"\n                \"torch.utils.data.Sampler, but got sampler={}\".format(sampler)\n            )\n        self.sampler = sampler\n        self.group_ids = group_ids\n        self.batch_size = batch_size\n\n    def __iter__(self):\n        buffer_per_group = defaultdict(list)\n        samples_per_group = defaultdict(list)\n\n        num_batches = 0\n        for idx in self.sampler:\n            group_id = self.group_ids[idx]\n            buffer_per_group[group_id].append(idx)\n            samples_per_group[group_id].append(idx)\n            if len(buffer_per_group[group_id]) == self.batch_size:\n                yield buffer_per_group[group_id]\n                num_batches += 1\n                del buffer_per_group[group_id]\n            assert len(buffer_per_group[group_id]) < self.batch_size\n\n        # now we have run out of elements that satisfy\n        # the group criteria, let's return the remaining\n        # elements so that the size of the sampler is\n        # deterministic\n        expected_num_batches = len(self)\n        num_remaining = expected_num_batches - num_batches\n        if num_remaining > 0:\n            # for the remaining batches, take first the buffers with largest number\n            # of elements\n            for group_id, _ in sorted(buffer_per_group.items(),\n                                      key=lambda x: len(x[1]), reverse=True):\n                remaining = self.batch_size - len(buffer_per_group[group_id])\n                samples_from_group_id = _repeat_to_at_least(samples_per_group[group_id], remaining)\n                buffer_per_group[group_id].extend(samples_from_group_id[:remaining])\n                assert len(buffer_per_group[group_id]) == self.batch_size\n                yield buffer_per_group[group_id]\n                num_remaining -= 1\n                if num_remaining == 0:\n                    break\n        assert num_remaining == 0\n\n    def __len__(self):\n        return len(self.sampler) // self.batch_size\n\n\ndef _compute_aspect_ratios_slow(dataset, indices=None):\n    print(\"Your dataset doesn't support the fast path for \"\n          \"computing the aspect ratios, so will iterate over \"\n          \"the full dataset and load every image instead. \"\n          \"This might take some time...\")\n    if indices is None:\n        indices = range(len(dataset))\n\n    class SubsetSampler(Sampler):\n        def __init__(self, indices):\n            self.indices = indices\n\n        def __iter__(self):\n            return iter(self.indices)\n\n        def __len__(self):\n            return len(self.indices)\n\n    sampler = SubsetSampler(indices)\n    data_loader = torch.utils.data.DataLoader(\n        dataset, batch_size=1, sampler=sampler,\n        num_workers=14,  # you might want to increase it for faster processing\n        collate_fn=lambda x: x[0])\n    aspect_ratios = []\n    with tqdm(total=len(dataset)) as pbar:\n        for _i, (img, _) in enumerate(data_loader):\n            pbar.update(1)\n            height, width = img.shape[-2:]\n            aspect_ratio = float(width) / float(height)\n            aspect_ratios.append(aspect_ratio)\n    return aspect_ratios\n\n\ndef _compute_aspect_ratios_custom_dataset(dataset, indices=None):\n    if indices is None:\n        indices = range(len(dataset))\n    aspect_ratios = []\n    for i in indices:\n        height, width = dataset.get_height_and_width(i)\n        aspect_ratio = float(width) / float(height)\n        aspect_ratios.append(aspect_ratio)\n    return aspect_ratios\n\n\ndef _compute_aspect_ratios_coco_dataset(dataset, indices=None):\n    if indices is None:\n        indices = range(len(dataset))\n    aspect_ratios = []\n    for i in indices:\n        img_info = dataset.coco.imgs[dataset.ids[i]]\n        aspect_ratio = float(img_info[\"width\"]) / float(img_info[\"height\"])\n        aspect_ratios.append(aspect_ratio)\n    return aspect_ratios\n\n\ndef _compute_aspect_ratios_voc_dataset(dataset, indices=None):\n    if indices is None:\n        indices = range(len(dataset))\n    aspect_ratios = []\n    for i in indices:\n        # this doesn't load the data into memory, because PIL loads it lazily\n        width, height = Image.open(dataset.images[i]).size\n        aspect_ratio = float(width) / float(height)\n        aspect_ratios.append(aspect_ratio)\n    return aspect_ratios\n\n\ndef _compute_aspect_ratios_subset_dataset(dataset, indices=None):\n    if indices is None:\n        indices = range(len(dataset))\n\n    ds_indices = [dataset.indices[i] for i in indices]\n    return compute_aspect_ratios(dataset.dataset, ds_indices)\n\n\ndef compute_aspect_ratios(dataset, indices=None):\n    if hasattr(dataset, \"get_height_and_width\"):\n        return _compute_aspect_ratios_custom_dataset(dataset, indices)\n\n    if isinstance(dataset, torchvision.datasets.CocoDetection):\n        return _compute_aspect_ratios_coco_dataset(dataset, indices)\n\n    if isinstance(dataset, torchvision.datasets.VOCDetection):\n        return _compute_aspect_ratios_voc_dataset(dataset, indices)\n\n    if isinstance(dataset, torch.utils.data.Subset):\n        return _compute_aspect_ratios_subset_dataset(dataset, indices)\n\n    # slow path\n    return _compute_aspect_ratios_slow(dataset, indices)\n\n\ndef _quantize(x, bins):\n    bins = copy.deepcopy(bins)\n    bins = sorted(bins)\n    # bisect_right：寻找y元素按顺序应该排在bins中哪个元素的右边，返回的是索引\n    quantized = list(map(lambda y: bisect.bisect_right(bins, y), x))\n    return quantized\n\n\ndef create_aspect_ratio_groups(dataset, k=0):\n    # 计算所有数据集中的图片width/height比例\n    aspect_ratios = compute_aspect_ratios(dataset)\n    # 将[0.5, 2]区间划分成2*k+1等份\n    bins = (2 ** np.linspace(-1, 1, 2 * k + 1)).tolist() if k > 0 else [1.0]\n\n    # 统计所有图像比例在bins区间中的位置索引\n    groups = _quantize(aspect_ratios, bins)\n    # count number of elements per group\n    # 统计每个区间的频次\n    counts = np.unique(groups, return_counts=True)[1]\n    fbins = [0] + bins + [np.inf]\n    print(\"Using {} as bins for aspect ratio quantization\".format(fbins))\n    print(\"Count of instances per bin: {}\".format(counts))\n    return groups","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.636942Z","iopub.execute_input":"2023-02-13T08:37:10.637532Z","iopub.status.idle":"2023-02-13T08:37:10.666725Z","shell.execute_reply.started":"2023-02-13T08:37:10.637490Z","shell.execute_reply":"2023-02-13T08:37:10.665730Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# train_utils/train_eval_utils.py\n\nimport math\nimport sys\nimport time\n\nimport torch\n\n# from train_utils import get_coco_api_from_dataset, CocoEvaluator\n# import train_utils.distributed_utils as utils\n\n\ndef train_one_epoch(model, optimizer, data_loader, device, epoch,\n                    print_freq=20, warmup=False):\n    model.train()\n    metric_logger = MetricLogger(delimiter=\"  \")\n    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n    header = 'Epoch: [{}]'.format(epoch)\n    lr_scheduler = None\n    if epoch == 0 and warmup is True:  # 当训练第一轮（epoch=0）时，启用warmup训练方式，可理解为热身训练\n        warmup_factor = 5.0 / 10000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    mloss = torch.zeros(1).to(device)  # mean losses\n    for i, [images, targets] in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n        # batch inputs information\n        images = torch.stack(images, dim=0)\n\n        boxes = []\n        labels = []\n        img_id = []\n        for t in targets:\n            boxes.append(t['boxes'])\n            labels.append(t['labels'])\n            img_id.append(t[\"image_id\"])\n        targets = {\"boxes\": torch.stack(boxes, dim=0),\n                   \"labels\": torch.stack(labels, dim=0),\n                   \"image_id\": torch.as_tensor(img_id)}\n\n        images = images.to(device)\n\n        targets = {k: v.to(device) for k, v in targets.items()}\n        losses_dict = model(images, targets)\n        losses = losses_dict[\"total_losses\"]\n\n        # reduce losses over all GPUs for logging purpose\n        losses_dict_reduced = reduce_dict(losses_dict)\n        losses_reduce = losses_dict_reduced[\"total_losses\"]\n\n        loss_value = losses_reduce.detach()\n        # 记录训练损失\n        mloss = (mloss * i + loss_value) / (i + 1)  # update mean losses\n\n        if not math.isfinite(loss_value):  # 当计算的损失为无穷大时停止训练\n            print(\"Loss is {}, stopping training\".format(loss_value))\n            print(losses_dict_reduced)\n            sys.exit(1)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if lr_scheduler is not None:  # 第一轮使用warmup训练方式\n            lr_scheduler.step()\n\n        # metric_logger.update(loss=losses, **loss_dict_reduced)\n        metric_logger.update(**losses_dict_reduced)\n        now_lr = optimizer.param_groups[0][\"lr\"]\n        metric_logger.update(lr=now_lr)\n\n    return mloss, now_lr\n\n\n@torch.no_grad()\ndef evaluate(model, data_loader, device, data_set=None):\n\n    cpu_device = torch.device(\"cpu\")\n    model.eval()\n    metric_logger = MetricLogger(delimiter=\"  \")\n    header = \"Test: \"\n\n    if data_set is None:\n        data_set = get_coco_api_from_dataset(data_loader.dataset)\n    iou_types = _get_iou_types(model)\n    coco_evaluator = CocoEvaluator(data_set, iou_types)\n\n    for images, targets in metric_logger.log_every(data_loader, 100, header):\n        images = torch.stack(images, dim=0).to(device)\n\n        if device != torch.device(\"cpu\"):\n            torch.cuda.synchronize(device)\n\n        model_time = time.time()\n        #  list((bboxes_out, labels_out, scores_out), ...)\n        results = model(images, targets=None)\n        model_time = time.time() - model_time\n\n        outputs = []\n        for index, (bboxes_out, labels_out, scores_out) in enumerate(results):\n            # 将box的相对坐标信息（0-1）转为绝对值坐标(xmin, ymin, xmax, ymax)\n            height_width = targets[index][\"height_width\"]\n            # 还原回原图尺度\n            bboxes_out[:, [0, 2]] = bboxes_out[:, [0, 2]] * height_width[1]\n            bboxes_out[:, [1, 3]] = bboxes_out[:, [1, 3]] * height_width[0]\n\n            info = {\"boxes\": bboxes_out.to(cpu_device),\n                    \"labels\": labels_out.to(cpu_device),\n                    \"scores\": scores_out.to(cpu_device)}\n            outputs.append(info)\n\n        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n\n        evaluator_time = time.time()\n        coco_evaluator.update(res)\n        evaluator_time = time.time() - evaluator_time\n        metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n\n    # gather the stats from all processes\n    metric_logger.synchronize_between_processes()\n    print(\"Averaged stats:\", metric_logger)\n    coco_evaluator.synchronize_between_processes()\n\n    # accumulate predictions from all images\n    coco_evaluator.accumulate()\n    coco_evaluator.summarize()\n\n    coco_info = coco_evaluator.coco_eval[iou_types[0]].stats.tolist()  # numpy to list\n\n    return coco_info\n\n\ndef _get_iou_types(model):\n    model_without_ddp = model\n    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n        model_without_ddp = model.module\n    iou_types = [\"bbox\"]\n    return iou_types","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.668354Z","iopub.execute_input":"2023-02-13T08:37:10.668988Z","iopub.status.idle":"2023-02-13T08:37:10.691512Z","shell.execute_reply.started":"2023-02-13T08:37:10.668950Z","shell.execute_reply":"2023-02-13T08:37:10.690378Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# my_dataset.py\n\nfrom torch.utils.data import Dataset\nimport os\nimport torch\nimport json\nfrom PIL import Image\n\nfrom torch.jit.annotations import List\n\nCSV_FIELD_COUNT = 8\n\nIMAGE_TYPE = \".jpg\"\nANNOTATION_FILE_TYPE = \".csv\"\n\nCSV_FIELD_FILENAME = \"filename\"\nCSV_FIELD_WIDTH = \"width\"\nCSV_FIELD_HEIGHT = \"height\"\nCSV_FIELD_CLASS = \"class\"\nCSV_FIELD_XMIN = \"xmin\"\nCSV_FIELD_YMIN = \"ymin\"\nCSV_FIELD_XMAX = \"xmax\"\nCSV_FIELD_YMAX = \"ymax\"\n\nCSV_FIELD_FILENAME_INDEX = 0\nCSV_FIELD_WIDTH_INDEX = 1\nCSV_FIELD_HEIGHT_INDEX = 2\nCSV_FIELD_CLASS_INDEX = 3\nCSV_FIELD_XMIN_INDEX = 4\nCSV_FIELD_YMIN_INDEX = 5\nCSV_FIELD_XMAX_INDEX = 6\nCSV_FIELD_YMAX_INDEX = 7\n\nTARGET_FIELD_BOXES = \"boxes\"\nTARGET_FIELD_LABELS = \"labels\"\nTARGET_FIELD_IMAGE_ID = \"image_id\"\nTARGET_FIELD_AREA = \"area\"\nTARGET_FIELD_ISCROWD = \"iscrowd\"\nTARGET_FIELD_HEIGHT_WIDTH = \"height_width\"\nTARGET_FIELD_IMAGE_DATA = \"image_data\"\n\nclass AirCraftDataSet(Dataset):\n    \"\"\"\n        读取解析 军用飞行器 数据集\n    \"\"\"\n    def __init__(self, img_root, annotations_root, transforms=None, train_set='train.txt'):\n        self.root = img_root\n        self.img_root = os.path.join(self.root, \"dataset\")\n        self.annotations_root = annotations_root\n\n        self.annotation_data = torch.jit.annotate(List[str], [])\n        data_file = os.path.join(annotations_root, train_set)\n        with open(data_file, mode=\"r\", encoding=\"utf8\") as f:\n            for file in f.readlines():\n                self.annotation_data.append(file.strip())\n        # read class_indict\n        json_file = \"/kaggle/input/nvidia-ssdpyt-fp32-190826pt/aircraft_classes.json\"\n        assert os.path.exists(json_file), \"{} file not exist.\".format(json_file)\n\n        with open(json_file, 'r') as f:\n            self.class_dict = json.load(f)\n\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.annotation_data)\n\n    def __getitem__(self, idx):\n        \"\"\"\n            读取CSV标注文件\n        \"\"\"\n        image_raw_data = None\n        boxes = []\n        labels = []\n        iscrowd = []\n        # read csv annotation\n        csv_file = os.path.join(self.img_root, self.annotation_data[idx])\n        if not os.path.exists(csv_file):\n            print(f\"{csv_file} not exists!\")\n            return (None, None)\n        \n        with open(file=csv_file, mode=\"r\", encoding=\"utf8\") as fid:\n            # Ignore the first line(field title)\n            fid.readline()\n            while True:\n                csv_line = fid.readline()\n                if not csv_line:\n                    break\n\n                csv_line_content = csv_line.strip().split(sep=\",\")\n                if len(csv_line_content) < CSV_FIELD_COUNT:\n                    # Not satisfy annotation format\n                    print(f\"{csv_file} field count({len(csv_line_content)}) less than {CSV_FIELD_COUNT}\")\n                    continue\n\n                parsed_dict = self.parse_csv_line_to_dict(csv_line_content = csv_line_content, load_img_data=not image_raw_data)\n\n                if not image_raw_data and parsed_dict[TARGET_FIELD_IMAGE_DATA]:\n                    image_raw_data = parsed_dict[TARGET_FIELD_IMAGE_DATA]\n\n                    data_height = int(parsed_dict[CSV_FIELD_HEIGHT])\n                    data_width = int(parsed_dict[CSV_FIELD_WIDTH])\n                    height_width = [data_height, data_width]\n\n                boxes.append(parsed_dict[TARGET_FIELD_BOXES])\n                labels.append(parsed_dict[TARGET_FIELD_LABELS])\n                iscrowd.append(parsed_dict[TARGET_FIELD_ISCROWD])\n            # 缺少 object\n            assert len(boxes), \"{} lack of object information.\".format(csv_file)\n\n        # 转 tensor\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n        height_width = torch.as_tensor(height_width, dtype=torch.int64)\n        # 编号\n        image_id = torch.tensor([idx])\n        # 面积\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n\n        target = {}\n        target[TARGET_FIELD_BOXES] = boxes\n        target[TARGET_FIELD_LABELS] = labels\n        target[TARGET_FIELD_IMAGE_ID] = image_id\n        target[TARGET_FIELD_AREA] = area\n        target[TARGET_FIELD_ISCROWD] = iscrowd\n        target[TARGET_FIELD_HEIGHT_WIDTH] = height_width\n\n        # 图像预处理\n        if self.transforms is not None:\n            image, target = self.transforms(image_raw_data, target)\n        return image, target\n\n    def get_height_and_width(self, idx):\n        # read csv\n        csv_path = self.annotation_data[idx]\n        with open(csv_path) as fid:\n            fid.readline()\n            csv_line = fid.readLine()\n            if not csv_line:\n                print(f\"get_height_and_width, {csv_path} has no valid content\")\n                return -1, -1\n            parsed_dict = self.parse_csv_line_to_dict(csv_line_content = csv_line.strip().split(sep=\",\"),\n                                                      load_img_data = False)\n            data_height = int(parsed_dict[CSV_FIELD_HEIGHT])\n            data_width = int(parsed_dict[CSV_FIELD_WIDTH])\n\n            return data_height, data_width\n\n    def parse_csv_line_to_dict(self, csv_line_content, load_img_data = True):\n        \"\"\"\n        将csv文件解析成字典形式.\n        \"\"\"\n        result = {}\n        if not csv_line_content:\n            return self.emptyResult(result, \"\")\n\n        if len(csv_line_content) < 8:\n            print(f\"Not satisfy annotation format, expect 8 columns, but got {len(csv_line_content)} columns instead.\")\n            return self.emptyResult(result, \"\")\n\n        data_height = int(csv_line_content[CSV_FIELD_HEIGHT_INDEX])\n        data_width = int(csv_line_content[CSV_FIELD_WIDTH_INDEX])\n        height_width = [data_height, data_width]\n\n        if load_img_data:\n            img_path = os.path.join(self.img_root, csv_line_content[CSV_FIELD_FILENAME_INDEX])\n            try:\n                image = Image.open(img_path + IMAGE_TYPE)\n            except:\n                print(f\"Open {img_path + '.' + IMAGE_TYPE} failed\")\n                return self.emptyResult(result, img_path + IMAGE_TYPE)\n            if image.format != \"JPEG\" and image.format != \"MPO\":\n                raise ValueError(f\"Image '{img_path + '.' + image.format}' format not JPEG\")\n        # 将所有的gt box信息转换成相对值0-1之间\n        xmin = float(csv_line_content[CSV_FIELD_XMIN_INDEX]) / data_width\n        ymin = float(csv_line_content[CSV_FIELD_YMIN_INDEX]) / data_height\n        xmax = float(csv_line_content[CSV_FIELD_XMAX_INDEX]) / data_width\n        ymax = float(csv_line_content[CSV_FIELD_YMAX_INDEX]) / data_height\n        # 检查错误的标注信息\n        if xmax <= xmin or ymax <= ymin:\n            print(f\"Warning: there are some bbox w/h <=0, source line: {csv_line_content}\")\n            return result\n\n        if csv_line_content[CSV_FIELD_CLASS_INDEX] not in self.class_dict:\n            print(f\"{csv_line_content[CSV_FIELD_CLASS_INDEX]} not in class dict\")\n            return result\n        \n        result[CSV_FIELD_FILENAME] = csv_line_content[CSV_FIELD_FILENAME_INDEX] + IMAGE_TYPE\n        result[CSV_FIELD_HEIGHT] = data_height\n        result[CSV_FIELD_WIDTH] = data_width\n        result[TARGET_FIELD_HEIGHT_WIDTH] = height_width\n        result[TARGET_FIELD_BOXES] = [xmin, ymin, xmax, ymax]\n        result[TARGET_FIELD_LABELS] = self.class_dict[csv_line_content[CSV_FIELD_CLASS_INDEX]]\n        result[TARGET_FIELD_ISCROWD] = 0\n        result[TARGET_FIELD_IMAGE_DATA] = image if load_img_data else None\n\n        return result\n\n    def emptyResult(self, result, filename):\n        result[CSV_FIELD_FILENAME] = filename\n        result[CSV_FIELD_HEIGHT] = -1\n        result[CSV_FIELD_WIDTH] = -1\n        result[TARGET_FIELD_HEIGHT_WIDTH] = -1, -1\n        result[TARGET_FIELD_BOXES] = [-1., -1., -1., -1.]\n        result[TARGET_FIELD_LABELS] = 0\n        result[TARGET_FIELD_ISCROWD] = 0\n        result[TARGET_FIELD_IMAGE_DATA] = None\n\n        return result\n\n    def coco_index(self, idx):\n        \"\"\"\n        该方法是专门为 pycocotools 统计标签信息准备，不对图像和标签作任何处理\n        由于不用去读取图片，可大幅缩减统计时间\n\n        Args:\n            idx: 输入需要获取图像的索引\n        \"\"\"\n        boxes = []\n        labels = []\n        iscrowd = []\n        height_width = None\n        # read csv\n        csv_path = os.path.join(self.img_root, self.annotation_data[idx])\n        if not os.path.exists(csv_path):\n            print(f\"{csv_path} not exists!\")\n            return {}\n        \n        with open(file=csv_path, mode=\"r\", encoding=\"utf8\") as fid:\n            fid.readline()\n            while True:\n                csv_line = fid.readline()\n                if not csv_line:\n                    break\n                csv_line_content = csv_line.strip().split(sep=\",\")\n                if len(csv_line_content) < CSV_FIELD_COUNT:\n                    print(f\"coco_index, csv_line_content len({len(csv_line_content)}) smaller than csv field count({CSV_FIELD_COUNT})\")\n                    continue\n\n                parsed_dict = self.parse_csv_line_to_dict(csv_line_content = csv_line_content, load_img_data=False)\n                if not height_width:\n                    data_height = parsed_dict[CSV_FIELD_HEIGHT]\n                    data_width = parsed_dict[CSV_FIELD_WIDTH]\n                    height_width = [data_height, data_width]\n                boxes.append(parsed_dict[TARGET_FIELD_BOXES])\n                labels.append(parsed_dict[TARGET_FIELD_LABELS])\n                iscrowd.append(parsed_dict[TARGET_FIELD_ISCROWD])\n        # convert everything into a torch.Tensor\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n        height_width = torch.as_tensor(height_width, dtype=torch.int64)\n        image_id = torch.tensor([idx])\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n\n        target = {}\n        target[TARGET_FIELD_BOXES] = boxes\n        target[TARGET_FIELD_LABELS] = labels\n        target[TARGET_FIELD_IMAGE_ID] = image_id\n        target[TARGET_FIELD_AREA] = area\n        target[TARGET_FIELD_ISCROWD] = iscrowd\n        target[TARGET_FIELD_HEIGHT_WIDTH] = height_width\n\n        return target\n\n    @staticmethod\n    def collate_fn(batch):\n        images, targets = tuple(zip(*batch))\n        return images, targets","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.695170Z","iopub.execute_input":"2023-02-13T08:37:10.695592Z","iopub.status.idle":"2023-02-13T08:37:10.734842Z","shell.execute_reply.started":"2023-02-13T08:37:10.695555Z","shell.execute_reply":"2023-02-13T08:37:10.733741Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# transforms.py\n\nimport random\n\nimport numpy as np\nimport torch\nimport torchvision.transforms as t\nfrom torchvision.transforms import functional as F_torchvision\n\n# from src import dboxes300_coco, calc_iou_tensor, Encoder\n\n\nclass Compose(object):\n    \"\"\"组合多个transform函数\"\"\"\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, image, target=None):\n        for trans in self.transforms:\n            image, target = trans(image, target)\n        return image, target\n\n\nclass ToTensor(object):\n    \"\"\"将PIL图像转为Tensor\"\"\"\n    def __call__(self, image, target):\n        image = F_torchvision.to_tensor(image).contiguous()\n        return image, target\n\n\nclass RandomHorizontalFlip(object):\n    \"\"\"随机水平翻转图像以及bboxes,该方法应放在ToTensor后\"\"\"\n    def __init__(self, prob=0.5):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            # height, width = image.shape[-2:]\n            image = image.flip(-1)  # 水平翻转图片\n            bbox = target[\"boxes\"]\n            # bbox: xmin, ymin, xmax, ymax\n            # bbox[:, [0, 2]] = width - bbox[:, [2, 0]]  # 翻转对应bbox坐标信息\n            bbox[:, [0, 2]] = 1.0 - bbox[:, [2, 0]]  # 翻转对应bbox坐标信息\n            target[\"boxes\"] = bbox\n        return image, target\n\n\nclass SSDCropping(object):\n    \"\"\"\n    根据原文，对图像进行裁剪,该方法应放在ToTensor前\n    Cropping for SSD, according to original paper\n    Choose between following 3 conditions:\n    1. Preserve the original image\n    2. Random crop minimum IoU is among 0.1, 0.3, 0.5, 0.7, 0.9\n    3. Random crop\n    Reference to https://github.com/chauhan-utk/src.DomainAdaptation\n    \"\"\"\n    def __init__(self):\n        self.sample_options = (\n            # 不做裁剪\n            None,\n            # 最小和最大 IoU\n            (0.1, None),\n            (0.3, None),\n            (0.5, None),\n            (0.7, None),\n            (0.9, None),\n            # 不做限制\n            (None, None),\n        )\n        self.dboxes = dboxes300_coco()\n\n    def __call__(self, image, target):\n        # 死循环，确保一定会返回结果\n        while True:\n            mode = random.choice(self.sample_options)\n\n            if mode is None:  # 不做随机裁剪处理\n                return image, target\n\n            htot, wtot = target['height_width']\n\n            min_iou, max_iou = mode\n            min_iou = float('-inf') if min_iou is None else min_iou\n            max_iou = float('+inf') if max_iou is None else max_iou\n            # Implementation use 5 iteration to find possible candidate\n            for _ in range(5):\n                # 0.3*0.3 approx. 0.1\n                w = random.uniform(0.3, 1.0)\n                h = random.uniform(0.3, 1.0)\n                if w/h < 0.5 or w/h > 2:  # 保证宽高比例在0.5-2之间\n                    continue\n\n                # left 0 ~ wtot - w, top 0 ~ htot - h\n                left = random.uniform(0, 1.0 - w)\n                top = random.uniform(0, 1.0 - h)\n\n                right = left + w\n                bottom = top + h\n\n                # boxes的坐标是在0-1之间的\n                bboxes = target[\"boxes\"]\n                ious = calc_iou_tensor(bboxes, torch.tensor([[left, top, right, bottom]]))\n                # tailor all the bboxes and return\n                # all(): Returns True if all elements in the tensor are True, False otherwise.\n                if not ((ious > min_iou) & (ious < max_iou)).all():\n                    continue\n\n                # 计算所有目标框的中心点\n                xc = 0.5 * (bboxes[:, 0] + bboxes[:, 2])\n                yc = 0.5 * (bboxes[:, 1] + bboxes[:, 3])\n                # 查看哪些目标框的中心点没有在被截取的图像中\n                masks = (xc > left) & (xc < right) & (yc > top) & (yc < bottom)\n\n                # 如果所有的gt box的中心点都不在采样的patch中，则重新找\n                if not masks.any():\n                    continue\n\n                # 修改采样patch中的所有gt box的坐标（防止出现越界的情况）\n                bboxes[bboxes[:, 0] < left, 0] = left\n                bboxes[bboxes[:, 1] < top, 1] = top\n                bboxes[bboxes[:, 2] > right, 2] = right\n                bboxes[bboxes[:, 3] > bottom, 3] = bottom\n\n                # 虑除不在采样patch中的gt box\n                bboxes = bboxes[masks, :]\n\n                # 获取在采样patch中的gt box的标签\n                labels = target['labels']\n                labels = labels[masks]\n\n                # 裁剪 patch\n                left_idx = int(left * wtot)\n                top_idx = int(top * htot)\n                right_idx = int(right * wtot)\n                bottom_idx = int(bottom * htot)\n                image = image.crop((left_idx, top_idx, right_idx, bottom_idx))\n                # 调整裁剪后的bboxes坐标信息\n\n                bboxes[:, 0] = (bboxes[:, 0] - left) / w\n                bboxes[:, 1] = (bboxes[:, 1] - top) / h\n                bboxes[:, 2] = (bboxes[:, 2] - left) / w\n                bboxes[:, 3] = (bboxes[:, 3] - top) / h\n\n                # 更新crop后的gt box坐标信息以及标签信息\n                target['boxes'] = bboxes\n                target['labels'] = labels\n                return image, target\n\n\nclass Resize(object):\n    \"\"\"对图像进行resize处理,该方法应放在ToTensor前\"\"\"\n    def __init__(self, size=(300, 300)):\n        self.resize = t.Resize(size)\n\n    def __call__(self, image, target):\n        image = self.resize(image)\n        return image, target\n\n\nclass ColorJitter(object):\n    \"\"\"对图像颜色信息进行随机调整,该方法应放在ToTensor前\"\"\"\n    def __init__(self, brightness=0.125, contrast=0.5, saturation=0.5, hue=0.05):\n        self.trans = t.ColorJitter(brightness, contrast, saturation, hue)\n\n    def __call__(self, image, target):\n        image = self.trans(image)\n        return image, target\n\n\nclass Normalization(object):\n    \"\"\"对图像标准化处理,该方法应放在ToTensor后\"\"\"\n    def __init__(self, mean=None, std=None):\n        if mean is None:\n            mean = [0.50599086, 0.5436684, 0.57830775]\n        if std is None:\n            std = [0.25552753, 0.24381228, 0.26706386]\n        self.normalize = t.Normalize(mean=mean, std=std)\n\n    def __call__(self, image, target):\n        image = self.normalize(image)\n        return image, target\n\n\nclass AssignGTtoDefaultBox(object):\n    \"\"\" 将 DefaultBox 与 GT进行匹配 \"\"\"\n    def __init__(self):\n        self.default_box = dboxes300_coco()\n        self.encoder = Encoder(self.default_box)\n\n    def __call__(self, image, target):\n        boxes = target['boxes']\n        labels = target[\"labels\"]\n        # bboxes_out (Tensor 8732 x 4), labels_out (Tensor 8732)\n        bboxes_out, labels_out = self.encoder.encode(boxes, labels)\n        target['boxes'] = bboxes_out\n        target['labels'] = labels_out\n        return image, target","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.736604Z","iopub.execute_input":"2023-02-13T08:37:10.737065Z","iopub.status.idle":"2023-02-13T08:37:10.766785Z","shell.execute_reply.started":"2023-02-13T08:37:10.737028Z","shell.execute_reply":"2023-02-13T08:37:10.765760Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# plot_curv.py\n\nimport datetime\nimport matplotlib.pyplot as plt\n\n\ndef plot_loss_and_lr(train_loss, learning_rate):\n    try:\n        x = list(range(len(train_loss)))\n        fig, ax1 = plt.subplots(1, 1)\n        ax1.plot(x, train_loss, 'r', label='loss')\n        ax1.set_xlabel(\"epoch\")\n        ax1.set_ylabel(\"loss\")\n        ax1.set_title(\"Train Loss and lr\")\n        plt.legend(loc='best')\n\n        ax2 = ax1.twinx()\n        ax2.plot(x, learning_rate, label='lr')\n        ax2.set_ylabel(\"learning rate\")\n        ax2.set_xlim(0, len(train_loss))  # 设置横坐标整数间隔\n        plt.legend(loc='best')\n\n        handles1, labels1 = ax1.get_legend_handles_labels()\n        handles2, labels2 = ax2.get_legend_handles_labels()\n        plt.legend(handles1 + handles2, labels1 + labels2, loc='upper right')\n\n        fig.subplots_adjust(right=0.8)  # 防止出现保存图片显示不全的情况\n        fig.savefig('./loss_and_lr{}.png'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n        plt.close()\n        print(\"successful save loss curve! \")\n    except Exception as e:\n        print(e)\n\n\ndef plot_map(mAP):\n    try:\n        x = list(range(len(mAP)))\n        plt.plot(x, mAP, label='mAp')\n        plt.xlabel('epoch')\n        plt.ylabel('mAP')\n        plt.title('Eval mAP')\n        plt.xlim(0, len(mAP))\n        plt.legend(loc='best')\n        plt.savefig('./mAP.png')\n        plt.close()\n        print(\"successful save mAP curve!\")\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T08:37:10.768417Z","iopub.execute_input":"2023-02-13T08:37:10.768782Z","iopub.status.idle":"2023-02-13T08:37:10.781812Z","shell.execute_reply.started":"2023-02-13T08:37:10.768742Z","shell.execute_reply":"2023-02-13T08:37:10.780841Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# train_ssd300.py\n\nimport os\nimport datetime\n\nimport torch\n\n# import transforms\n# from my_dataset import AirCraftDataSet\n# from src import SSD300, Backbone\n# import train_utils.train_eval_utils as utils\n# from train_utils import get_coco_api_from_dataset\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# from my_dataset import ANNOTATION_FILE_TYPE\n\nTRAIN_FILE = \"train.txt\"\nVAL_FILE = \"val.txt\"\n\ndef create_model(num_classes=41):\n    # pre_train_path = \"./src/resnet50.pth\"\n\n    # 先构建一个 backbone\n    backbone = Backbone()\n\n    # 再构建一个SSD300\n    model = SSD300(backbone=backbone, num_classes=num_classes)\n\n    pre_ssd_path = \"/kaggle/input/nvidia-ssdpyt-fp32-190826pt/nvidia_ssdpyt_fp32_190826.pt\"\n    if not os.path.exists(pre_ssd_path):\n        raise FileNotFoundError(\"nvidia_ssdpyt_fp32.pt not find in {}\".format(pre_ssd_path))\n    pre_model_dict = torch.load(pre_ssd_path, map_location='cpu')\n    pre_weights_dict = pre_model_dict[\"model\"]\n\n    # 删除类别预测器权重，注意，回归预测器的权重可以重用，因为不涉及num_classes\n    del_conf_loc_dict = {}\n    for k, v in pre_weights_dict.items():\n        split_key = k.split(\".\")\n        if \"conf\" in split_key:\n            continue\n        del_conf_loc_dict.update({k: v})\n\n    missing_keys, unexpected_keys = model.load_state_dict(del_conf_loc_dict, strict=False)\n    if len(missing_keys) != 0 or len(unexpected_keys) != 0:\n        print(\"missing_keys: \", missing_keys)\n        print(\"unexpected_keys: \", unexpected_keys)\n\n    return model\n\ndef getInvalidImage(img_dir):\n    print(\"getInvalidImage\")\n    invalid_csv_files = []\n    all_jpg_file_lists = [file for file in os.listdir(img_dir) if os.path.splitext(file)[-1] == IMAGE_TYPE]\n\n    for jpg_file in all_jpg_file_lists:\n        csv_file = os.path.splitext(jpg_file)[0] + ANNOTATION_FILE_TYPE\n        csv_file_path = os.path.join(img_dir, csv_file)\n        try:\n            img_file = os.path.join(img_dir, jpg_file)\n            image = Image.open(img_file)\n        except:\n            print(f\"Open {img_file} failed\")\n            if os.path.exists(csv_file_path):\n                invalid_csv_files.append(csv_file)\n            continue\n\n        if image.format != \"JPEG\" and image.format != \"MPO\":\n            print(f\"Image '{img_file}' format not JPEG\")\n            if os.path.exists(csv_file_path):\n                invalid_csv_files.append(csv_file)\n            continue\n\n        if image.mode != \"RGB\":\n            print(f\"Image {img_file} format not RGB, but {image.mode}\")\n            if image.mode != \"RGB\" and os.path.exists(csv_file_path):\n                invalid_csv_files.append(csv_file)\n            continue\n            \n        with open(file=csv_file_path, mode=\"r\", encoding=\"utf8\") as fid:\n            # Ignore the first line(field title)\n            fid.readline()\n            while True:\n                csv_line = fid.readline()\n                if not csv_line:\n                    break\n\n                csv_line_content = csv_line.strip().split(sep=\",\")\n                if len(csv_line_content) < CSV_FIELD_COUNT:\n                    # Not satisfy annotation format\n                    print(f\"{csv_file} field count({len(csv_line_content)}) less than {CSV_FIELD_COUNT}\")\n                    invalid_csv_files.append(csv_file)\n                    break\n\n                if csv_line_content[CSV_FIELD_CLASS_INDEX].strip() == \"C2\":\n                    print(f\"{csv_file}'s type is C2, invalid\")\n                    invalid_csv_files.append(csv_file)\n                    break\n\n    return invalid_csv_files\n\n\ndef preDealDatasetIfNecessary(img_root, train_file_ratio, annotation_root):\n    # check image root\n    img_dir = os.path.join(img_root, \"dataset\")\n    if not os.path.exists(img_dir):\n        raise FileNotFoundError(\"Image dataset dose not in path:'{}'.\".format(img_dir))\n\n    if os.path.exists(TRAIN_FILE) and os.path.exists(VAL_FILE):\n        print(f\"{TRAIN_FILE} and {VAL_FILE} are both exist.\")\n        return\n\n    if not os.path.exists(annotation_root):\n        os.mkdir(annotation_root)\n\n    invalid_csv_files = getInvalidImage(img_dir)\n    invalid_csv_files_count = len(invalid_csv_files)\n\n    print(f\"{TRAIN_FILE} or/and {VAL_FILE} are not all exist\")\n\n    all_csv_file_lists = [file for file in os.listdir(img_dir) if os.path.splitext(file)[-1] == ANNOTATION_FILE_TYPE]\n    csv_file_count = len(all_csv_file_lists)\n    assert csv_file_count > 0, \"No csv file\"\n\n    valid_csv_files_count = csv_file_count - invalid_csv_files_count\n    assert valid_csv_files_count > 0, \"No valid csv file\"\n\n    train_count = (int) (valid_csv_files_count * (train_file_ratio if 0 < train_file_ratio < 1 else .8) + .5);\n    assert train_count < valid_csv_files_count, f\"train_count({train_count}) >= valid_csv_files_count({valid_csv_files_count})\"\n    csv_files = np.array(all_csv_file_lists)\n    csv_files = np.sort(csv_files, axis=0)\n\n    # csv_files = torch.tensor(all_csv_file_lists);\n    # csv_files = csv_files.sort(dim=-1, descending=False)\n    # 拆分训练集和验证集，并写入文件\n    index = 0\n    train_file = os.path.join(annotation_root, TRAIN_FILE)\n    with open(train_file, mode=\"w\", encoding=\"utf8\") as f:\n        count = 0\n        while index < valid_csv_files_count and count < train_count:\n            if csv_files[index] in invalid_csv_files:\n                index += 1\n                continue\n            f.write(csv_files[index] + \"\\n\")\n            count += 1\n            index += 1\n        f.flush()\n\n    assert index < valid_csv_files_count - 1, f\"index({index} >= valid_csv_files_count({valid_csv_files_count}) - 1)\"\n\n    val_file = os.path.join(annotation_root, VAL_FILE)\n    with open(val_file, mode=\"w\", encoding=\"utf8\") as f:\n        for csv_file in csv_files[index:]:\n            if csv_file in invalid_csv_files:\n                continue\n            f.write(csv_file + \"\\n\")\n        f.flush()\n\n    print(\"Finish splitting train and val dataset\")\n\ndef main(parser_data):\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    # 保存训练完成之后的权重\n    if not os.path.exists(\"save_weights\"):\n        os.mkdir(\"save_weights\")\n\n\n    # 定义一个结果文件\n    results_file = \"results{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n    \"\"\"\n        1，数据读取后的处理工作\n            - 类型转换\n            - 数据增强\n    \"\"\"\n\n    data_transform = {\n        \"train\": Compose([SSDCropping(), # 图像切割\n                         Resize(),   # 统一大小\n                         ColorJitter(), # 颜色抖动\n                         ToTensor(),  # 转张量\n                         RandomHorizontalFlip(), # 水平翻转\n                         Normalization(), # 标准化\n                         AssignGTtoDefaultBox()]), # 处理目标框和锚框\n\n        \"val\": Compose([Resize(),\n                        ToTensor(),\n                        Normalization()])\n    }\n\n    img_root = parser_data.data_path\n    annotations_root = \"./\"\n    preDealDatasetIfNecessary(img_root, parser_data.train_file_ratio, annotations_root)\n\n    train_dataset = AirCraftDataSet(img_root, annotations_root, data_transform['train'], train_set=TRAIN_FILE)\n\n    # 注意训练时，batch_size必须大于1\n    batch_size = parser_data.batch_size\n\n    assert batch_size > 1, \"batch size must be greater than 1\"\n\n    # 防止最后一个batch_size=1，如果最后一个batch_size=1就舍去\n    drop_last = True if len(train_dataset) % batch_size == 1 else False\n\n    # 数据预处理多少线程\n    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n    train_data_loader = DataLoader(train_dataset,\n                                   batch_size=batch_size,\n                                   shuffle=True,\n                                   num_workers=nw,\n                                   collate_fn=train_dataset.collate_fn,\n                                   drop_last=drop_last)\n\n    val_dataset = AirCraftDataSet(img_root, annotations_root, data_transform['val'], train_set=VAL_FILE)\n    val_data_loader = torch.utils.data.DataLoader(val_dataset,\n                                                  batch_size=batch_size,\n                                                  shuffle=False,\n                                                  num_workers=nw,\n                                                  collate_fn=train_dataset.collate_fn)\n    # 定义模型\n    model = create_model(num_classes=args.num_classes + 1)\n    model.to(device)\n\n    # 定义优化器\n    params = [p for p in model.parameters() if p.requires_grad]\n    optimizer = torch.optim.SGD(params=params, lr=0.01,\n                                momentum=0.9, weight_decay=0.0005)\n    # 学习率调度器\n    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,\n                                                   step_size=10,\n                                                   gamma=0.9)\n\n    # 如果指定了上次训练保存的权重文件地址，则接着上次结果接着训练\n    if parser_data.resume != \"\":\n        checkpoint = torch.load(parser_data.resume, map_location='cpu')\n        model.load_state_dict(checkpoint['model'])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n        parser_data.start_epoch = checkpoint['epoch'] + 1\n        print(\"the training process from epoch{}...\".format(parser_data.start_epoch))\n\n    train_loss = []\n    learning_rate = []\n    val_map = []\n\n    # 提前加载验证集数据，以免每次验证时都要重新加载一次数据，节省时间\n    val_data = get_coco_api_from_dataset(val_data_loader.dataset)\n\n    for epoch in range(parser_data.start_epoch, parser_data.epochs):\n        mean_loss, lr = train_one_epoch(model=model, optimizer=optimizer,\n                                        data_loader=train_data_loader,\n                                        device=device, epoch=epoch,\n                                        print_freq=20)\n        train_loss.append(mean_loss.item())\n        learning_rate.append(lr)\n\n        # 更新学习率\n        lr_scheduler.step()\n\n        # 测试数据\n        coco_info = evaluate(model=model, data_loader=val_data_loader,\n                             device=device, data_set=val_data)\n\n        # write into txt\n        with open(results_file, \"a\") as f:\n            # 写入的数据包括coco指标还有loss和learning rate\n            result_info = [str(round(i, 4)) for i in coco_info + [mean_loss.item()]] + [str(round(lr, 6))]\n            txt = \"epoch:{} {}\".format(epoch, '  '.join(result_info))\n            f.write(txt + \"\\n\")\n\n        val_map.append(coco_info[1])  # pascal mAP\n\n        # save weights\n        save_files = {\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'lr_scheduler': lr_scheduler.state_dict(),\n            'epoch': epoch}\n        torch.save(save_files, \"./save_weights/ssd300-{}.pth\".format(epoch))\n\n    # plot loss and lr curve\n    if len(train_loss) != 0 and len(learning_rate) != 0:\n        plot_loss_and_lr(train_loss, learning_rate)\n\n    # plot mAP curve\n    if len(val_map) != 0:\n        plot_map(val_map)\n\n    # inputs = torch.rand(size=(2, 3, 300, 300))\n    # output = model(inputs)\n    # print(output)\n\n\nif __name__ == '__main__':\n\n    import argparse\n\n    parser = argparse.ArgumentParser(description=__doc__)\n\n    # 检测的目标类别个数，不包括背景(替换：自己的检测类别)\n    parser.add_argument('--num_classes', default=40, type=int, help='num_classes')\n    # 训练数据集的根目录 \n    parser.add_argument('--data_path', default='/kaggle/input/militaryaircraftdetectiondataset', help='dataset')\n    # 文件保存地址\n    parser.add_argument('--output-dir', default='./save_weights', help='path where to save')\n    # 若需要接着上次训练，则指定上次训练保存权重文件地址 ./save_weights/ssd300-12.pth /kaggle/input/ssd300-14/ssd300-14.pth\n    parser.add_argument('--resume', default='./save_weights/ssd300-231.pth', type=str, help='resume from checkpoint')\n    # 指定接着从哪个epoch数开始训练\n    parser.add_argument('--start_epoch', default=232, type=int, help='start epoch')\n    # 训练的总epoch数\n    parser.add_argument('--epochs', default=250, type=int, metavar='N',\n                        help='number of total epochs to run')\n    # 训练的batch size\n    parser.add_argument('--batch_size', default=30, type=int, metavar='N',\n                        help='batch size when training.')\n\n    parser.add_argument('--train_file_ratio', default=0.8, type=float, help='Train files ratio')\n\n    args = parser.parse_args(args=[])\n\n    # 检查保存权重文件夹是否存在，不存在则创建\n    if not os.path.exists(args.output_dir):\n        os.makedirs(args.output_dir)\n\n    main(args)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-13T08:37:10.783600Z","iopub.execute_input":"2023-02-13T08:37:10.784210Z","iopub.status.idle":"2023-02-13T12:36:00.750428Z","shell.execute_reply.started":"2023-02-13T08:37:10.784148Z","shell.execute_reply":"2023-02-13T12:36:00.749234Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"train.txt and val.txt are both exist.\nmissing_keys:  ['conf.0.weight', 'conf.0.bias', 'conf.1.weight', 'conf.1.bias', 'conf.2.weight', 'conf.2.bias', 'conf.3.weight', 'conf.3.bias', 'conf.4.weight', 'conf.4.bias', 'conf.5.weight', 'conf.5.bias', 'compute_loss.dboxes', 'postprocess.dboxes_xywh']\nunexpected_keys:  []\nthe training process from epoch232...\ncreating index...\nindex created!\nEpoch: [232]  [  0/268]  eta: 0:58:04.794293  lr: 0.000886  total_losses: 1.1766 (1.1766) hist: [1.18]  time: 13.0030  data: 6.4760  max mem: 7723\nEpoch: [232]  [ 20/268]  eta: 0:11:48.142783  lr: 0.000886  total_losses: 0.6363 (0.8574) hist: [0.69 0.71 0.74 0.59 0.77 0.60 1.16 0.66 0.79 0.67 1.65 0.86 0.73 0.56 1.27 0.81 0.72 1.13 1.09 0.64]  time: 2.3480  data: 1.8186  max mem: 7771\nEpoch: [232]  [ 40/268]  eta: 0:10:19.515577  lr: 0.000886  total_losses: 0.9658 (0.8272) hist: [0.60 1.08 0.61 1.09 0.66 0.73 0.65 0.89 0.88 0.71 0.79 0.65 0.66 1.04 0.91 0.66 0.98 0.66 0.70 0.97]  time: 2.5720  data: 2.0460  max mem: 7771\nEpoch: [232]  [ 60/268]  eta: 0:09:17.935082  lr: 0.000886  total_losses: 0.6619 (0.8337) hist: [0.78 1.13 0.70 0.88 0.61 0.96 0.88 1.27 0.84 0.96 0.87 0.75 0.69 0.83 0.73 0.94 0.76 0.81 0.88 0.66]  time: 2.6111  data: 2.0986  max mem: 7771\nEpoch: [232]  [ 80/268]  eta: 0:08:16.759967  lr: 0.000886  total_losses: 0.6531 (0.8177) hist: [0.50 1.08 0.68 0.96 0.81 0.66 0.90 0.50 0.63 0.73 0.64 1.25 0.77 0.67 1.08 0.65 0.98 0.73 0.50 0.65]  time: 2.5202  data: 2.0032  max mem: 7771\nEpoch: [232]  [100/268]  eta: 0:07:13.028525  lr: 0.000886  total_losses: 0.6853 (0.8275) hist: [0.56 1.30 1.17 0.60 0.91 0.56 0.75 0.71 1.25 0.79 1.18 0.72 0.56 0.76 1.00 0.73 0.93 1.61 0.58 0.69]  time: 2.3152  data: 1.7887  max mem: 7771\nEpoch: [232]  [120/268]  eta: 0:06:22.657266  lr: 0.000886  total_losses: 1.0510 (0.8375) hist: [1.18 0.73 1.15 0.92 1.04 0.63 0.68 1.20 0.96 0.99 0.62 1.18 0.52 0.57 1.17 0.69 0.84 0.89 0.74 1.05]  time: 2.6258  data: 2.1043  max mem: 7771\nEpoch: [232]  [140/268]  eta: 0:05:31.366655  lr: 0.000886  total_losses: 0.6895 (0.8336) hist: [0.97 0.73 0.76 0.59 0.99 0.89 0.84 0.96 0.60 0.68 0.93 0.79 0.88 0.93 0.80 0.72 1.03 0.77 0.65 0.69]  time: 2.6086  data: 2.0857  max mem: 7771\nEpoch: [232]  [160/268]  eta: 0:04:40.633265  lr: 0.000886  total_losses: 0.8644 (0.8388) hist: [1.16 0.89 0.84 0.74 0.64 0.70 0.87 0.80 0.52 0.86 0.72 1.35 0.92 0.82 0.82 1.10 1.02 0.65 1.23 0.86]  time: 2.6665  data: 2.1399  max mem: 7771\nEpoch: [232]  [180/268]  eta: 0:03:47.842163  lr: 0.000886  total_losses: 0.6583 (0.8363) hist: [1.02 1.08 0.94 0.58 0.52 0.86 0.82 0.84 0.74 0.89 0.71 0.77 0.86 0.70 0.92 0.68 0.96 0.73 1.06 0.66]  time: 2.5139  data: 1.9807  max mem: 7771\nEpoch: [232]  [200/268]  eta: 0:02:55.646917  lr: 0.000886  total_losses: 0.7392 (0.8359) hist: [1.14 0.76 0.71 0.71 0.75 0.52 0.49 0.86 0.88 0.90 0.99 0.89 0.93 0.98 0.99 0.88 1.10 0.66 0.75 0.74]  time: 2.5281  data: 2.0023  max mem: 7771\nEpoch: [232]  [220/268]  eta: 0:02:04.209485  lr: 0.000886  total_losses: 0.9040 (0.8411) hist: [0.98 1.06 0.88 0.81 0.93 0.70 1.13 0.71 0.92 1.10 0.71 0.75 0.91 1.02 0.60 0.91 0.95 0.97 0.94 0.90]  time: 2.6345  data: 2.1002  max mem: 7771\nEpoch: [232]  [240/268]  eta: 0:01:12.301595  lr: 0.000886  total_losses: 0.4997 (0.8448) hist: [0.89 0.58 0.82 0.70 1.25 1.03 0.98 1.09 0.65 1.11 0.95 0.87 0.97 0.90 0.94 1.05 0.79 0.66 0.97 0.50]  time: 2.5214  data: 1.9849  max mem: 7771\nEpoch: [232]  [260/268]  eta: 0:00:20.597672  lr: 0.000886  total_losses: 0.7948 (0.8464) hist: [0.82 0.80 1.22 1.14 0.66 0.76 0.68 0.99 0.81 0.72 1.25 1.00 0.79 0.58 0.65 0.92 0.82 0.89 1.03 0.79]  time: 2.4844  data: 1.9463  max mem: 7771\nEpoch: [232]  [267/268]  eta: 0:00:02.562844  lr: 0.000886  total_losses: 0.7879 (0.8475) hist: [0.99 0.81 0.72 1.25 1.00 0.79 0.58 0.65 0.92 0.82 0.89 1.03 0.79 0.80 0.76 0.87 1.10 1.06 0.85 0.79]  time: 2.3607  data: 1.8429  max mem: 7771\nEpoch: [232] Total time: 0:11:26 (2.5632 s / it)\nTest:   [ 0/67]  eta: 0:06:26.917451  model_time: 0.2145 (0.2145) hist: [0.21]  evaluator_time: 0.0531 (0.0531) hist: [0.05]  time: 5.7749  data: 5.4481  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.403826  model_time: 0.1462 (0.1812) hist: [0.21 0.17 0.17 0.17 0.17 0.20 0.17 0.18 0.18 0.17 0.18 0.17 0.18 0.17 0.18 0.19 0.19 0.18 0.16 0.15]  evaluator_time: 0.0253 (0.0761) hist: [0.11 0.06 0.04 0.09 0.17 0.12 0.06 0.05 0.29 0.06 0.04 0.04 0.05 0.09 0.06 0.07 0.11 0.06 0.03 0.03]  time: 2.3012  data: 2.0037  max mem: 7771\nTest:  Total time: 0:02:41 (2.4048 s / it)\nAveraged stats: model_time: 0.1462 (0.1812) hist: [0.21 0.17 0.17 0.17 0.17 0.20 0.17 0.18 0.18 0.17 0.18 0.17 0.18 0.17 0.18 0.19 0.19 0.18 0.16 0.15]  evaluator_time: 0.0253 (0.0761) hist: [0.11 0.06 0.04 0.09 0.17 0.12 0.06 0.05 0.29 0.06 0.04 0.04 0.05 0.09 0.06 0.07 0.11 0.06 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.87s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\nEpoch: [233]  [  0/268]  eta: 0:27:42.770846  lr: 0.000886  total_losses: 1.0636 (1.0636) hist: [1.06]  time: 6.2044  data: 5.6620  max mem: 7771\nEpoch: [233]  [ 20/268]  eta: 0:10:31.921008  lr: 0.000886  total_losses: 0.9056 (0.9144) hist: [0.92 0.78 0.88 0.75 0.65 0.79 1.34 0.86 0.96 0.90 0.91 0.61 1.15 0.97 0.79 0.69 1.08 1.14 1.07 0.91]  time: 2.3653  data: 1.8484  max mem: 7771\nEpoch: [233]  [ 40/268]  eta: 0:09:36.514905  lr: 0.000886  total_losses: 1.1678 (0.8840) hist: [0.76 1.01 0.96 0.76 1.04 0.66 1.09 0.97 0.62 1.20 0.69 1.17 0.70 0.85 0.86 0.65 0.49 0.86 0.53 1.17]  time: 2.5081  data: 1.9932  max mem: 7771\nEpoch: [233]  [ 60/268]  eta: 0:08:38.467736  lr: 0.000886  total_losses: 0.7816 (0.8696) hist: [0.90 0.61 0.79 0.81 0.58 0.95 0.92 1.02 1.23 0.75 0.47 0.82 1.03 0.90 0.69 1.13 1.05 0.58 0.81 0.78]  time: 2.4190  data: 1.9010  max mem: 7771\nEpoch: [233]  [ 80/268]  eta: 0:07:43.610825  lr: 0.000886  total_losses: 0.8013 (0.8654) hist: [1.09 0.75 0.62 0.66 0.62 0.93 0.84 0.62 0.55 1.05 1.06 1.13 0.68 1.25 0.90 0.89 0.88 0.67 1.06 0.80]  time: 2.3848  data: 1.8760  max mem: 7771\nEpoch: [233]  [100/268]  eta: 0:06:51.640327  lr: 0.000886  total_losses: 0.7945 (0.8517) hist: [0.66 1.09 0.51 0.78 0.84 0.99 0.79 0.92 0.56 0.63 0.75 0.76 0.73 0.70 0.77 1.16 0.56 0.82 1.10 0.79]  time: 2.3864  data: 1.8825  max mem: 7771\nEpoch: [233]  [120/268]  eta: 0:05:58.378452  lr: 0.000886  total_losses: 1.1900 (0.8558) hist: [0.85 0.87 0.70 0.70 0.63 0.60 0.93 0.95 0.95 1.00 0.84 0.86 0.87 1.03 0.97 1.16 0.81 0.85 0.79 1.19]  time: 2.2762  data: 1.7664  max mem: 7771\nEpoch: [233]  [140/268]  eta: 0:05:12.760866  lr: 0.000886  total_losses: 0.9843 (0.8574) hist: [0.94 1.01 0.85 0.99 0.72 0.84 0.73 0.65 0.75 0.57 1.04 1.21 1.10 0.70 0.69 1.05 0.80 0.70 1.01 0.98]  time: 2.5764  data: 2.0652  max mem: 7771\nEpoch: [233]  [160/268]  eta: 0:04:25.510385  lr: 0.000886  total_losses: 1.0943 (0.8484) hist: [0.47 0.82 0.79 1.20 0.55 0.64 0.94 0.71 0.61 1.14 0.76 0.67 0.65 0.63 0.82 0.80 0.70 0.75 1.00 1.09]  time: 2.5641  data: 2.0519  max mem: 7771\nEpoch: [233]  [180/268]  eta: 0:03:37.520206  lr: 0.000886  total_losses: 0.7480 (0.8486) hist: [0.80 0.74 0.41 0.90 0.74 0.90 0.80 0.70 0.98 0.65 0.94 0.83 1.10 0.90 0.96 1.52 1.06 0.62 0.73 0.75]  time: 2.5796  data: 2.0634  max mem: 7771\nEpoch: [233]  [200/268]  eta: 0:02:47.418170  lr: 0.000886  total_losses: 0.9654 (0.8453) hist: [0.62 0.82 0.72 1.07 0.91 0.85 0.56 0.67 0.72 0.68 0.73 0.68 0.71 0.97 0.88 0.83 0.95 0.90 1.07 0.97]  time: 2.3734  data: 1.8710  max mem: 7771\nEpoch: [233]  [220/268]  eta: 0:01:56.925029  lr: 0.000886  total_losses: 0.7401 (0.8480) hist: [0.77 0.72 0.52 0.96 0.81 1.28 0.65 0.78 1.15 0.75 1.43 0.90 0.60 0.79 0.91 0.83 0.98 0.79 1.14 0.74]  time: 2.1737  data: 1.6624  max mem: 7771\nEpoch: [233]  [240/268]  eta: 0:01:08.127243  lr: 0.000886  total_losses: 0.5509 (0.8498) hist: [0.78 0.79 0.78 0.57 0.91 1.14 1.04 0.62 1.33 1.02 0.63 0.91 1.30 0.81 0.66 0.95 0.87 0.99 0.75 0.55]  time: 2.4019  data: 1.8902  max mem: 7771\nEpoch: [233]  [260/268]  eta: 0:00:19.366370  lr: 0.000886  total_losses: 0.9042 (0.8473) hist: [0.66 0.92 0.82 0.55 0.95 0.59 0.96 0.76 0.78 0.85 0.68 0.99 0.91 0.96 1.01 0.72 0.68 0.89 0.76 0.90]  time: 2.2723  data: 1.7665  max mem: 7771\nEpoch: [233]  [267/268]  eta: 0:00:02.421216  lr: 0.000886  total_losses: 0.7291 (0.8484) hist: [0.76 0.78 0.85 0.68 0.99 0.91 0.96 1.01 0.72 0.68 0.89 0.76 0.90 0.60 0.77 0.86 1.18 0.99 1.09 0.73]  time: 2.4410  data: 1.9476  max mem: 7771\nEpoch: [233] Total time: 0:10:49 (2.4217 s / it)\nTest:   [ 0/67]  eta: 0:06:23.685694  model_time: 0.1810 (0.1810) hist: [0.18]  evaluator_time: 0.0580 (0.0580) hist: [0.06]  time: 5.7267  data: 5.4197  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.310497  model_time: 0.1444 (0.1811) hist: [0.18 0.17 0.19 0.17 0.19 0.17 0.17 0.19 0.17 0.19 0.17 0.20 0.20 0.20 0.20 0.20 0.17 0.17 0.16 0.14]  evaluator_time: 0.0275 (0.0884) hist: [0.13 0.06 0.24 0.06 0.07 0.09 0.07 0.07 0.06 0.13 0.04 0.09 0.09 0.12 0.07 0.07 0.06 0.06 0.03 0.03]  time: 2.2033  data: 1.8910  max mem: 7771\nTest:  Total time: 0:02:34 (2.3118 s / it)\nAveraged stats: model_time: 0.1444 (0.1811) hist: [0.18 0.17 0.19 0.17 0.19 0.17 0.17 0.19 0.17 0.19 0.17 0.20 0.20 0.20 0.20 0.20 0.17 0.17 0.16 0.14]  evaluator_time: 0.0275 (0.0884) hist: [0.13 0.06 0.24 0.06 0.07 0.09 0.07 0.07 0.06 0.13 0.04 0.09 0.09 0.12 0.07 0.07 0.06 0.06 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.85s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.567\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\nEpoch: [234]  [  0/268]  eta: 0:23:04.002040  lr: 0.000886  total_losses: 0.7558 (0.7558) hist: [0.76]  time: 5.1642  data: 4.6663  max mem: 7771\nEpoch: [234]  [ 20/268]  eta: 0:09:58.521790  lr: 0.000886  total_losses: 0.9050 (0.7487) hist: [0.97 0.55 0.73 0.76 0.75 0.81 0.71 0.69 0.61 0.84 0.71 0.72 0.75 0.71 0.62 0.83 0.57 0.91 0.84 0.90]  time: 2.2759  data: 1.7655  max mem: 7771\nEpoch: [234]  [ 40/268]  eta: 0:09:11.370495  lr: 0.000886  total_losses: 0.7098 (0.8145) hist: [1.69 0.84 0.77 0.68 0.75 1.05 1.04 0.74 0.91 0.79 1.00 0.88 0.68 0.88 0.70 0.97 0.97 1.06 0.58 0.71]  time: 2.4234  data: 1.9196  max mem: 7771\nEpoch: [234]  [ 60/268]  eta: 0:08:21.021100  lr: 0.000886  total_losses: 0.7761 (0.8042) hist: [0.74 0.74 0.71 0.78 1.10 0.69 0.65 0.68 0.43 0.68 1.04 0.65 0.87 1.03 0.83 0.77 0.87 0.79 0.86 0.78]  time: 2.3892  data: 1.8700  max mem: 7771\nEpoch: [234]  [ 80/268]  eta: 0:07:33.157009  lr: 0.000886  total_losses: 0.7893 (0.8013) hist: [0.66 1.03 0.92 0.74 0.99 0.83 0.79 0.76 0.59 0.70 1.27 0.43 0.76 0.74 0.89 0.56 0.66 0.83 0.90 0.79]  time: 2.4155  data: 1.9137  max mem: 7771\nEpoch: [234]  [100/268]  eta: 0:06:44.811298  lr: 0.000886  total_losses: 0.8117 (0.8072) hist: [0.95 0.57 0.58 0.46 0.85 0.71 0.73 1.44 0.82 0.74 1.07 0.98 0.88 0.98 0.67 0.83 0.96 0.74 0.85 0.81]  time: 2.4063  data: 1.8972  max mem: 7771\nEpoch: [234]  [120/268]  eta: 0:06:01.018817  lr: 0.000886  total_losses: 0.6106 (0.8231) hist: [0.84 0.80 1.27 1.08 0.89 0.91 1.39 0.77 0.96 1.14 0.78 0.88 0.82 0.89 0.88 0.79 0.60 0.70 1.08 0.61]  time: 2.5894  data: 2.0687  max mem: 7771\nEpoch: [234]  [140/268]  eta: 0:05:15.139774  lr: 0.000886  total_losses: 1.2047 (0.8324) hist: [1.15 1.11 0.88 1.22 0.95 0.56 1.10 0.73 1.03 0.66 0.74 0.55 0.91 0.77 0.62 0.91 1.04 0.75 0.89 1.20]  time: 2.5994  data: 2.0875  max mem: 7771\nEpoch: [234]  [160/268]  eta: 0:04:29.585530  lr: 0.000886  total_losses: 0.8689 (0.8333) hist: [0.80 0.67 0.58 0.98 0.59 1.07 0.67 1.01 1.00 0.56 0.66 0.84 0.78 0.96 0.89 0.97 1.08 0.89 0.92 0.87]  time: 2.7368  data: 2.2239  max mem: 7771\nEpoch: [234]  [180/268]  eta: 0:03:40.695163  lr: 0.000886  total_losses: 0.9931 (0.8348) hist: [1.08 0.58 0.84 0.63 1.01 0.84 0.91 0.88 0.70 1.31 0.63 0.94 1.04 0.93 0.69 0.63 0.81 0.53 0.97 0.99]  time: 2.6024  data: 2.0863  max mem: 7771\nEpoch: [234]  [200/268]  eta: 0:02:50.895989  lr: 0.000886  total_losses: 0.7933 (0.8289) hist: [1.00 0.68 0.81 0.53 0.73 0.86 0.90 0.70 1.14 0.49 0.99 0.97 0.64 0.40 0.68 0.62 0.70 1.10 0.78 0.79]  time: 2.5609  data: 2.0422  max mem: 7771\nEpoch: [234]  [220/268]  eta: 0:02:01.535644  lr: 0.000886  total_losses: 0.8695 (0.8301) hist: [1.13 0.85 0.98 0.74 0.67 0.95 0.73 0.92 0.83 0.65 0.56 0.66 1.20 0.97 0.76 0.56 0.79 0.78 1.24 0.87]  time: 2.7211  data: 2.2123  max mem: 7771\nEpoch: [234]  [240/268]  eta: 0:01:11.199318  lr: 0.000886  total_losses: 1.2061 (0.8356) hist: [1.14 0.74 0.57 1.08 0.82 0.67 0.76 0.88 0.72 0.94 0.75 0.80 1.20 1.03 0.88 0.78 0.82 0.70 1.45 1.21]  time: 2.6626  data: 2.1394  max mem: 7771\nEpoch: [234]  [260/268]  eta: 0:00:20.321626  lr: 0.000886  total_losses: 0.7654 (0.8389) hist: [0.91 0.59 0.90 0.60 1.03 1.00 1.56 1.03 0.92 0.75 0.81 1.24 0.93 0.90 0.87 0.77 0.65 0.55 0.85 0.77]  time: 2.5085  data: 1.9951  max mem: 7771\nEpoch: [234]  [267/268]  eta: 0:00:02.528774  lr: 0.000886  total_losses: 0.4795 (0.8381) hist: [1.03 0.92 0.75 0.81 1.24 0.93 0.90 0.87 0.77 0.65 0.55 0.85 0.77 0.85 0.99 0.93 0.63 0.73 1.03 0.48]  time: 2.2826  data: 1.7886  max mem: 7771\nEpoch: [234] Total time: 0:11:17 (2.5295 s / it)\nTest:   [ 0/67]  eta: 0:06:30.920706  model_time: 0.1721 (0.1721) hist: [0.17]  evaluator_time: 0.0598 (0.0598) hist: [0.06]  time: 5.8346  data: 5.5330  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.289963  model_time: 0.1511 (0.1847) hist: [0.20 0.20 0.17 0.20 0.17 0.26 0.17 0.20 0.19 0.20 0.17 0.17 0.19 0.20 0.19 0.18 0.17 0.17 0.18 0.15]  evaluator_time: 0.0400 (0.0818) hist: [0.10 0.10 0.22 0.09 0.06 0.13 0.06 0.05 0.07 0.09 0.04 0.07 0.09 0.05 0.05 0.04 0.10 0.06 0.05 0.04]  time: 2.2400  data: 1.9355  max mem: 7771\nTest:  Total time: 0:02:33 (2.2926 s / it)\nAveraged stats: model_time: 0.1511 (0.1847) hist: [0.20 0.20 0.17 0.20 0.17 0.26 0.17 0.20 0.19 0.20 0.17 0.17 0.19 0.20 0.19 0.18 0.17 0.17 0.18 0.15]  evaluator_time: 0.0400 (0.0818) hist: [0.10 0.10 0.22 0.09 0.06 0.13 0.06 0.05 0.07 0.09 0.04 0.07 0.09 0.05 0.05 0.04 0.10 0.06 0.05 0.04]\nAccumulating evaluation results...\nDONE (t=0.89s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.566\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\nEpoch: [235]  [  0/268]  eta: 0:20:05.953036  lr: 0.000886  total_losses: 0.8891 (0.8891) hist: [0.89]  time: 4.4998  data: 3.9795  max mem: 7771\nEpoch: [235]  [ 20/268]  eta: 0:10:52.423989  lr: 0.000886  total_losses: 0.9216 (0.8580) hist: [0.85 0.81 1.21 0.85 0.97 0.75 0.74 1.00 1.11 0.83 0.68 0.88 0.79 0.70 1.04 0.89 0.46 1.06 0.59 0.92]  time: 2.5373  data: 2.0203  max mem: 7771\nEpoch: [235]  [ 40/268]  eta: 0:08:56.034549  lr: 0.000886  total_losses: 0.8738 (0.8331) hist: [0.93 0.53 0.84 1.13 0.50 0.71 1.12 0.62 0.84 1.11 0.90 0.74 0.56 0.57 0.83 0.61 0.68 1.06 0.98 0.87]  time: 2.0573  data: 1.5447  max mem: 7771\nEpoch: [235]  [ 60/268]  eta: 0:08:10.576668  lr: 0.000886  total_losses: 0.7454 (0.8484) hist: [0.82 0.76 0.70 0.81 1.26 1.06 1.11 0.85 1.11 0.76 0.70 0.77 0.82 0.83 1.07 0.65 1.10 0.82 0.83 0.75]  time: 2.3739  data: 1.8575  max mem: 7771\nEpoch: [235]  [ 80/268]  eta: 0:07:23.731426  lr: 0.000886  total_losses: 0.9551 (0.8330) hist: [0.90 0.74 0.68 0.86 0.79 0.91 0.53 0.68 0.62 0.97 0.70 0.85 0.65 0.64 0.91 1.02 0.84 0.72 0.76 0.96]  time: 2.3656  data: 1.8460  max mem: 7771\nEpoch: [235]  [100/268]  eta: 0:06:35.809742  lr: 0.000886  total_losses: 0.7066 (0.8415) hist: [0.82 1.33 0.80 0.81 1.07 0.69 1.46 0.94 0.88 0.68 0.70 0.70 1.03 0.71 0.74 0.78 0.94 1.01 0.71 0.71]  time: 2.3387  data: 1.8232  max mem: 7771\nEpoch: [235]  [120/268]  eta: 0:05:52.145621  lr: 0.000886  total_losses: 0.7768 (0.8405) hist: [0.69 0.68 0.70 1.44 0.89 0.83 0.98 0.85 0.77 0.68 0.76 0.97 0.57 1.07 0.67 1.09 0.61 0.86 0.83 0.78]  time: 2.4973  data: 1.9833  max mem: 7771\nEpoch: [235]  [140/268]  eta: 0:05:04.759203  lr: 0.000886  total_losses: 0.6681 (0.8452) hist: [0.98 0.72 1.02 0.73 1.10 1.00 0.81 0.95 0.67 0.90 0.80 0.67 1.18 0.85 0.78 0.92 1.21 0.74 0.76 0.67]  time: 2.3904  data: 1.8720  max mem: 7771\nEpoch: [235]  [160/268]  eta: 0:04:17.506586  lr: 0.000886  total_losses: 0.8331 (0.8437) hist: [0.81 0.75 0.90 0.75 1.03 0.77 1.02 0.91 0.74 0.87 0.84 0.77 1.07 0.75 0.85 0.64 0.70 0.89 0.77 0.83]  time: 2.4082  data: 1.8930  max mem: 7771\nEpoch: [235]  [180/268]  eta: 0:03:29.867795  lr: 0.000886  total_losses: 0.6776 (0.8409) hist: [1.05 0.92 0.73 0.79 1.02 0.87 0.60 0.89 0.95 0.82 0.75 0.84 0.64 0.59 0.58 0.98 1.12 0.76 0.82 0.68]  time: 2.3892  data: 1.8756  max mem: 7771\nEpoch: [235]  [200/268]  eta: 0:02:42.403798  lr: 0.000886  total_losses: 0.9881 (0.8387) hist: [0.99 1.20 0.74 0.50 0.50 0.66 0.54 0.65 1.44 1.07 0.92 0.72 0.79 0.85 0.68 0.62 0.89 0.80 0.83 0.99]  time: 2.4193  data: 1.9037  max mem: 7771\nEpoch: [235]  [220/268]  eta: 0:01:54.484180  lr: 0.000886  total_losses: 0.7503 (0.8379) hist: [0.68 0.70 1.10 0.72 0.66 0.90 0.88 1.09 0.92 0.62 0.83 0.59 0.75 0.98 0.90 0.72 0.90 0.95 0.97 0.75]  time: 2.3529  data: 1.8309  max mem: 7771\nEpoch: [235]  [240/268]  eta: 0:01:07.041691  lr: 0.000886  total_losses: 0.7602 (0.8412) hist: [0.96 0.69 1.07 1.31 1.10 0.68 0.76 0.56 0.77 0.91 0.98 0.84 0.55 0.77 0.69 0.96 1.17 0.96 1.07 0.76]  time: 2.4967  data: 1.9813  max mem: 7771\nEpoch: [235]  [260/268]  eta: 0:00:19.129663  lr: 0.000886  total_losses: 0.8184 (0.8367) hist: [1.02 0.71 0.44 0.69 0.85 0.54 1.02 0.81 1.03 0.82 0.75 0.66 0.72 0.53 0.69 0.93 0.90 0.68 1.04 0.82]  time: 2.3534  data: 1.8446  max mem: 7771\nEpoch: [235]  [267/268]  eta: 0:00:02.387527  lr: 0.000886  total_losses: 0.5872 (0.8384) hist: [0.81 1.03 0.82 0.75 0.66 0.72 0.53 0.69 0.93 0.90 0.68 1.04 0.82 0.59 1.07 1.11 1.03 0.94 0.99 0.59]  time: 2.4440  data: 1.9524  max mem: 7771\nEpoch: [235] Total time: 0:10:39 (2.3880 s / it)\nTest:   [ 0/67]  eta: 0:06:17.635333  model_time: 0.1979 (0.1979) hist: [0.20]  evaluator_time: 0.0973 (0.0973) hist: [0.10]  time: 5.6363  data: 5.2691  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.225901  model_time: 0.1462 (0.1860) hist: [0.20 0.18 0.17 0.17 0.24 0.27 0.19 0.18 0.18 0.20 0.18 0.19 0.19 0.19 0.17 0.19 0.20 0.20 0.16 0.15]  evaluator_time: 0.0270 (0.0908) hist: [0.10 0.09 0.25 0.08 0.19 0.16 0.06 0.05 0.05 0.11 0.05 0.09 0.08 0.10 0.08 0.08 0.08 0.14 0.03 0.03]  time: 2.1259  data: 1.8015  max mem: 7771\nTest:  Total time: 0:02:29 (2.2274 s / it)\nAveraged stats: model_time: 0.1462 (0.1860) hist: [0.20 0.18 0.17 0.17 0.24 0.27 0.19 0.18 0.18 0.20 0.18 0.19 0.19 0.19 0.17 0.19 0.20 0.20 0.16 0.15]  evaluator_time: 0.0270 (0.0908) hist: [0.10 0.09 0.25 0.08 0.19 0.16 0.06 0.05 0.05 0.11 0.05 0.09 0.08 0.10 0.08 0.08 0.08 0.14 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=1.62s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.506\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\nEpoch: [236]  [  0/268]  eta: 0:19:05.591083  lr: 0.000886  total_losses: 0.6680 (0.6680) hist: [0.67]  time: 4.2746  data: 3.7392  max mem: 7771\nEpoch: [236]  [ 20/268]  eta: 0:10:38.610385  lr: 0.000886  total_losses: 1.1968 (0.9068) hist: [0.86 0.74 0.79 0.60 1.01 1.06 1.51 0.74 0.76 0.85 0.82 1.12 0.69 1.09 0.89 0.97 0.70 1.31 0.68 1.20]  time: 2.4901  data: 1.9732  max mem: 7771\nEpoch: [236]  [ 40/268]  eta: 0:09:06.791480  lr: 0.000886  total_losses: 0.6263 (0.8619) hist: [0.59 0.62 0.83 0.83 1.24 0.78 0.86 0.89 1.10 0.69 0.77 0.79 0.86 0.78 0.67 1.04 0.69 0.89 0.73 0.63]  time: 2.2125  data: 1.6939  max mem: 7771\nEpoch: [236]  [ 60/268]  eta: 0:08:12.778378  lr: 0.000886  total_losses: 0.7313 (0.8444) hist: [0.97 0.97 1.02 0.80 0.64 0.80 0.79 0.94 1.07 0.56 0.69 0.72 0.96 0.89 0.47 0.77 1.06 0.80 0.56 0.73]  time: 2.3095  data: 1.7941  max mem: 7771\nEpoch: [236]  [ 80/268]  eta: 0:07:24.703072  lr: 0.000886  total_losses: 0.8070 (0.8410) hist: [0.92 0.67 0.67 1.23 0.55 0.84 0.58 0.92 0.98 0.87 1.03 0.75 0.85 0.66 0.62 1.12 1.30 0.54 0.72 0.81]  time: 2.3542  data: 1.8371  max mem: 7771\nEpoch: [236]  [100/268]  eta: 0:06:44.431350  lr: 0.000886  total_losses: 0.8312 (0.8264) hist: [0.54 0.54 0.96 0.93 0.64 0.62 0.61 0.84 0.73 0.59 1.12 0.66 0.71 0.83 0.82 1.03 0.68 0.81 0.84 0.83]  time: 2.5770  data: 2.0682  max mem: 7771\nEpoch: [236]  [120/268]  eta: 0:05:52.552959  lr: 0.000886  total_losses: 0.9036 (0.8325) hist: [0.58 0.70 1.14 0.80 0.86 0.93 0.76 0.75 1.18 1.10 0.79 1.10 0.56 0.91 0.79 0.77 0.58 0.81 1.25 0.90]  time: 2.2548  data: 1.7379  max mem: 7771\nEpoch: [236]  [140/268]  eta: 0:05:02.437068  lr: 0.000886  total_losses: 0.6981 (0.8264) hist: [0.70 0.86 0.80 0.81 1.11 1.14 0.64 0.63 0.87 0.51 0.97 0.72 0.73 0.79 0.79 0.53 0.92 0.69 0.89 0.70]  time: 2.2459  data: 1.7297  max mem: 7771\nEpoch: [236]  [160/268]  eta: 0:04:16.696668  lr: 0.000886  total_losses: 0.5937 (0.8263) hist: [0.71 0.50 0.90 1.25 0.87 0.84 1.39 0.57 0.54 0.93 0.92 0.78 0.85 0.60 0.65 0.64 1.56 0.78 0.68 0.59]  time: 2.4757  data: 1.9584  max mem: 7771\nEpoch: [236]  [180/268]  eta: 0:03:29.673677  lr: 0.000886  total_losses: 0.8744 (0.8215) hist: [0.96 0.77 0.72 0.92 0.58 0.80 0.79 0.94 0.92 0.72 0.60 1.24 0.63 0.58 0.65 0.72 0.77 0.65 0.81 0.87]  time: 2.4296  data: 1.9164  max mem: 7771\nEpoch: [236]  [200/268]  eta: 0:02:41.585452  lr: 0.000886  total_losses: 0.5816 (0.8167) hist: [0.50 0.67 0.98 0.96 0.69 0.88 0.94 1.14 0.99 0.72 0.77 0.77 0.56 0.72 0.93 0.67 0.83 0.56 0.62 0.58]  time: 2.3183  data: 1.8070  max mem: 7771\nEpoch: [236]  [220/268]  eta: 0:01:53.477603  lr: 0.000886  total_losses: 0.6479 (0.8169) hist: [0.77 0.81 0.89 0.64 1.08 0.86 0.98 0.93 0.80 0.67 0.55 0.85 0.46 0.88 0.80 1.10 1.01 0.86 0.78 0.65]  time: 2.2421  data: 1.7294  max mem: 7771\nEpoch: [236]  [240/268]  eta: 0:01:07.267903  lr: 0.000886  total_losses: 0.7707 (0.8162) hist: [0.58 0.78 0.71 0.95 1.01 0.87 0.91 0.61 0.63 0.96 0.67 0.65 0.61 0.99 0.67 0.94 1.31 0.75 0.80 0.77]  time: 2.8257  data: 2.3077  max mem: 7771\nEpoch: [236]  [260/268]  eta: 0:00:19.299489  lr: 0.000886  total_losses: 0.8865 (0.8183) hist: [0.87 1.47 0.89 0.87 0.91 0.77 0.71 1.14 0.58 0.84 0.55 0.72 0.76 0.67 0.78 1.09 0.58 0.94 0.84 0.89]  time: 2.5331  data: 2.0201  max mem: 7771\nEpoch: [236]  [267/268]  eta: 0:00:02.398986  lr: 0.000886  total_losses: 1.2949 (0.8253) hist: [1.14 0.58 0.84 0.55 0.72 0.76 0.67 0.78 1.09 0.58 0.94 0.84 0.89 1.16 0.89 1.05 1.08 1.06 1.06 1.29]  time: 2.1933  data: 1.6935  max mem: 7771\nEpoch: [236] Total time: 0:10:43 (2.3995 s / it)\nTest:   [ 0/67]  eta: 0:06:45.449419  model_time: 0.1889 (0.1889) hist: [0.19]  evaluator_time: 0.0510 (0.0510) hist: [0.05]  time: 6.0515  data: 5.7436  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.258015  model_time: 0.1531 (0.1849) hist: [0.19 0.20 0.17 0.17 0.20 0.17 0.17 0.19 0.17 0.20 0.17 0.20 0.21 0.19 0.17 0.19 0.20 0.17 0.17 0.15]  evaluator_time: 0.1998 (0.0862) hist: [0.07 0.10 0.04 0.08 0.07 0.05 0.05 0.06 0.05 0.05 0.05 0.10 0.05 0.10 0.05 0.10 0.10 0.05 0.05 0.20]  time: 2.1823  data: 1.8885  max mem: 7771\nTest:  Total time: 0:02:31 (2.2593 s / it)\nAveraged stats: model_time: 0.1531 (0.1849) hist: [0.19 0.20 0.17 0.17 0.20 0.17 0.17 0.19 0.17 0.20 0.17 0.20 0.21 0.19 0.17 0.19 0.20 0.17 0.17 0.15]  evaluator_time: 0.1998 (0.0862) hist: [0.07 0.10 0.04 0.08 0.07 0.05 0.05 0.06 0.05 0.05 0.05 0.10 0.05 0.10 0.05 0.10 0.10 0.05 0.05 0.20]\nAccumulating evaluation results...\nDONE (t=0.85s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.566\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\nEpoch: [237]  [  0/268]  eta: 0:21:59.417124  lr: 0.000886  total_losses: 0.7880 (0.7880) hist: [0.79]  time: 4.9232  data: 4.4254  max mem: 7771\nEpoch: [237]  [ 20/268]  eta: 0:09:45.787814  lr: 0.000886  total_losses: 0.5460 (0.8290) hist: [0.74 0.64 0.77 0.46 0.79 0.96 1.21 1.12 0.67 0.68 0.59 0.75 1.25 0.85 1.17 0.86 0.75 0.90 0.92 0.55]  time: 2.2340  data: 1.7149  max mem: 7771\nEpoch: [237]  [ 40/268]  eta: 0:09:09.467074  lr: 0.000886  total_losses: 1.1604 (0.8194) hist: [0.66 0.68 1.03 0.52 0.71 0.74 0.61 0.92 0.84 0.85 0.92 0.90 0.83 0.84 0.75 0.95 0.77 0.64 0.86 1.16]  time: 2.4602  data: 1.9461  max mem: 7771\nEpoch: [237]  [ 60/268]  eta: 0:08:27.013407  lr: 0.000886  total_losses: 0.8135 (0.8425) hist: [0.68 0.98 1.24 0.79 0.80 0.48 0.91 0.90 1.27 0.99 0.72 0.97 1.03 0.77 0.78 0.83 1.16 0.68 1.03 0.81]  time: 2.4942  data: 1.9727  max mem: 7771\nEpoch: [237]  [ 80/268]  eta: 0:07:34.443982  lr: 0.000886  total_losses: 0.7918 (0.8507) hist: [0.85 0.85 1.10 1.19 0.87 0.91 1.05 1.06 1.05 0.93 0.54 0.68 0.81 0.81 0.95 0.99 0.70 0.84 0.54 0.79]  time: 2.3553  data: 1.8402  max mem: 7771\nEpoch: [237]  [100/268]  eta: 0:06:46.242112  lr: 0.000886  total_losses: 1.0776 (0.8464) hist: [0.68 0.87 0.96 0.73 0.70 0.74 0.97 0.89 0.84 1.16 0.63 0.67 0.75 0.86 0.70 0.57 0.79 0.97 1.02 1.08]  time: 2.4216  data: 1.9038  max mem: 7771\nEpoch: [237]  [120/268]  eta: 0:05:53.181063  lr: 0.000886  total_losses: 0.8177 (0.8433) hist: [0.54 0.67 0.91 0.78 0.94 1.23 1.10 0.90 0.56 0.87 0.63 0.78 0.89 0.98 0.80 0.61 0.86 0.89 0.79 0.82]  time: 2.2260  data: 1.7119  max mem: 7771\nEpoch: [237]  [140/268]  eta: 0:05:05.686771  lr: 0.000886  total_losses: 0.8352 (0.8376) hist: [0.90 0.87 0.99 1.00 0.98 0.66 0.42 0.81 0.88 0.75 0.68 1.03 1.00 0.59 0.50 0.58 0.83 0.86 0.88 0.84]  time: 2.3992  data: 1.8827  max mem: 7771\nEpoch: [237]  [160/268]  eta: 0:04:18.452926  lr: 0.000886  total_losses: 0.8526 (0.8415) hist: [0.68 1.12 0.79 0.81 1.06 1.08 0.77 1.23 0.96 0.66 0.64 0.97 0.90 0.97 0.95 0.76 0.77 0.64 0.77 0.85]  time: 2.4277  data: 1.9113  max mem: 7771\nEpoch: [237]  [180/268]  eta: 0:03:29.815880  lr: 0.000886  total_losses: 1.2081 (0.8420) hist: [0.83 0.87 0.73 0.88 0.80 1.07 0.73 0.66 0.99 0.59 0.94 0.56 0.76 1.10 0.74 0.85 0.81 0.62 1.18 1.21]  time: 2.3133  data: 1.7974  max mem: 7771\nEpoch: [237]  [200/268]  eta: 0:02:42.283236  lr: 0.000886  total_losses: 1.0792 (0.8459) hist: [0.70 1.16 0.49 0.70 0.93 0.88 1.37 0.74 0.83 0.91 0.47 0.99 0.83 0.94 1.20 0.90 0.76 0.64 1.12 1.08]  time: 2.4069  data: 1.8920  max mem: 7771\nEpoch: [237]  [220/268]  eta: 0:01:54.239044  lr: 0.000886  total_losses: 0.8557 (0.8407) hist: [0.58 0.66 0.81 0.95 0.79 0.81 0.92 0.89 0.66 0.88 0.77 0.62 0.64 0.85 0.81 1.07 0.78 0.53 0.86 0.86]  time: 2.3143  data: 1.8026  max mem: 7771\nEpoch: [237]  [240/268]  eta: 0:01:06.733829  lr: 0.000886  total_losses: 0.6265 (0.8397) hist: [0.73 0.87 0.90 0.76 0.75 1.10 0.79 0.95 0.81 0.89 0.55 0.67 1.04 0.97 0.79 0.76 0.72 0.92 1.01 0.63]  time: 2.4206  data: 1.9079  max mem: 7771\nEpoch: [237]  [260/268]  eta: 0:00:19.103616  lr: 0.000886  total_losses: 0.4468 (0.8460) hist: [0.66 0.59 0.90 1.17 1.34 0.69 0.87 1.08 1.35 1.27 0.53 0.76 0.85 1.10 0.86 0.63 0.94 0.84 1.56 0.45]  time: 2.4434  data: 1.9344  max mem: 7771\nEpoch: [237]  [267/268]  eta: 0:00:02.379125  lr: 0.000886  total_losses: 1.0321 (0.8487) hist: [1.08 1.35 1.27 0.53 0.76 0.85 1.10 0.86 0.63 0.94 0.84 1.56 0.45 0.75 1.18 1.43 0.66 0.97 0.63 1.03]  time: 2.1395  data: 1.6424  max mem: 7771\nEpoch: [237] Total time: 0:10:37 (2.3796 s / it)\nTest:   [ 0/67]  eta: 0:06:37.132165  model_time: 0.2118 (0.2118) hist: [0.21]  evaluator_time: 0.0944 (0.0944) hist: [0.09]  time: 5.9273  data: 5.5230  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.273911  model_time: 0.1477 (0.1895) hist: [0.18 0.20 0.17 0.20 0.19 0.17 0.22 0.20 0.17 0.17 0.17 0.17 0.20 0.19 0.20 0.20 0.20 0.19 0.16 0.15]  evaluator_time: 0.0267 (0.0911) hist: [0.05 0.07 0.05 0.05 0.07 0.05 0.43 0.12 0.05 0.09 0.04 0.08 0.07 0.05 0.12 0.10 0.10 0.05 0.03 0.03]  time: 2.1492  data: 1.8460  max mem: 7771\nTest:  Total time: 0:02:32 (2.2752 s / it)\nAveraged stats: model_time: 0.1477 (0.1895) hist: [0.18 0.20 0.17 0.20 0.19 0.17 0.22 0.20 0.17 0.17 0.17 0.17 0.20 0.19 0.20 0.20 0.20 0.19 0.16 0.15]  evaluator_time: 0.0267 (0.0911) hist: [0.05 0.07 0.05 0.05 0.07 0.05 0.43 0.12 0.05 0.09 0.04 0.08 0.07 0.05 0.12 0.10 0.10 0.05 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.89s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.574\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661\nEpoch: [238]  [  0/268]  eta: 0:23:46.845003  lr: 0.000886  total_losses: 0.8158 (0.8158) hist: [0.82]  time: 5.3240  data: 4.7601  max mem: 7771\nEpoch: [238]  [ 20/268]  eta: 0:11:25.517319  lr: 0.000886  total_losses: 1.2732 (0.8290) hist: [0.70 1.09 0.66 0.70 0.53 0.89 0.85 0.58 0.82 0.71 1.03 1.06 0.67 1.06 0.81 0.85 0.64 0.88 0.80 1.27]  time: 2.6362  data: 2.1074  max mem: 7771\nEpoch: [238]  [ 40/268]  eta: 0:09:43.118933  lr: 0.000886  total_losses: 0.6297 (0.8406) hist: [1.10 1.03 0.75 0.85 0.63 1.13 0.74 0.78 0.80 0.98 0.81 0.63 0.77 1.00 1.09 0.59 0.78 0.82 1.13 0.63]  time: 2.3406  data: 1.8243  max mem: 7771\nEpoch: [238]  [ 60/268]  eta: 0:08:31.971593  lr: 0.000886  total_losses: 0.6555 (0.8301) hist: [0.77 0.99 0.73 0.74 1.02 0.77 0.78 0.63 0.78 0.68 0.86 0.93 0.80 0.81 0.36 1.04 1.09 0.91 0.82 0.66]  time: 2.2643  data: 1.7471  max mem: 7771\nEpoch: [238]  [ 80/268]  eta: 0:07:39.815217  lr: 0.000886  total_losses: 0.5048 (0.8314) hist: [0.61 0.64 1.30 0.67 0.90 1.08 0.89 1.23 0.55 0.72 0.66 0.85 0.90 0.76 0.90 1.07 0.75 0.81 0.89 0.50]  time: 2.3983  data: 1.8871  max mem: 7771\nEpoch: [238]  [100/268]  eta: 0:06:49.886691  lr: 0.000886  total_losses: 1.2543 (0.8305) hist: [0.80 0.76 0.96 0.58 0.64 1.03 0.70 0.84 0.74 0.85 0.52 1.26 0.74 1.03 0.77 0.56 1.12 0.66 0.75 1.25]  time: 2.4154  data: 1.9014  max mem: 7771\nEpoch: [238]  [120/268]  eta: 0:05:59.702891  lr: 0.000886  total_losses: 0.8599 (0.8429) hist: [1.03 0.66 0.81 0.60 1.01 1.28 0.81 0.82 0.93 0.61 1.03 0.70 1.02 0.90 1.19 0.87 1.54 0.43 1.00 0.86]  time: 2.3831  data: 1.8655  max mem: 7771\nEpoch: [238]  [140/268]  eta: 0:05:08.624805  lr: 0.000886  total_losses: 1.1077 (0.8524) hist: [1.02 0.71 0.91 0.62 1.12 0.63 1.05 0.69 1.01 0.97 0.75 1.52 0.98 0.91 0.73 0.87 0.95 1.06 0.60 1.11]  time: 2.2944  data: 1.7777  max mem: 7771\nEpoch: [238]  [160/268]  eta: 0:04:18.902109  lr: 0.000886  total_losses: 0.6129 (0.8476) hist: [0.72 0.80 1.13 0.73 1.08 0.86 0.64 0.69 0.91 1.24 0.81 0.45 0.96 0.94 0.73 0.67 0.70 0.65 0.93 0.61]  time: 2.2993  data: 1.7853  max mem: 7771\nEpoch: [238]  [180/268]  eta: 0:03:32.215352  lr: 0.000886  total_losses: 0.9609 (0.8496) hist: [0.77 1.04 0.60 0.76 0.76 1.05 1.22 1.29 0.68 1.29 0.82 0.90 0.73 0.73 0.63 0.90 0.86 0.50 0.84 0.96]  time: 2.5266  data: 2.0082  max mem: 7771\nEpoch: [238]  [200/268]  eta: 0:02:44.126762  lr: 0.000886  total_losses: 0.5201 (0.8478) hist: [0.74 0.90 0.72 0.76 0.84 0.87 0.68 0.61 0.82 0.93 0.75 0.82 0.78 0.97 0.92 0.83 1.48 0.95 0.75 0.52]  time: 2.4326  data: 1.9207  max mem: 7771\nEpoch: [238]  [220/268]  eta: 0:01:55.210599  lr: 0.000886  total_losses: 0.9641 (0.8474) hist: [0.66 0.51 0.91 1.25 0.86 0.87 1.05 0.76 0.66 0.70 0.90 0.60 1.05 1.11 0.70 0.87 0.60 0.99 0.86 0.96]  time: 2.2655  data: 1.7472  max mem: 7771\nEpoch: [238]  [240/268]  eta: 0:01:06.875275  lr: 0.000886  total_losses: 0.8090 (0.8476) hist: [0.92 0.66 0.65 0.99 1.02 0.63 0.62 0.77 1.27 0.92 1.09 0.81 0.80 0.57 0.95 0.76 1.21 0.90 0.63 0.81]  time: 2.2578  data: 1.7418  max mem: 7771\nEpoch: [238]  [260/268]  eta: 0:00:19.063336  lr: 0.000886  total_losses: 0.6410 (0.8475) hist: [0.85 0.59 0.66 0.83 1.33 0.65 0.51 0.92 0.63 1.25 0.66 0.96 1.02 0.85 0.89 0.87 0.92 1.05 0.81 0.64]  time: 2.3168  data: 1.8015  max mem: 7771\nEpoch: [238]  [267/268]  eta: 0:00:02.374579  lr: 0.000886  total_losses: 0.9281 (0.8479) hist: [0.92 0.63 1.25 0.66 0.96 1.02 0.85 0.89 0.87 0.92 1.05 0.81 0.64 0.80 0.78 0.82 1.27 0.77 0.67 0.93]  time: 2.2657  data: 1.7656  max mem: 7771\nEpoch: [238] Total time: 0:10:36 (2.3751 s / it)\nTest:   [ 0/67]  eta: 0:07:04.856861  model_time: 0.1735 (0.1735) hist: [0.17]  evaluator_time: 0.1040 (0.1040) hist: [0.10]  time: 6.3411  data: 5.9895  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.228068  model_time: 0.1456 (0.1841) hist: [0.18 0.17 0.18 0.20 0.18 0.19 0.22 0.19 0.21 0.17 0.17 0.20 0.20 0.17 0.19 0.18 0.19 0.20 0.16 0.15]  evaluator_time: 0.0235 (0.0896) hist: [0.05 0.09 0.04 0.07 0.33 0.09 0.12 0.10 0.09 0.10 0.05 0.09 0.09 0.05 0.09 0.08 0.08 0.11 0.03 0.02]  time: 2.1373  data: 1.8254  max mem: 7771\nTest:  Total time: 0:02:29 (2.2294 s / it)\nAveraged stats: model_time: 0.1456 (0.1841) hist: [0.18 0.17 0.18 0.20 0.18 0.19 0.22 0.19 0.21 0.17 0.17 0.20 0.20 0.17 0.19 0.18 0.19 0.20 0.16 0.15]  evaluator_time: 0.0235 (0.0896) hist: [0.05 0.09 0.04 0.07 0.33 0.09 0.12 0.10 0.09 0.10 0.05 0.09 0.09 0.05 0.09 0.08 0.08 0.11 0.03 0.02]\nAccumulating evaluation results...\nDONE (t=1.00s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664\nEpoch: [239]  [  0/268]  eta: 0:28:45.781872  lr: 0.000886  total_losses: 0.6872 (0.6872) hist: [0.69]  time: 6.4395  data: 5.9408  max mem: 7771\nEpoch: [239]  [ 20/268]  eta: 0:10:11.692521  lr: 0.000886  total_losses: 0.7946 (0.8399) hist: [0.89 0.85 1.07 0.75 0.59 0.57 0.73 0.78 1.42 0.52 0.71 0.92 0.85 0.67 0.85 0.85 1.20 0.97 0.97 0.79]  time: 2.2679  data: 1.7430  max mem: 7771\nEpoch: [239]  [ 40/268]  eta: 0:08:57.300182  lr: 0.000886  total_losses: 0.6307 (0.8399) hist: [0.60 0.76 0.62 1.32 0.81 1.04 0.75 0.98 0.79 0.71 0.80 1.05 0.94 0.66 0.63 0.61 0.77 1.18 1.14 0.63]  time: 2.2412  data: 1.7238  max mem: 7771\nEpoch: [239]  [ 60/268]  eta: 0:08:13.117280  lr: 0.000886  total_losses: 0.7772 (0.8271) hist: [0.69 1.08 1.10 0.73 0.66 0.85 0.93 0.87 0.66 0.83 0.66 0.97 0.53 0.78 0.96 0.41 0.61 0.81 1.14 0.78]  time: 2.3998  data: 1.8853  max mem: 7771\nEpoch: [239]  [ 80/268]  eta: 0:07:27.621760  lr: 0.000886  total_losses: 0.6998 (0.8137) hist: [1.15 0.84 1.08 0.86 0.73 0.76 0.66 0.52 0.50 0.68 0.97 0.58 0.57 1.06 0.70 0.76 0.83 0.84 0.66 0.70]  time: 2.4121  data: 1.8961  max mem: 7771\nEpoch: [239]  [100/268]  eta: 0:06:46.130774  lr: 0.000886  total_losses: 0.9603 (0.8280) hist: [0.69 1.35 0.74 0.94 0.83 0.69 1.14 0.69 0.64 1.42 0.72 0.91 0.81 0.98 0.58 1.17 0.90 0.86 0.69 0.96]  time: 2.5652  data: 2.0528  max mem: 7771\nEpoch: [239]  [120/268]  eta: 0:05:58.325831  lr: 0.000886  total_losses: 0.9030 (0.8245) hist: [0.77 1.15 0.81 0.73 0.56 1.07 0.82 0.74 0.51 0.68 0.90 0.93 0.99 0.84 0.70 0.87 0.47 0.84 0.85 0.90]  time: 2.4397  data: 1.9303  max mem: 7771\nEpoch: [239]  [140/268]  eta: 0:05:06.375383  lr: 0.000886  total_losses: 0.6046 (0.8282) hist: [0.78 1.01 0.90 1.20 0.81 1.25 0.82 1.01 0.79 0.71 0.62 1.34 0.60 0.94 0.61 0.73 0.65 0.54 1.10 0.60]  time: 2.2268  data: 1.7151  max mem: 7771\nEpoch: [239]  [160/268]  eta: 0:04:19.748256  lr: 0.000886  total_losses: 0.7598 (0.8408) hist: [0.77 1.09 0.75 1.13 0.69 0.89 1.20 1.38 0.85 0.72 1.03 1.25 0.96 0.63 1.23 0.96 0.58 0.66 1.07 0.76]  time: 2.4863  data: 1.9771  max mem: 7771\nEpoch: [239]  [180/268]  eta: 0:03:29.675751  lr: 0.000886  total_losses: 0.7250 (0.8411) hist: [0.79 0.85 0.64 1.39 0.90 1.08 0.91 0.52 0.51 0.90 0.84 1.06 0.58 0.90 0.70 1.15 0.90 0.80 0.71 0.72]  time: 2.2024  data: 1.6832  max mem: 7771\nEpoch: [239]  [200/268]  eta: 0:02:42.394739  lr: 0.000886  total_losses: 1.0379 (0.8471) hist: [0.68 0.71 0.92 0.99 1.44 1.22 0.52 1.07 0.73 0.61 0.97 0.82 0.86 0.75 0.63 0.79 0.89 0.87 1.53 1.04]  time: 2.4377  data: 1.9248  max mem: 7771\nEpoch: [239]  [220/268]  eta: 0:01:53.969010  lr: 0.000886  total_losses: 1.0867 (0.8485) hist: [0.83 1.08 0.78 1.04 0.71 1.07 0.69 0.95 1.08 0.90 0.84 0.58 0.81 1.09 0.95 0.70 0.62 0.59 0.86 1.09]  time: 2.2356  data: 1.7132  max mem: 7771\nEpoch: [239]  [240/268]  eta: 0:01:06.003097  lr: 0.000886  total_losses: 0.7107 (0.8490) hist: [0.83 1.23 1.39 0.64 0.78 0.95 0.71 0.74 0.78 0.96 0.90 0.69 1.07 0.79 0.74 0.71 1.09 0.57 0.78 0.71]  time: 2.1683  data: 1.6552  max mem: 7771\nEpoch: [239]  [260/268]  eta: 0:00:18.922222  lr: 0.000886  total_losses: 0.7686 (0.8558) hist: [0.66 1.28 1.57 0.83 1.18 0.84 0.92 0.62 0.82 1.25 0.93 1.04 1.08 1.01 0.54 0.87 0.83 0.91 0.77 0.77]  time: 2.4620  data: 1.9434  max mem: 7771\nEpoch: [239]  [267/268]  eta: 0:00:02.357469  lr: 0.000886  total_losses: 0.6846 (0.8534) hist: [0.62 0.82 1.25 0.93 1.04 1.08 1.01 0.54 0.87 0.83 0.91 0.77 0.77 0.90 0.91 0.92 0.49 0.57 0.88 0.68]  time: 2.1110  data: 1.6102  max mem: 7771\nEpoch: [239] Total time: 0:10:31 (2.3581 s / it)\nTest:   [ 0/67]  eta: 0:06:17.827980  model_time: 0.1795 (0.1795) hist: [0.18]  evaluator_time: 0.0840 (0.0840) hist: [0.08]  time: 5.6392  data: 5.3190  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.239420  model_time: 0.1461 (0.1860) hist: [0.19 0.17 0.17 0.19 0.19 0.19 0.20 0.20 0.21 0.19 0.17 0.17 0.19 0.20 0.19 0.20 0.21 0.19 0.17 0.15]  evaluator_time: 0.0253 (0.0904) hist: [0.05 0.06 0.05 0.04 0.10 0.07 0.09 0.09 0.04 0.07 0.05 0.06 0.05 0.10 0.40 0.13 0.07 0.06 0.03 0.03]  time: 2.1668  data: 1.8605  max mem: 7771\nTest:  Total time: 0:02:30 (2.2409 s / it)\nAveraged stats: model_time: 0.1461 (0.1860) hist: [0.19 0.17 0.17 0.19 0.19 0.19 0.20 0.20 0.21 0.19 0.17 0.17 0.19 0.20 0.19 0.20 0.21 0.19 0.17 0.15]  evaluator_time: 0.0253 (0.0904) hist: [0.05 0.06 0.05 0.04 0.10 0.07 0.09 0.09 0.04 0.07 0.05 0.06 0.05 0.10 0.40 0.13 0.07 0.06 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.86s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.563\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\nEpoch: [240]  [  0/268]  eta: 0:26:48.809756  lr: 0.000798  total_losses: 0.8386 (0.8386) hist: [0.84]  time: 6.0030  data: 5.4577  max mem: 7771\nEpoch: [240]  [ 20/268]  eta: 0:10:37.222078  lr: 0.000798  total_losses: 0.8009 (0.7765) hist: [0.70 0.74 0.93 0.65 0.75 0.97 1.13 0.93 0.64 0.54 0.69 0.49 0.89 0.67 0.75 0.98 0.83 0.65 0.71 0.80]  time: 2.3978  data: 1.8674  max mem: 7771\nEpoch: [240]  [ 40/268]  eta: 0:09:28.204229  lr: 0.000798  total_losses: 0.5218 (0.7972) hist: [1.07 0.78 0.91 0.54 0.66 0.44 0.71 0.88 0.94 1.15 0.87 0.81 0.76 1.24 0.83 0.80 0.86 1.00 0.61 0.52]  time: 2.4109  data: 1.8920  max mem: 7771\nEpoch: [240]  [ 60/268]  eta: 0:08:32.891406  lr: 0.000798  total_losses: 1.0685 (0.8175) hist: [0.89 0.93 1.31 0.64 0.89 0.76 0.74 0.71 0.58 0.90 0.68 0.94 0.81 1.29 1.03 0.66 0.80 0.78 0.78 1.07]  time: 2.4119  data: 1.8914  max mem: 7771\nEpoch: [240]  [ 80/268]  eta: 0:07:31.652656  lr: 0.000798  total_losses: 0.7891 (0.8139) hist: [0.62 0.63 0.48 0.90 0.87 0.72 0.86 0.88 0.80 0.82 1.06 1.06 0.59 0.85 1.01 0.84 0.80 0.72 0.77 0.79]  time: 2.2090  data: 1.6965  max mem: 7771\nEpoch: [240]  [100/268]  eta: 0:06:37.128477  lr: 0.000798  total_losses: 1.1570 (0.8238) hist: [0.73 0.75 1.00 0.65 0.78 0.79 0.87 0.86 0.94 1.05 0.91 0.72 0.90 1.16 0.60 0.93 0.94 0.92 0.65 1.16]  time: 2.2077  data: 1.6955  max mem: 7771\nEpoch: [240]  [120/268]  eta: 0:05:56.001970  lr: 0.000798  total_losses: 0.9377 (0.8371) hist: [1.16 0.72 0.76 0.80 1.05 0.67 1.06 0.97 0.67 0.79 0.91 1.38 0.63 0.87 0.76 1.10 0.91 1.06 0.88 0.94]  time: 2.6153  data: 2.0982  max mem: 7771\nEpoch: [240]  [140/268]  eta: 0:05:08.270508  lr: 0.000798  total_losses: 0.6006 (0.8370) hist: [0.81 0.79 0.78 0.77 0.58 1.10 0.84 0.80 0.62 0.96 0.82 1.30 1.02 0.71 0.71 0.70 0.76 1.25 0.81 0.60]  time: 2.4262  data: 1.9129  max mem: 7771\nEpoch: [240]  [160/268]  eta: 0:04:20.651222  lr: 0.000798  total_losses: 1.0865 (0.8337) hist: [0.69 0.60 0.78 1.35 0.59 0.68 1.05 0.74 0.66 0.68 0.56 0.81 0.82 0.53 0.77 0.72 1.00 1.09 0.99 1.09]  time: 2.4492  data: 1.9324  max mem: 7771\nEpoch: [240]  [180/268]  eta: 0:03:32.283803  lr: 0.000798  total_losses: 0.8827 (0.8315) hist: [0.59 0.66 0.65 0.94 1.17 0.82 0.83 0.75 0.68 1.03 0.71 0.71 0.65 1.13 0.95 0.66 0.94 0.80 0.74 0.88]  time: 2.4033  data: 1.8893  max mem: 7771\nEpoch: [240]  [200/268]  eta: 0:02:43.598785  lr: 0.000798  total_losses: 0.9133 (0.8347) hist: [0.68 0.80 0.97 1.10 0.87 0.57 0.75 0.88 1.09 0.70 0.89 0.93 1.00 0.84 0.68 0.77 0.70 0.97 1.17 0.91]  time: 2.3475  data: 1.8263  max mem: 7771\nEpoch: [240]  [220/268]  eta: 0:01:54.707625  lr: 0.000798  total_losses: 0.6524 (0.8339) hist: [1.00 0.62 0.79 0.79 0.71 0.87 0.64 0.84 0.87 0.71 0.86 0.69 1.00 0.92 0.83 1.04 0.87 0.84 0.97 0.65]  time: 2.2277  data: 1.7045  max mem: 7771\nEpoch: [240]  [240/268]  eta: 0:01:07.098735  lr: 0.000798  total_losses: 0.7694 (0.8348) hist: [0.73 0.76 0.72 0.60 1.02 1.07 0.79 0.54 0.70 0.82 0.70 0.87 0.82 0.84 0.84 0.75 1.47 0.98 1.12 0.77]  time: 2.4698  data: 1.9504  max mem: 7771\nEpoch: [240]  [260/268]  eta: 0:00:19.128373  lr: 0.000798  total_losses: 1.1363 (0.8288) hist: [0.62 0.96 0.88 0.62 0.58 0.70 0.93 0.53 0.77 0.73 0.90 0.64 0.68 0.65 0.52 0.69 0.92 0.82 0.87 1.14]  time: 2.3267  data: 1.8076  max mem: 7771\nEpoch: [240]  [267/268]  eta: 0:00:02.369671  lr: 0.000798  total_losses: 1.0970 (0.8327) hist: [0.53 0.77 0.73 0.90 0.64 0.68 0.65 0.52 0.69 0.92 0.82 0.87 1.14 0.98 0.98 0.75 1.06 0.79 1.17 1.10]  time: 1.9373  data: 1.4347  max mem: 7771\nEpoch: [240] Total time: 0:10:35 (2.3702 s / it)\nTest:   [ 0/67]  eta: 0:07:07.755543  model_time: 0.2336 (0.2336) hist: [0.23]  evaluator_time: 0.0983 (0.0983) hist: [0.10]  time: 6.3844  data: 5.9920  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.247277  model_time: 0.1455 (0.1829) hist: [0.17 0.19 0.17 0.17 0.17 0.19 0.17 0.19 0.17 0.18 0.17 0.17 0.18 0.20 0.20 0.20 0.17 0.19 0.17 0.15]  evaluator_time: 0.0264 (0.0766) hist: [0.07 0.10 0.04 0.04 0.06 0.10 0.06 0.09 0.04 0.05 0.04 0.28 0.11 0.10 0.05 0.06 0.06 0.08 0.03 0.03]  time: 2.1835  data: 1.8929  max mem: 7771\nTest:  Total time: 0:02:30 (2.2486 s / it)\nAveraged stats: model_time: 0.1455 (0.1829) hist: [0.17 0.19 0.17 0.17 0.17 0.19 0.17 0.19 0.17 0.18 0.17 0.17 0.18 0.20 0.20 0.20 0.17 0.19 0.17 0.15]  evaluator_time: 0.0264 (0.0766) hist: [0.07 0.10 0.04 0.04 0.06 0.10 0.06 0.09 0.04 0.05 0.04 0.28 0.11 0.10 0.05 0.06 0.06 0.08 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.83s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.564\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\nEpoch: [241]  [  0/268]  eta: 0:20:34.687020  lr: 0.000798  total_losses: 0.8061 (0.8061) hist: [0.81]  time: 4.6070  data: 4.0851  max mem: 7771\nEpoch: [241]  [ 20/268]  eta: 0:09:53.413207  lr: 0.000798  total_losses: 0.4652 (0.7870) hist: [0.81 0.98 0.92 0.91 0.86 0.87 0.76 0.77 0.68 0.87 1.06 0.78 0.73 1.02 0.69 0.48 0.60 0.87 0.59 0.47]  time: 2.2821  data: 1.7559  max mem: 7771\nEpoch: [241]  [ 40/268]  eta: 0:09:21.044225  lr: 0.000798  total_losses: 0.6489 (0.7692) hist: [1.17 0.63 0.63 0.50 0.86 0.74 0.65 0.75 0.51 0.67 0.53 0.80 0.65 0.57 0.98 0.83 0.74 1.04 1.10 0.65]  time: 2.5320  data: 2.0171  max mem: 7771\nEpoch: [241]  [ 60/268]  eta: 0:08:14.226947  lr: 0.000798  total_losses: 0.7059 (0.7884) hist: [0.87 0.94 0.62 0.76 1.13 0.82 0.84 0.71 1.00 0.94 0.55 0.61 1.12 0.96 1.02 0.64 0.79 0.63 0.90 0.71]  time: 2.2026  data: 1.6844  max mem: 7771\nEpoch: [241]  [ 80/268]  eta: 0:07:24.650957  lr: 0.000798  total_losses: 0.8355 (0.7981) hist: [0.65 0.99 0.63 0.75 1.08 0.55 0.77 0.71 0.74 1.01 0.78 1.34 0.84 0.66 0.85 0.94 0.55 0.83 1.06 0.84]  time: 2.3318  data: 1.8257  max mem: 7771\nEpoch: [241]  [100/268]  eta: 0:06:33.269006  lr: 0.000798  total_losses: 1.0790 (0.7961) hist: [0.57 0.77 0.93 0.86 0.61 0.82 0.75 0.73 0.74 0.67 1.01 1.13 0.70 0.89 0.57 0.71 1.02 0.58 0.63 1.08]  time: 2.2426  data: 1.7252  max mem: 7771\nEpoch: [241]  [120/268]  eta: 0:05:45.534214  lr: 0.000798  total_losses: 0.6985 (0.7997) hist: [1.16 0.70 0.89 0.71 1.12 0.87 0.72 1.20 1.09 0.66 0.63 0.94 0.88 0.65 0.74 0.67 0.69 0.51 0.84 0.70]  time: 2.3034  data: 1.7797  max mem: 7771\nEpoch: [241]  [140/268]  eta: 0:04:58.004945  lr: 0.000798  total_losses: 1.2071 (0.7984) hist: [0.85 0.63 0.72 0.60 0.55 0.70 0.84 0.77 0.81 0.85 0.81 1.15 0.85 0.98 1.06 0.86 0.43 0.53 0.62 1.21]  time: 2.2887  data: 1.7768  max mem: 7771\nEpoch: [241]  [160/268]  eta: 0:04:13.051782  lr: 0.000798  total_losses: 0.8628 (0.8066) hist: [0.40 0.87 0.77 0.80 0.89 0.79 1.01 0.65 0.61 0.69 0.95 0.76 0.78 0.70 1.13 1.01 0.99 0.82 1.78 0.86]  time: 2.4482  data: 1.9242  max mem: 7771\nEpoch: [241]  [180/268]  eta: 0:03:27.747608  lr: 0.000798  total_losses: 0.8452 (0.8085) hist: [0.89 1.09 0.75 0.85 0.47 1.02 0.97 0.66 0.79 0.75 1.06 0.70 0.54 0.68 1.11 0.97 0.71 0.82 0.80 0.85]  time: 2.5032  data: 1.9816  max mem: 7771\nEpoch: [241]  [200/268]  eta: 0:02:41.036032  lr: 0.000798  total_losses: 0.7034 (0.8083) hist: [1.12 0.70 0.96 1.17 0.82 0.75 0.59 0.82 0.69 1.07 0.58 0.95 0.83 0.91 0.48 0.89 0.64 0.56 0.92 0.70]  time: 2.4352  data: 1.9187  max mem: 7771\nEpoch: [241]  [220/268]  eta: 0:01:53.237880  lr: 0.000798  total_losses: 1.1395 (0.8033) hist: [0.69 0.61 0.53 0.53 0.75 0.83 0.70 0.91 0.69 1.22 0.58 0.67 0.48 0.96 0.83 0.78 0.77 0.59 0.80 1.14]  time: 2.2681  data: 1.7548  max mem: 7771\nEpoch: [241]  [240/268]  eta: 0:01:05.900326  lr: 0.000798  total_losses: 0.8666 (0.8026) hist: [0.76 0.72 0.56 0.72 0.83 0.89 0.60 0.68 0.64 1.11 0.69 0.70 0.69 0.90 0.69 0.90 0.94 1.18 0.82 0.87]  time: 2.2924  data: 1.7758  max mem: 7771\nEpoch: [241]  [260/268]  eta: 0:00:18.910847  lr: 0.000798  total_losses: 0.6575 (0.8035) hist: [0.71 0.64 0.99 0.79 0.76 1.21 0.64 0.89 0.89 0.88 1.04 0.68 0.69 0.84 1.05 0.84 0.66 0.70 0.70 0.66]  time: 2.4876  data: 1.9736  max mem: 7771\nEpoch: [241]  [267/268]  eta: 0:00:02.357629  lr: 0.000798  total_losses: 1.1536 (0.8057) hist: [0.89 0.89 0.88 1.04 0.68 0.69 0.84 1.05 0.84 0.66 0.70 0.70 0.66 0.93 0.86 0.66 0.79 0.82 1.00 1.15]  time: 2.1450  data: 1.6485  max mem: 7771\nEpoch: [241] Total time: 0:10:31 (2.3581 s / it)\nTest:   [ 0/67]  eta: 0:06:35.323936  model_time: 0.1686 (0.1686) hist: [0.17]  evaluator_time: 0.0739 (0.0739) hist: [0.07]  time: 5.9004  data: 5.5920  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.208011  model_time: 0.1473 (0.1833) hist: [0.21 0.17 0.17 0.17 0.17 0.20 0.19 0.23 0.18 0.17 0.17 0.19 0.19 0.17 0.19 0.19 0.20 0.19 0.16 0.15]  evaluator_time: 0.0326 (0.0862) hist: [0.06 0.05 0.04 0.04 0.06 0.10 0.35 0.10 0.05 0.08 0.05 0.10 0.05 0.07 0.10 0.09 0.05 0.11 0.04 0.03]  time: 2.1015  data: 1.8036  max mem: 7771\nTest:  Total time: 0:02:28 (2.2094 s / it)\nAveraged stats: model_time: 0.1473 (0.1833) hist: [0.21 0.17 0.17 0.17 0.17 0.20 0.19 0.23 0.18 0.17 0.17 0.19 0.19 0.17 0.19 0.19 0.20 0.19 0.16 0.15]  evaluator_time: 0.0326 (0.0862) hist: [0.06 0.05 0.04 0.04 0.06 0.10 0.35 0.10 0.05 0.08 0.05 0.10 0.05 0.07 0.10 0.09 0.05 0.11 0.04 0.03]\nAccumulating evaluation results...\nDONE (t=1.06s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.577\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659\nEpoch: [242]  [  0/268]  eta: 0:24:29.824640  lr: 0.000798  total_losses: 0.9299 (0.9299) hist: [0.93]  time: 5.4844  data: 4.9392  max mem: 7771\nEpoch: [242]  [ 20/268]  eta: 0:10:32.158079  lr: 0.000798  total_losses: 0.8493 (0.7443) hist: [0.59 0.88 0.82 0.78 0.68 0.72 1.42 0.87 0.73 0.52 0.68 0.64 0.49 0.55 0.71 0.53 0.68 0.91 0.65 0.85]  time: 2.4023  data: 1.8826  max mem: 7771\nEpoch: [242]  [ 40/268]  eta: 0:09:16.883870  lr: 0.000798  total_losses: 1.1348 (0.7868) hist: [1.01 0.78 0.94 0.86 0.77 0.73 0.73 0.73 0.81 0.70 1.08 0.96 1.04 0.70 0.62 0.74 0.72 0.73 0.85 1.13]  time: 2.3306  data: 1.8164  max mem: 7771\nEpoch: [242]  [ 60/268]  eta: 0:08:27.533376  lr: 0.000798  total_losses: 0.9797 (0.7716) hist: [0.81 0.82 0.67 0.68 1.11 0.87 0.82 0.66 0.79 0.59 0.58 0.68 0.51 0.73 0.64 0.82 0.67 0.66 0.69 0.98]  time: 2.4351  data: 1.9280  max mem: 7771\nEpoch: [242]  [ 80/268]  eta: 0:07:34.517261  lr: 0.000798  total_losses: 0.7116 (0.7961) hist: [0.91 0.81 0.52 0.81 1.28 0.83 0.92 0.77 0.88 0.89 0.62 0.62 0.81 1.36 0.73 0.87 1.30 0.79 0.98 0.71]  time: 2.3493  data: 1.8316  max mem: 7771\nEpoch: [242]  [100/268]  eta: 0:06:39.012758  lr: 0.000798  total_losses: 1.0407 (0.8061) hist: [1.01 0.93 0.90 0.84 0.85 0.82 1.23 0.95 0.72 0.73 0.60 0.48 0.62 0.86 0.74 0.81 1.03 0.77 1.01 1.04]  time: 2.2027  data: 1.6903  max mem: 7771\nEpoch: [242]  [120/268]  eta: 0:05:52.846661  lr: 0.000798  total_losses: 0.7318 (0.8061) hist: [1.02 0.56 0.95 0.98 0.73 0.82 0.44 0.87 0.80 0.96 0.66 0.96 0.97 1.11 0.57 0.84 0.69 0.56 0.91 0.73]  time: 2.4297  data: 1.9139  max mem: 7771\nEpoch: [242]  [140/268]  eta: 0:05:02.208305  lr: 0.000798  total_losses: 0.7205 (0.8138) hist: [0.96 0.74 0.53 0.80 0.66 1.20 0.96 0.61 1.10 0.96 0.75 0.87 0.94 1.16 0.71 0.83 0.91 0.94 0.86 0.72]  time: 2.2213  data: 1.7090  max mem: 7771\nEpoch: [242]  [160/268]  eta: 0:04:13.264177  lr: 0.000798  total_losses: 0.7945 (0.8071) hist: [0.75 0.64 0.64 0.75 0.66 0.91 0.82 0.67 0.77 0.57 1.33 0.66 0.78 0.71 0.70 0.82 0.87 0.65 0.75 0.79]  time: 2.2325  data: 1.7220  max mem: 7771\nEpoch: [242]  [180/268]  eta: 0:03:26.361564  lr: 0.000798  total_losses: 0.6818 (0.8071) hist: [1.06 0.63 0.78 0.52 0.66 1.09 1.00 1.08 1.00 0.50 0.97 0.95 0.79 0.78 1.04 0.50 0.59 0.75 0.77 0.68]  time: 2.3448  data: 1.8282  max mem: 7771\nEpoch: [242]  [200/268]  eta: 0:02:39.637892  lr: 0.000798  total_losses: 0.7110 (0.8114) hist: [0.60 0.64 0.92 1.03 0.77 0.75 0.99 1.16 0.91 1.05 0.70 0.82 0.49 0.75 0.88 1.27 1.31 0.78 0.48 0.71]  time: 2.3711  data: 1.8524  max mem: 7771\nEpoch: [242]  [220/268]  eta: 0:01:53.466707  lr: 0.000798  total_losses: 0.5170 (0.8099) hist: [0.99 0.47 1.00 0.62 0.51 0.62 1.01 1.34 1.05 0.66 0.84 0.81 0.93 0.74 0.76 0.87 0.71 0.70 0.74 0.52]  time: 2.5274  data: 2.0159  max mem: 7771\nEpoch: [242]  [240/268]  eta: 0:01:06.179095  lr: 0.000798  total_losses: 0.7373 (0.8146) hist: [1.02 0.85 0.80 0.82 0.64 1.12 0.81 0.65 0.74 0.99 0.82 0.94 0.81 0.76 1.52 1.22 0.78 0.51 0.76 0.74]  time: 2.3597  data: 1.8421  max mem: 7771\nEpoch: [242]  [260/268]  eta: 0:00:18.947296  lr: 0.000798  total_losses: 0.8181 (0.8131) hist: [0.70 0.72 0.78 0.60 0.64 1.31 1.06 0.90 0.63 0.69 0.84 0.70 1.00 0.93 0.80 0.69 0.45 0.89 0.75 0.82]  time: 2.4271  data: 1.9096  max mem: 7771\nEpoch: [242]  [267/268]  eta: 0:00:02.356202  lr: 0.000798  total_losses: 0.9003 (0.8144) hist: [0.90 0.63 0.69 0.84 0.70 1.00 0.93 0.80 0.69 0.45 0.89 0.75 0.82 0.76 1.07 0.89 0.72 0.86 0.83 0.90]  time: 2.1013  data: 1.5968  max mem: 7771\nEpoch: [242] Total time: 0:10:31 (2.3567 s / it)\nTest:   [ 0/67]  eta: 0:06:20.098690  model_time: 0.1846 (0.1846) hist: [0.18]  evaluator_time: 0.0537 (0.0537) hist: [0.05]  time: 5.6731  data: 5.3914  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.232165  model_time: 0.1448 (0.1833) hist: [0.19 0.19 0.17 0.19 0.17 0.19 0.17 0.20 0.20 0.20 0.17 0.17 0.19 0.20 0.20 0.19 0.19 0.17 0.16 0.14]  evaluator_time: 0.0240 (0.0798) hist: [0.09 0.08 0.04 0.08 0.07 0.29 0.07 0.09 0.05 0.11 0.05 0.05 0.05 0.05 0.09 0.05 0.05 0.05 0.03 0.02]  time: 2.1746  data: 1.8790  max mem: 7771\nTest:  Total time: 0:02:29 (2.2335 s / it)\nAveraged stats: model_time: 0.1448 (0.1833) hist: [0.19 0.19 0.17 0.19 0.17 0.19 0.17 0.20 0.20 0.20 0.17 0.17 0.19 0.20 0.20 0.19 0.19 0.17 0.16 0.14]  evaluator_time: 0.0240 (0.0798) hist: [0.09 0.08 0.04 0.08 0.07 0.29 0.07 0.09 0.05 0.11 0.05 0.05 0.05 0.05 0.09 0.05 0.05 0.05 0.03 0.02]\nAccumulating evaluation results...\nDONE (t=0.87s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.571\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\nEpoch: [243]  [  0/268]  eta: 0:21:05.129396  lr: 0.000798  total_losses: 0.9132 (0.9132) hist: [0.91]  time: 4.7206  data: 4.1800  max mem: 7771\nEpoch: [243]  [ 20/268]  eta: 0:09:56.487836  lr: 0.000798  total_losses: 1.1471 (0.8218) hist: [0.88 0.56 0.68 0.60 0.49 0.94 0.83 0.79 0.88 0.51 0.78 0.87 1.20 0.77 1.04 0.78 0.85 0.76 0.97 1.15]  time: 2.2894  data: 1.7640  max mem: 7771\nEpoch: [243]  [ 40/268]  eta: 0:09:17.292192  lr: 0.000798  total_losses: 0.6501 (0.8172) hist: [0.82 0.69 1.28 0.60 1.16 0.84 0.99 0.52 0.78 0.69 0.78 0.81 0.52 0.83 0.79 0.91 0.88 0.86 0.86 0.65]  time: 2.4853  data: 1.9671  max mem: 7771\nEpoch: [243]  [ 60/268]  eta: 0:08:14.380425  lr: 0.000798  total_losses: 0.7046 (0.8194) hist: [0.95 1.04 1.09 0.66 0.66 1.03 0.77 0.69 0.58 0.86 0.78 0.82 0.54 0.73 0.95 1.13 0.67 1.16 0.66 0.70]  time: 2.2386  data: 1.7226  max mem: 7771\nEpoch: [243]  [ 80/268]  eta: 0:07:26.305628  lr: 0.000798  total_losses: 0.7337 (0.8045) hist: [0.72 0.75 1.03 0.58 0.62 0.46 0.72 0.63 0.72 0.77 0.73 0.65 1.11 0.69 0.68 0.86 0.95 1.09 0.68 0.73]  time: 2.3652  data: 1.8503  max mem: 7771\nEpoch: [243]  [100/268]  eta: 0:06:39.851443  lr: 0.000798  total_losses: 0.6750 (0.7953) hist: [0.97 0.59 1.01 0.85 0.71 0.71 0.75 0.57 0.74 1.03 0.76 0.81 0.58 0.74 0.85 0.64 0.89 0.55 0.77 0.68]  time: 2.4048  data: 1.8913  max mem: 7771\nEpoch: [243]  [120/268]  eta: 0:05:56.405690  lr: 0.000798  total_losses: 1.2272 (0.7924) hist: [0.92 1.22 0.63 0.64 0.52 0.76 0.61 0.86 0.74 0.84 0.57 0.78 0.65 0.71 0.97 0.65 0.49 1.12 0.64 1.23]  time: 2.5499  data: 2.0404  max mem: 7771\nEpoch: [243]  [140/268]  eta: 0:05:10.704924  lr: 0.000798  total_losses: 0.7549 (0.7935) hist: [1.10 0.66 0.72 0.78 1.38 0.46 1.11 0.77 0.77 0.55 0.55 0.70 0.71 0.76 1.02 0.51 1.26 0.64 0.82 0.75]  time: 2.5438  data: 2.0225  max mem: 7771\nEpoch: [243]  [160/268]  eta: 0:04:18.879675  lr: 0.000798  total_losses: 0.6674 (0.7921) hist: [1.00 0.68 1.05 0.68 0.64 0.59 0.60 0.72 0.91 0.96 0.51 0.52 0.77 0.94 0.90 0.91 0.93 0.72 0.93 0.67]  time: 2.1831  data: 1.6637  max mem: 7771\nEpoch: [243]  [180/268]  eta: 0:03:29.817313  lr: 0.000798  total_losses: 0.8073 (0.8015) hist: [0.94 0.66 0.91 0.86 0.92 1.29 0.94 0.91 1.31 0.68 0.70 0.69 0.57 0.69 0.93 0.92 1.02 0.83 0.95 0.81]  time: 2.2817  data: 1.7721  max mem: 7771\nEpoch: [243]  [200/268]  eta: 0:02:41.828780  lr: 0.000798  total_losses: 0.8370 (0.8063) hist: [0.90 0.71 0.53 0.97 0.61 0.95 0.76 1.21 0.81 1.19 0.75 0.77 1.02 0.97 0.71 0.79 0.67 0.83 1.03 0.84]  time: 2.3395  data: 1.8186  max mem: 7771\nEpoch: [243]  [220/268]  eta: 0:01:53.723636  lr: 0.000798  total_losses: 0.8044 (0.8114) hist: [0.90 0.88 1.09 0.66 1.05 0.78 0.70 0.76 1.14 0.70 0.86 0.66 0.89 0.77 0.83 0.70 0.70 0.83 1.56 0.80]  time: 2.2628  data: 1.7496  max mem: 7771\nEpoch: [243]  [240/268]  eta: 0:01:06.490930  lr: 0.000798  total_losses: 0.9753 (0.8100) hist: [0.40 0.61 0.56 0.92 0.84 0.92 0.83 1.25 0.70 0.71 1.04 0.94 0.79 0.69 0.57 0.78 0.67 1.00 0.68 0.98]  time: 2.4347  data: 1.9190  max mem: 7771\nEpoch: [243]  [260/268]  eta: 0:00:18.946106  lr: 0.000798  total_losses: 0.9517 (0.8124) hist: [0.87 0.81 0.63 0.91 0.69 0.83 1.42 0.90 0.99 0.69 0.80 1.05 1.08 0.70 0.56 0.79 0.62 0.77 0.76 0.95]  time: 2.2910  data: 1.7751  max mem: 7771\nEpoch: [243]  [267/268]  eta: 0:00:02.360948  lr: 0.000798  total_losses: 1.0252 (0.8122) hist: [0.90 0.99 0.69 0.80 1.05 1.08 0.70 0.56 0.79 0.62 0.77 0.76 0.95 0.79 0.49 0.85 0.61 0.93 0.94 1.03]  time: 2.1425  data: 1.6421  max mem: 7771\nEpoch: [243] Total time: 0:10:32 (2.3615 s / it)\nTest:   [ 0/67]  eta: 0:06:14.941102  model_time: 0.2047 (0.2047) hist: [0.20]  evaluator_time: 0.0773 (0.0773) hist: [0.08]  time: 5.5961  data: 5.2636  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.232277  model_time: 0.1466 (0.1799) hist: [0.20 0.20 0.17 0.19 0.18 0.18 0.17 0.20 0.17 0.17 0.17 0.20 0.22 0.17 0.20 0.17 0.17 0.19 0.16 0.15]  evaluator_time: 0.0544 (0.0766) hist: [0.08 0.10 0.04 0.38 0.11 0.05 0.08 0.05 0.05 0.06 0.04 0.08 0.05 0.05 0.10 0.04 0.06 0.06 0.03 0.05]  time: 2.1459  data: 1.8499  max mem: 7771\nTest:  Total time: 0:02:29 (2.2337 s / it)\nAveraged stats: model_time: 0.1466 (0.1799) hist: [0.20 0.20 0.17 0.19 0.18 0.18 0.17 0.20 0.17 0.17 0.17 0.20 0.22 0.17 0.20 0.17 0.17 0.19 0.16 0.15]  evaluator_time: 0.0544 (0.0766) hist: [0.08 0.10 0.04 0.38 0.11 0.05 0.08 0.05 0.05 0.06 0.04 0.08 0.05 0.05 0.10 0.04 0.06 0.06 0.03 0.05]\nAccumulating evaluation results...\nDONE (t=1.02s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.565\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\nEpoch: [244]  [  0/268]  eta: 0:20:17.166752  lr: 0.000798  total_losses: 0.6000 (0.6000) hist: [0.60]  time: 4.5417  data: 4.0042  max mem: 7771\nEpoch: [244]  [ 20/268]  eta: 0:10:09.006429  lr: 0.000798  total_losses: 0.8131 (0.7859) hist: [0.98 0.94 0.79 0.81 1.18 0.75 0.68 1.00 0.66 0.82 0.57 0.98 0.74 0.69 0.57 0.38 0.69 0.91 0.95 0.81]  time: 2.3514  data: 1.8303  max mem: 7771\nEpoch: [244]  [ 40/268]  eta: 0:08:55.099622  lr: 0.000798  total_losses: 0.6671 (0.7919) hist: [1.06 0.87 0.97 0.76 0.68 0.48 0.68 0.57 0.83 0.90 1.15 0.68 0.53 0.91 0.82 0.94 0.75 0.94 0.79 0.67]  time: 2.2327  data: 1.7117  max mem: 7771\nEpoch: [244]  [ 60/268]  eta: 0:08:07.989927  lr: 0.000798  total_losses: 1.1270 (0.8054) hist: [0.51 0.57 0.84 0.69 1.41 0.90 0.78 0.96 0.57 0.79 0.86 0.90 0.99 0.76 0.54 0.69 0.86 0.87 1.04 1.13]  time: 2.3444  data: 1.8240  max mem: 7771\nEpoch: [244]  [ 80/268]  eta: 0:07:32.272704  lr: 0.000798  total_losses: 0.6587 (0.8082) hist: [1.14 0.81 0.82 0.84 0.69 0.52 0.64 1.24 0.63 0.97 0.68 0.70 0.58 1.04 0.94 0.90 0.84 0.80 0.91 0.66]  time: 2.5875  data: 2.0664  max mem: 7771\nEpoch: [244]  [100/268]  eta: 0:06:49.047416  lr: 0.000798  total_losses: 0.6641 (0.8067) hist: [0.94 0.66 1.06 0.98 0.68 0.63 1.18 0.54 0.92 0.68 0.57 0.51 0.80 0.80 0.78 1.10 0.82 0.74 0.96 0.66]  time: 2.5527  data: 2.0329  max mem: 7771\nEpoch: [244]  [120/268]  eta: 0:06:01.432600  lr: 0.000798  total_losses: 0.8079 (0.8067) hist: [1.16 0.90 0.99 0.90 0.94 0.94 0.99 0.87 0.68 0.52 0.84 0.65 0.46 1.18 0.60 0.88 0.59 0.70 0.53 0.81]  time: 2.4790  data: 1.9603  max mem: 7771\nEpoch: [244]  [140/268]  eta: 0:05:08.389940  lr: 0.000798  total_losses: 0.8283 (0.8044) hist: [0.88 0.79 0.90 0.74 0.66 1.16 0.98 0.64 0.58 0.53 0.70 0.77 0.72 1.12 0.73 0.75 0.53 1.08 0.73 0.83]  time: 2.2108  data: 1.6973  max mem: 7771\nEpoch: [244]  [160/268]  eta: 0:04:19.215422  lr: 0.000798  total_losses: 0.5624 (0.8062) hist: [1.39 0.60 1.05 0.61 0.66 0.90 0.87 1.00 0.70 0.77 0.82 0.77 1.00 1.01 1.01 0.89 0.73 0.37 0.68 0.56]  time: 2.3356  data: 1.8200  max mem: 7771\nEpoch: [244]  [180/268]  eta: 0:03:29.930061  lr: 0.000798  total_losses: 0.9900 (0.8066) hist: [0.82 0.85 1.01 0.89 0.66 0.72 0.87 0.53 0.76 0.85 0.47 0.52 0.81 0.72 1.05 1.10 0.86 0.87 0.83 0.99]  time: 2.2682  data: 1.7466  max mem: 7771\nEpoch: [244]  [200/268]  eta: 0:02:41.960574  lr: 0.000798  total_losses: 0.7620 (0.8052) hist: [0.77 0.74 0.56 1.00 0.91 0.69 0.83 0.70 0.81 1.03 0.78 0.89 0.86 0.51 0.64 0.81 0.96 1.03 0.58 0.76]  time: 2.3474  data: 1.8273  max mem: 7771\nEpoch: [244]  [220/268]  eta: 0:01:54.100196  lr: 0.000798  total_losses: 0.9209 (0.8040) hist: [0.73 0.50 1.00 1.03 0.87 1.25 0.55 0.53 0.91 0.95 0.78 0.59 0.80 0.65 0.97 0.58 0.74 0.89 0.58 0.92]  time: 2.3300  data: 1.8158  max mem: 7771\nEpoch: [244]  [240/268]  eta: 0:01:06.719733  lr: 0.000798  total_losses: 0.6977 (0.8087) hist: [1.02 0.93 0.84 0.54 0.96 0.61 0.59 1.14 1.00 1.21 0.69 1.07 0.94 0.50 0.83 1.28 0.94 0.70 0.72 0.70]  time: 2.4465  data: 1.9229  max mem: 7771\nEpoch: [244]  [260/268]  eta: 0:00:19.092267  lr: 0.000798  total_losses: 0.6286 (0.8043) hist: [0.71 0.97 0.87 0.80 0.77 0.73 0.51 0.85 0.57 0.84 0.85 0.64 0.72 0.86 0.79 0.73 0.77 0.59 0.83 0.63]  time: 2.4309  data: 1.9179  max mem: 7771\nEpoch: [244]  [267/268]  eta: 0:00:02.371639  lr: 0.000798  total_losses: 0.8696 (0.8059) hist: [0.85 0.57 0.84 0.85 0.64 0.72 0.86 0.79 0.73 0.77 0.59 0.83 0.63 1.11 0.79 0.74 1.08 0.75 0.74 0.87]  time: 2.3904  data: 1.8919  max mem: 7771\nEpoch: [244] Total time: 0:10:35 (2.3721 s / it)\nTest:   [ 0/67]  eta: 0:07:22.466936  model_time: 0.1842 (0.1842) hist: [0.18]  evaluator_time: 0.0614 (0.0614) hist: [0.06]  time: 6.6040  data: 6.3015  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.266341  model_time: 0.1454 (0.1855) hist: [0.20 0.17 0.17 0.17 0.17 0.20 0.20 0.17 0.18 0.21 0.20 0.20 0.21 0.19 0.19 0.21 0.21 0.20 0.16 0.15]  evaluator_time: 0.0268 (0.0823) hist: [0.05 0.11 0.04 0.37 0.11 0.10 0.11 0.05 0.06 0.05 0.07 0.09 0.05 0.10 0.11 0.05 0.08 0.10 0.03 0.03]  time: 2.2096  data: 1.8964  max mem: 7771\nTest:  Total time: 0:02:31 (2.2677 s / it)\nAveraged stats: model_time: 0.1454 (0.1855) hist: [0.20 0.17 0.17 0.17 0.17 0.20 0.20 0.17 0.18 0.21 0.20 0.20 0.21 0.19 0.19 0.21 0.21 0.20 0.16 0.15]  evaluator_time: 0.0268 (0.0823) hist: [0.05 0.11 0.04 0.37 0.11 0.10 0.11 0.05 0.06 0.05 0.07 0.09 0.05 0.10 0.11 0.05 0.08 0.10 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.89s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\nEpoch: [245]  [  0/268]  eta: 0:24:06.899458  lr: 0.000798  total_losses: 0.6567 (0.6567) hist: [0.66]  time: 5.3989  data: 4.8602  max mem: 7771\nEpoch: [245]  [ 20/268]  eta: 0:10:29.313643  lr: 0.000798  total_losses: 0.7521 (0.7657) hist: [0.70 0.50 1.21 1.10 0.66 0.78 0.60 0.65 0.88 0.66 0.49 0.85 0.74 0.52 0.73 1.08 0.54 1.16 0.83 0.75]  time: 2.3945  data: 1.8722  max mem: 7771\nEpoch: [245]  [ 40/268]  eta: 0:09:28.966830  lr: 0.000798  total_losses: 0.6666 (0.7812) hist: [0.56 0.61 0.64 0.52 0.91 0.79 1.02 1.08 0.94 0.58 0.90 0.77 0.48 0.85 1.05 1.10 1.01 0.85 0.62 0.67]  time: 2.4513  data: 1.9335  max mem: 7771\nEpoch: [245]  [ 60/268]  eta: 0:08:22.114861  lr: 0.000798  total_losses: 0.8764 (0.7850) hist: [0.78 0.77 0.87 0.89 0.73 0.83 0.70 1.17 1.04 0.94 0.61 0.96 0.69 0.58 0.55 0.74 0.77 0.61 0.76 0.88]  time: 2.2470  data: 1.7311  max mem: 7771\nEpoch: [245]  [ 80/268]  eta: 0:07:30.838689  lr: 0.000798  total_losses: 0.6056 (0.7883) hist: [0.96 0.82 0.64 0.94 0.96 0.80 0.76 0.45 0.87 0.83 1.06 0.65 0.75 0.65 0.74 0.61 0.87 1.06 0.94 0.61]  time: 2.3495  data: 1.8371  max mem: 7771\nEpoch: [245]  [100/268]  eta: 0:06:40.476245  lr: 0.000798  total_losses: 0.9476 (0.7864) hist: [0.77 0.73 0.81 0.79 0.71 0.70 0.49 1.02 0.99 0.57 0.92 0.73 0.96 0.73 0.54 0.95 0.76 1.03 0.46 0.95]  time: 2.3259  data: 1.8099  max mem: 7771\nEpoch: [245]  [120/268]  eta: 0:05:49.475148  lr: 0.000798  total_losses: 0.7733 (0.7865) hist: [0.62 0.81 0.92 0.52 1.13 0.87 0.71 0.72 0.98 0.79 0.54 0.56 0.97 0.97 0.58 0.87 0.77 0.83 0.81 0.77]  time: 2.2479  data: 1.7289  max mem: 7771\nEpoch: [245]  [140/268]  eta: 0:04:59.527060  lr: 0.000798  total_losses: 0.8089 (0.7949) hist: [0.80 0.93 0.64 0.74 0.79 1.01 0.69 0.74 1.00 1.02 0.94 0.53 1.12 0.83 0.85 1.10 0.70 0.67 0.99 0.81]  time: 2.2114  data: 1.6918  max mem: 7771\nEpoch: [245]  [160/268]  eta: 0:04:13.613449  lr: 0.000798  total_losses: 0.6718 (0.7934) hist: [0.78 0.59 0.55 0.64 0.60 1.05 0.65 0.69 1.19 0.68 0.73 0.95 0.57 1.16 0.79 0.79 1.11 0.89 0.58 0.67]  time: 2.4062  data: 1.8862  max mem: 7771\nEpoch: [245]  [180/268]  eta: 0:03:27.270563  lr: 0.000798  total_losses: 0.7696 (0.7921) hist: [0.95 0.78 1.08 0.73 0.58 0.94 0.78 1.07 0.57 0.71 0.66 0.79 0.64 0.48 0.57 0.76 0.95 0.74 1.09 0.77]  time: 2.4123  data: 1.8979  max mem: 7771\nEpoch: [245]  [200/268]  eta: 0:02:40.291667  lr: 0.000798  total_losses: 0.5964 (0.7989) hist: [0.97 0.76 0.70 0.65 0.53 1.07 0.74 1.30 0.74 0.86 1.05 0.54 0.78 1.20 0.96 1.00 0.89 0.83 1.03 0.60]  time: 2.3743  data: 1.8521  max mem: 7771\nEpoch: [245]  [220/268]  eta: 0:01:53.266630  lr: 0.000798  total_losses: 0.7606 (0.8032) hist: [0.96 0.88 0.97 0.57 0.94 0.91 0.78 0.71 0.87 0.63 0.84 0.73 1.00 1.20 0.89 0.69 0.57 1.10 0.90 0.76]  time: 2.3848  data: 1.8592  max mem: 7771\nEpoch: [245]  [240/268]  eta: 0:01:06.346299  lr: 0.000798  total_losses: 0.6076 (0.8029) hist: [1.15 0.62 0.54 0.83 0.93 0.79 0.93 1.30 0.67 0.67 0.66 0.65 0.68 0.75 1.10 1.12 0.78 0.77 0.46 0.61]  time: 2.4777  data: 1.9679  max mem: 7771\nEpoch: [245]  [260/268]  eta: 0:00:19.021674  lr: 0.000798  total_losses: 0.8016 (0.8057) hist: [1.41 0.97 1.07 1.19 0.62 0.71 0.65 0.98 0.73 0.82 0.96 0.84 1.20 0.65 0.59 0.66 0.64 0.76 0.56 0.80]  time: 2.4765  data: 1.9502  max mem: 7771\nEpoch: [245]  [267/268]  eta: 0:00:02.364127  lr: 0.000798  total_losses: 0.5824 (0.8026) hist: [0.98 0.73 0.82 0.96 0.84 1.20 0.65 0.59 0.66 0.64 0.76 0.56 0.80 0.70 0.71 0.52 0.63 0.91 0.75 0.58]  time: 2.2058  data: 1.7010  max mem: 7771\nEpoch: [245] Total time: 0:10:33 (2.3647 s / it)\nTest:   [ 0/67]  eta: 0:06:55.594711  model_time: 0.1687 (0.1687) hist: [0.17]  evaluator_time: 0.0521 (0.0521) hist: [0.05]  time: 6.2029  data: 5.9449  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.244378  model_time: 0.1590 (0.1805) hist: [0.17 0.20 0.17 0.20 0.17 0.20 0.20 0.17 0.18 0.20 0.17 0.17 0.17 0.18 0.17 0.18 0.17 0.20 0.16 0.16]  evaluator_time: 0.0469 (0.0845) hist: [0.09 0.06 0.04 0.07 0.06 0.04 0.05 0.10 0.11 0.11 0.05 0.05 0.11 0.05 0.05 0.09 0.49 0.05 0.03 0.05]  time: 2.1052  data: 1.8030  max mem: 7771\nTest:  Total time: 0:02:30 (2.2462 s / it)\nAveraged stats: model_time: 0.1590 (0.1805) hist: [0.17 0.20 0.17 0.20 0.17 0.20 0.20 0.17 0.18 0.20 0.17 0.17 0.17 0.18 0.17 0.18 0.17 0.20 0.16 0.16]  evaluator_time: 0.0469 (0.0845) hist: [0.09 0.06 0.04 0.07 0.06 0.04 0.05 0.10 0.11 0.11 0.05 0.05 0.11 0.05 0.05 0.09 0.49 0.05 0.03 0.05]\nAccumulating evaluation results...\nDONE (t=0.98s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.566\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.501\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\nEpoch: [246]  [  0/268]  eta: 0:21:50.259076  lr: 0.000798  total_losses: 0.6970 (0.6970) hist: [0.70]  time: 4.8890  data: 4.3629  max mem: 7771\nEpoch: [246]  [ 20/268]  eta: 0:11:17.056881  lr: 0.000798  total_losses: 0.9169 (0.8418) hist: [1.23 0.60 0.59 1.22 0.78 1.01 0.57 0.49 0.82 1.15 0.93 0.70 0.71 0.80 0.93 0.73 0.86 0.70 1.24 0.92]  time: 2.6221  data: 2.0910  max mem: 7771\nEpoch: [246]  [ 40/268]  eta: 0:09:07.135091  lr: 0.000798  total_losses: 0.5453 (0.8199) hist: [0.93 0.67 0.65 1.07 0.72 1.07 0.69 1.15 0.75 0.57 1.08 0.80 0.73 0.68 0.80 0.67 0.98 0.76 0.65 0.55]  time: 2.0528  data: 1.5355  max mem: 7771\nEpoch: [246]  [ 60/268]  eta: 0:08:38.376214  lr: 0.000798  total_losses: 0.9729 (0.8170) hist: [0.93 0.70 0.65 0.68 0.83 0.73 1.27 0.50 0.72 0.90 1.00 0.97 0.84 0.76 0.90 0.71 0.67 0.57 0.92 0.97]  time: 2.6818  data: 2.1745  max mem: 7771\nEpoch: [246]  [ 80/268]  eta: 0:07:54.041257  lr: 0.000798  total_losses: 0.7978 (0.8130) hist: [0.75 1.04 0.74 0.95 0.96 0.50 0.79 0.88 0.81 0.85 0.98 0.73 0.87 0.63 0.57 1.28 0.77 0.69 0.41 0.80]  time: 2.6109  data: 2.0955  max mem: 7771\nEpoch: [246]  [100/268]  eta: 0:06:56.724078  lr: 0.000798  total_losses: 0.6221 (0.8115) hist: [0.98 1.06 0.75 0.80 0.64 0.71 1.00 0.80 0.77 0.97 0.75 0.94 0.75 0.70 0.81 0.71 0.79 0.76 0.78 0.62]  time: 2.3145  data: 1.7984  max mem: 7771\nEpoch: [246]  [120/268]  eta: 0:06:03.782067  lr: 0.000798  total_losses: 0.8163 (0.8219) hist: [0.86 0.88 0.78 0.92 0.81 1.22 0.70 0.69 0.74 0.96 1.09 0.87 0.81 0.47 1.01 0.99 0.80 1.15 0.94 0.82]  time: 2.3443  data: 1.8278  max mem: 7771\nEpoch: [246]  [140/268]  eta: 0:05:12.973207  lr: 0.000798  total_losses: 0.5828 (0.8168) hist: [0.58 0.65 0.64 0.68 0.84 0.83 0.69 0.59 0.74 1.05 0.79 0.96 1.29 0.83 0.82 0.75 0.89 0.68 0.88 0.58]  time: 2.3672  data: 1.8504  max mem: 7771\nEpoch: [246]  [160/268]  eta: 0:04:21.691510  lr: 0.000798  total_losses: 0.7079 (0.8325) hist: [1.04 0.79 0.79 0.85 1.37 0.87 0.75 0.91 1.01 1.01 0.81 0.89 0.79 1.20 1.03 0.68 1.22 0.93 1.21 0.71]  time: 2.2677  data: 1.7532  max mem: 7771\nEpoch: [246]  [180/268]  eta: 0:03:32.328750  lr: 0.000798  total_losses: 0.5456 (0.8314) hist: [0.95 0.64 0.80 0.63 0.84 1.16 1.04 0.62 0.51 0.75 0.70 0.76 0.83 1.00 0.55 1.10 0.92 0.98 1.15 0.55]  time: 2.3304  data: 1.8069  max mem: 7771\nEpoch: [246]  [200/268]  eta: 0:02:44.260143  lr: 0.000798  total_losses: 0.7510 (0.8333) hist: [0.87 1.00 0.74 0.81 0.80 0.91 0.72 0.72 1.01 1.07 1.02 0.86 0.67 0.61 0.77 1.00 0.80 0.80 1.06 0.75]  time: 2.4406  data: 1.9219  max mem: 7771\nEpoch: [246]  [220/268]  eta: 0:01:56.030658  lr: 0.000798  total_losses: 0.8694 (0.8297) hist: [0.59 0.95 0.63 1.00 1.03 0.78 0.67 0.63 1.07 0.67 0.68 0.81 0.83 0.71 0.61 0.94 0.74 1.12 0.55 0.87]  time: 2.4345  data: 1.9158  max mem: 7771\nEpoch: [246]  [240/268]  eta: 0:01:07.329486  lr: 0.000798  total_losses: 0.8286 (0.8345) hist: [1.17 0.90 0.91 0.67 1.05 0.84 0.73 1.02 1.14 0.58 1.14 0.97 0.88 0.93 0.82 0.88 0.62 1.01 0.66 0.83]  time: 2.2645  data: 1.7517  max mem: 7771\nEpoch: [246]  [260/268]  eta: 0:00:19.139548  lr: 0.000798  total_losses: 0.5765 (0.8342) hist: [0.78 0.81 1.17 0.73 0.58 0.81 1.01 0.80 0.52 0.62 1.14 0.55 0.60 0.76 1.02 1.03 1.16 0.89 1.05 0.58]  time: 2.2457  data: 1.7308  max mem: 7771\nEpoch: [246]  [267/268]  eta: 0:00:02.373971  lr: 0.000798  total_losses: 0.6366 (0.8355) hist: [0.80 0.52 0.62 1.14 0.55 0.60 0.76 1.02 1.03 1.16 0.89 1.05 0.58 0.63 1.60 0.80 0.72 1.01 0.79 0.64]  time: 2.2322  data: 1.7329  max mem: 7771\nEpoch: [246] Total time: 0:10:36 (2.3748 s / it)\nTest:   [ 0/67]  eta: 0:06:06.551087  model_time: 0.1767 (0.1767) hist: [0.18]  evaluator_time: 0.0541 (0.0541) hist: [0.05]  time: 5.4709  data: 5.1764  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.239975  model_time: 0.1447 (0.1848) hist: [0.20 0.17 0.18 0.19 0.20 0.17 0.17 0.17 0.17 0.19 0.17 0.19 0.20 0.17 0.21 0.20 0.20 0.17 0.16 0.14]  evaluator_time: 0.0298 (0.0794) hist: [0.09 0.11 0.05 0.08 0.38 0.07 0.10 0.05 0.04 0.05 0.05 0.04 0.09 0.05 0.12 0.10 0.05 0.05 0.03 0.03]  time: 2.2015  data: 1.9021  max mem: 7771\nTest:  Total time: 0:02:30 (2.2415 s / it)\nAveraged stats: model_time: 0.1447 (0.1848) hist: [0.20 0.17 0.18 0.19 0.20 0.17 0.17 0.17 0.17 0.19 0.17 0.19 0.20 0.17 0.21 0.20 0.20 0.17 0.16 0.14]  evaluator_time: 0.0298 (0.0794) hist: [0.09 0.11 0.05 0.08 0.38 0.07 0.10 0.05 0.04 0.05 0.05 0.04 0.09 0.05 0.12 0.10 0.05 0.05 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.90s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.564\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.494\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.606\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\nEpoch: [247]  [  0/268]  eta: 0:29:54.116727  lr: 0.000798  total_losses: 0.7116 (0.7116) hist: [0.71]  time: 6.6945  data: 6.1837  max mem: 7771\nEpoch: [247]  [ 20/268]  eta: 0:10:26.510904  lr: 0.000798  total_losses: 0.7642 (0.8650) hist: [1.12 0.66 1.04 1.78 0.76 0.67 0.92 0.47 1.16 0.72 0.53 1.12 0.90 0.83 1.01 0.67 0.90 0.80 0.63 0.76]  time: 2.3178  data: 1.7938  max mem: 7771\nEpoch: [247]  [ 40/268]  eta: 0:09:18.639331  lr: 0.000798  total_losses: 0.8025 (0.8175) hist: [0.83 0.91 0.63 0.95 0.65 0.57 0.62 0.79 0.74 0.79 0.84 0.67 0.67 0.85 0.83 0.60 0.69 0.93 0.99 0.80]  time: 2.3703  data: 1.8571  max mem: 7771\nEpoch: [247]  [ 60/268]  eta: 0:08:31.296028  lr: 0.000798  total_losses: 0.9704 (0.8173) hist: [0.81 0.72 0.73 0.56 0.84 0.54 1.08 0.64 0.78 0.50 0.90 0.89 1.18 1.07 0.64 0.76 1.22 0.83 0.66 0.97]  time: 2.4745  data: 1.9608  max mem: 7771\nEpoch: [247]  [ 80/268]  eta: 0:07:42.165472  lr: 0.000798  total_losses: 0.6211 (0.8061) hist: [1.09 0.79 0.60 0.99 0.78 0.71 0.56 0.84 0.68 0.64 0.72 0.79 0.69 1.02 0.68 0.78 0.96 1.02 0.46 0.62]  time: 2.4589  data: 1.9449  max mem: 7771\nEpoch: [247]  [100/268]  eta: 0:06:43.633462  lr: 0.000798  total_losses: 0.6368 (0.7911) hist: [0.76 0.70 0.81 0.76 0.71 0.55 0.94 0.61 0.83 0.77 0.82 0.82 0.48 0.76 0.79 1.05 0.67 0.58 0.57 0.64]  time: 2.1768  data: 1.6590  max mem: 7771\nEpoch: [247]  [120/268]  eta: 0:05:54.149028  lr: 0.000798  total_losses: 0.8761 (0.7911) hist: [0.72 0.82 0.84 0.63 0.67 0.74 1.12 0.85 1.14 0.64 0.76 0.63 0.54 0.63 1.05 0.93 0.92 0.46 0.86 0.88]  time: 2.3440  data: 1.8253  max mem: 7771\nEpoch: [247]  [140/268]  eta: 0:05:09.437613  lr: 0.000798  total_losses: 1.2444 (0.7884) hist: [0.46 0.64 0.82 0.69 0.94 0.58 0.46 0.65 0.82 1.04 0.53 1.05 0.60 1.08 0.64 0.83 0.89 0.79 0.69 1.24]  time: 2.5662  data: 2.0487  max mem: 7771\nEpoch: [247]  [160/268]  eta: 0:04:18.792618  lr: 0.000798  total_losses: 0.8347 (0.7999) hist: [0.82 0.59 0.60 0.89 0.77 1.19 1.08 1.09 0.74 0.69 1.09 0.80 1.05 0.86 1.00 0.75 0.83 0.93 1.02 0.83]  time: 2.2464  data: 1.7284  max mem: 7771\nEpoch: [247]  [180/268]  eta: 0:03:31.679514  lr: 0.000798  total_losses: 0.7778 (0.8026) hist: [0.75 1.03 0.47 0.76 0.78 0.89 0.70 1.05 0.83 0.98 0.60 0.83 0.87 0.85 0.94 0.85 1.14 0.74 0.66 0.78]  time: 2.4797  data: 1.9629  max mem: 7771\nEpoch: [247]  [200/268]  eta: 0:02:43.444598  lr: 0.000798  total_losses: 1.1626 (0.8064) hist: [0.77 0.76 0.83 0.81 0.92 0.66 1.20 0.80 1.06 0.84 0.73 0.82 0.93 0.57 0.73 0.77 0.72 0.88 0.83 1.16]  time: 2.3868  data: 1.8650  max mem: 7771\nEpoch: [247]  [220/268]  eta: 0:01:55.795864  lr: 0.000798  total_losses: 0.6866 (0.8081) hist: [0.79 0.72 0.96 0.82 0.85 0.82 1.00 1.20 0.51 0.80 0.75 1.01 0.76 0.87 0.80 0.68 1.05 0.70 0.73 0.69]  time: 2.5010  data: 1.9763  max mem: 7771\nEpoch: [247]  [240/268]  eta: 0:01:07.534227  lr: 0.000798  total_losses: 0.8070 (0.8111) hist: [1.18 0.91 0.92 0.91 0.89 0.64 0.96 1.16 0.81 0.62 0.97 0.77 0.70 0.84 0.64 0.84 1.08 0.66 0.59 0.81]  time: 2.4067  data: 1.8924  max mem: 7771\nEpoch: [247]  [260/268]  eta: 0:00:19.218760  lr: 0.000798  total_losses: 0.6093 (0.8061) hist: [0.53 0.61 0.62 0.55 0.56 1.05 0.63 0.99 0.49 0.88 0.83 0.49 0.61 0.61 0.99 0.80 1.17 0.97 0.94 0.61]  time: 2.2868  data: 1.7717  max mem: 7771\nEpoch: [247]  [267/268]  eta: 0:00:02.388287  lr: 0.000798  total_losses: 1.4738 (0.8056) hist: [0.99 0.49 0.88 0.83 0.49 0.61 0.61 0.99 0.80 1.17 0.97 0.94 0.61 0.57 0.48 0.67 0.57 0.80 0.94 1.47]  time: 2.0667  data: 1.5695  max mem: 7771\nEpoch: [247] Total time: 0:10:40 (2.3889 s / it)\nTest:   [ 0/67]  eta: 0:06:08.549232  model_time: 0.2056 (0.2056) hist: [0.21]  evaluator_time: 0.0501 (0.0501) hist: [0.05]  time: 5.5007  data: 5.2081  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.243282  model_time: 0.1455 (0.1843) hist: [0.19 0.20 0.17 0.17 0.17 0.17 0.18 0.17 0.17 0.17 0.17 0.20 0.17 0.19 0.21 0.20 0.19 0.17 0.16 0.15]  evaluator_time: 0.0255 (0.0910) hist: [0.08 0.06 0.05 0.08 0.08 0.06 0.11 0.05 0.04 0.10 0.04 0.08 0.09 0.11 0.11 0.10 0.06 0.05 0.21 0.03]  time: 2.1727  data: 1.8799  max mem: 7771\nTest:  Total time: 0:02:30 (2.2448 s / it)\nAveraged stats: model_time: 0.1455 (0.1843) hist: [0.19 0.20 0.17 0.17 0.17 0.17 0.18 0.17 0.17 0.17 0.17 0.20 0.17 0.19 0.21 0.20 0.19 0.17 0.16 0.15]  evaluator_time: 0.0255 (0.0910) hist: [0.08 0.06 0.05 0.08 0.08 0.06 0.11 0.05 0.04 0.10 0.04 0.08 0.09 0.11 0.11 0.10 0.06 0.05 0.21 0.03]\nAccumulating evaluation results...\nDONE (t=0.90s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\nEpoch: [248]  [  0/268]  eta: 0:21:26.776847  lr: 0.000798  total_losses: 0.5326 (0.5326) hist: [0.53]  time: 4.8014  data: 4.2965  max mem: 7771\nEpoch: [248]  [ 20/268]  eta: 0:09:30.516233  lr: 0.000798  total_losses: 0.5913 (0.8605) hist: [0.70 0.48 0.57 0.66 1.09 0.97 0.73 0.70 1.04 0.81 0.81 1.29 0.86 0.89 0.61 1.55 1.07 0.75 1.39 0.59]  time: 2.1754  data: 1.6585  max mem: 7771\nEpoch: [248]  [ 40/268]  eta: 0:08:54.326938  lr: 0.000798  total_losses: 1.1095 (0.8334) hist: [0.52 0.80 1.00 0.85 0.59 0.91 0.66 0.84 0.87 0.68 0.67 0.73 0.89 0.91 0.58 0.81 0.96 0.63 1.07 1.11]  time: 2.3888  data: 1.8642  max mem: 7771\nEpoch: [248]  [ 60/268]  eta: 0:08:03.851346  lr: 0.000798  total_losses: 0.7590 (0.8194) hist: [0.96 0.76 0.62 0.76 0.79 0.65 1.32 0.78 0.90 0.71 0.54 0.90 0.74 0.64 0.88 0.48 0.68 0.85 1.09 0.76]  time: 2.2907  data: 1.7753  max mem: 7771\nEpoch: [248]  [ 80/268]  eta: 0:07:16.610669  lr: 0.000798  total_losses: 0.7759 (0.8271) hist: [0.79 0.64 1.14 1.02 0.72 0.70 0.93 0.91 0.86 1.16 0.61 1.27 0.95 0.88 0.74 0.62 0.61 0.87 0.82 0.78]  time: 2.3108  data: 1.7940  max mem: 7771\nEpoch: [248]  [100/268]  eta: 0:06:38.461670  lr: 0.000798  total_losses: 0.7096 (0.8143) hist: [0.54 0.55 0.50 0.61 1.21 1.41 0.42 0.97 1.05 0.67 0.86 0.67 0.60 0.63 0.75 0.72 0.69 1.02 0.66 0.71]  time: 2.5719  data: 2.0534  max mem: 7771\nEpoch: [248]  [120/268]  eta: 0:05:51.566675  lr: 0.000798  total_losses: 0.7875 (0.8250) hist: [0.66 0.94 0.81 1.00 1.06 0.59 0.55 0.76 0.87 0.79 0.86 0.75 1.07 1.27 1.04 0.95 1.02 0.98 0.82 0.79]  time: 2.3939  data: 1.8824  max mem: 7771\nEpoch: [248]  [140/268]  eta: 0:05:05.058114  lr: 0.000798  total_losses: 0.9055 (0.8266) hist: [1.21 0.77 0.77 0.84 1.07 0.78 0.68 0.77 0.89 0.79 0.77 0.73 0.52 0.98 0.91 0.78 0.74 1.12 0.69 0.91]  time: 2.4306  data: 1.9153  max mem: 7771\nEpoch: [248]  [160/268]  eta: 0:04:15.715266  lr: 0.000798  total_losses: 0.7389 (0.8287) hist: [0.96 0.72 0.65 0.98 1.24 0.71 0.85 1.16 0.87 0.57 0.69 1.07 0.98 0.83 0.90 0.83 0.66 0.66 0.81 0.74]  time: 2.2582  data: 1.7435  max mem: 7771\nEpoch: [248]  [180/268]  eta: 0:03:28.416085  lr: 0.000798  total_losses: 0.9481 (0.8247) hist: [0.73 0.94 0.66 0.88 0.68 0.85 0.92 0.69 0.90 0.42 0.98 0.98 0.66 0.57 0.96 0.75 0.56 0.85 0.92 0.95]  time: 2.3734  data: 1.8551  max mem: 7771\nEpoch: [248]  [200/268]  eta: 0:02:41.842090  lr: 0.000798  total_losses: 0.6708 (0.8202) hist: [0.88 0.46 0.98 0.58 1.09 0.74 0.70 0.70 0.69 0.65 0.91 0.88 0.59 1.31 0.81 0.64 0.71 0.86 0.75 0.67]  time: 2.4856  data: 1.9740  max mem: 7771\nEpoch: [248]  [220/268]  eta: 0:01:53.662822  lr: 0.000798  total_losses: 0.7083 (0.8191) hist: [0.57 0.59 0.76 0.74 0.75 0.78 1.03 0.58 0.88 0.59 0.60 1.17 0.74 0.79 1.13 1.09 0.92 0.99 0.74 0.71]  time: 2.2468  data: 1.7248  max mem: 7771\nEpoch: [248]  [240/268]  eta: 0:01:06.620651  lr: 0.000798  total_losses: 1.2721 (0.8237) hist: [0.57 1.13 0.56 1.01 0.73 1.03 0.90 0.83 0.98 1.07 0.78 0.83 0.71 0.83 0.64 0.64 1.08 0.86 1.02 1.27]  time: 2.5045  data: 1.9887  max mem: 7771\nEpoch: [248]  [260/268]  eta: 0:00:18.962861  lr: 0.000798  total_losses: 0.6642 (0.8227) hist: [0.88 1.06 0.56 0.81 0.79 1.01 0.75 0.67 0.93 0.79 0.52 0.85 1.05 0.58 0.60 1.02 1.09 0.82 0.78 0.66]  time: 2.2625  data: 1.7440  max mem: 7771\nEpoch: [248]  [267/268]  eta: 0:00:02.371889  lr: 0.000798  total_losses: 1.2557 (0.8242) hist: [0.67 0.93 0.79 0.52 0.85 1.05 0.58 0.60 1.02 1.09 0.82 0.78 0.66 0.90 0.80 0.69 0.79 0.65 1.06 1.26]  time: 2.4025  data: 1.8980  max mem: 7771\nEpoch: [248] Total time: 0:10:35 (2.3724 s / it)\nTest:   [ 0/67]  eta: 0:06:38.047670  model_time: 0.1721 (0.1721) hist: [0.17]  evaluator_time: 0.0685 (0.0685) hist: [0.07]  time: 5.9410  data: 5.6436  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.248025  model_time: 0.1456 (0.1831) hist: [0.18 0.20 0.17 0.22 0.20 0.19 0.17 0.17 0.21 0.18 0.17 0.17 0.17 0.17 0.18 0.20 0.20 0.17 0.16 0.15]  evaluator_time: 0.0252 (0.0914) hist: [0.41 0.10 0.04 0.11 0.09 0.11 0.08 0.05 0.05 0.05 0.05 0.05 0.10 0.05 0.11 0.14 0.41 0.07 0.03 0.03]  time: 2.2059  data: 1.8751  max mem: 7771\nTest:  Total time: 0:02:30 (2.2495 s / it)\nAveraged stats: model_time: 0.1456 (0.1831) hist: [0.18 0.20 0.17 0.22 0.20 0.19 0.17 0.17 0.21 0.18 0.17 0.17 0.17 0.17 0.18 0.20 0.20 0.17 0.16 0.15]  evaluator_time: 0.0252 (0.0914) hist: [0.41 0.10 0.04 0.11 0.09 0.11 0.08 0.05 0.05 0.05 0.05 0.05 0.10 0.05 0.11 0.14 0.41 0.07 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.88s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.571\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\nEpoch: [249]  [  0/268]  eta: 0:24:28.313623  lr: 0.000798  total_losses: 0.5954 (0.5954) hist: [0.60]  time: 5.4788  data: 4.9001  max mem: 7771\nEpoch: [249]  [ 20/268]  eta: 0:11:01.891215  lr: 0.000798  total_losses: 1.0446 (0.8491) hist: [0.64 0.56 0.74 1.01 1.01 1.44 0.57 0.92 0.64 1.14 1.05 0.48 0.69 0.93 1.08 0.61 0.55 0.91 1.22 1.04]  time: 2.5284  data: 2.0105  max mem: 7771\nEpoch: [249]  [ 40/268]  eta: 0:09:31.054159  lr: 0.000798  total_losses: 1.1344 (0.8319) hist: [0.70 0.95 1.13 0.87 0.92 0.78 0.50 0.98 1.06 0.80 1.16 0.73 0.76 0.51 0.46 1.04 0.49 0.54 0.77 1.13]  time: 2.3321  data: 1.8100  max mem: 7771\nEpoch: [249]  [ 60/268]  eta: 0:08:24.770263  lr: 0.000798  total_losses: 1.2681 (0.8441) hist: [0.97 0.93 1.22 0.88 0.59 0.93 0.58 0.82 0.92 0.75 0.80 0.71 0.84 1.16 0.84 0.78 0.82 0.84 0.72 1.27]  time: 2.2672  data: 1.7416  max mem: 7771\nEpoch: [249]  [ 80/268]  eta: 0:07:41.678709  lr: 0.000798  total_losses: 0.6760 (0.8421) hist: [0.86 0.79 0.89 0.72 0.70 0.73 1.00 1.20 0.95 1.21 0.87 0.86 0.89 0.70 0.65 0.93 0.61 0.72 0.76 0.68]  time: 2.5441  data: 2.0322  max mem: 7771\nEpoch: [249]  [100/268]  eta: 0:06:53.320517  lr: 0.000798  total_losses: 0.6569 (0.8180) hist: [0.65 0.77 0.63 0.60 0.64 0.46 0.71 1.00 0.88 0.65 0.51 0.80 0.79 0.86 0.76 0.81 0.65 0.70 0.89 0.66]  time: 2.4785  data: 1.9601  max mem: 7771\nEpoch: [249]  [120/268]  eta: 0:06:01.303558  lr: 0.000798  total_losses: 0.9154 (0.8133) hist: [1.00 0.40 0.80 0.98 0.90 0.75 0.82 0.85 0.85 0.72 1.09 0.74 0.56 0.85 0.67 0.82 0.74 0.60 0.74 0.92]  time: 2.3453  data: 1.8307  max mem: 7771\nEpoch: [249]  [140/268]  eta: 0:05:09.846985  lr: 0.000798  total_losses: 0.8660 (0.8163) hist: [0.89 0.61 0.95 0.75 0.97 1.08 0.85 0.81 1.07 0.54 0.62 1.21 0.96 0.81 0.81 0.65 0.65 0.74 0.85 0.87]  time: 2.2963  data: 1.7780  max mem: 7771\nEpoch: [249]  [160/268]  eta: 0:04:19.786719  lr: 0.000798  total_losses: 0.7448 (0.8107) hist: [0.49 0.67 0.49 0.72 0.88 1.08 0.73 0.64 1.00 0.80 0.57 0.52 1.04 0.63 0.89 1.03 0.78 0.72 0.99 0.74]  time: 2.2979  data: 1.7842  max mem: 7771\nEpoch: [249]  [180/268]  eta: 0:03:30.381283  lr: 0.000798  total_losses: 0.7320 (0.8061) hist: [0.56 0.74 0.67 0.71 0.75 0.60 0.76 0.75 0.79 0.78 0.70 0.57 1.03 0.90 0.81 0.71 0.75 1.10 0.96 0.73]  time: 2.2721  data: 1.7536  max mem: 7771\nEpoch: [249]  [200/268]  eta: 0:02:42.442067  lr: 0.000798  total_losses: 0.6689 (0.8097) hist: [0.72 0.54 0.91 0.76 1.07 0.69 0.94 0.75 0.76 0.65 0.99 1.16 0.95 0.72 1.13 0.95 0.59 0.84 1.08 0.67]  time: 2.3722  data: 1.8537  max mem: 7771\nEpoch: [249]  [220/268]  eta: 0:01:54.959058  lr: 0.000798  total_losses: 0.8439 (0.8113) hist: [0.95 0.80 0.72 0.88 0.72 0.74 0.61 1.30 1.10 0.79 0.61 0.69 0.98 0.96 0.71 1.01 0.69 0.75 0.69 0.84]  time: 2.4566  data: 1.9350  max mem: 7771\nEpoch: [249]  [240/268]  eta: 0:01:07.265029  lr: 0.000798  total_losses: 0.7131 (0.8193) hist: [0.88 1.03 0.72 0.76 1.00 0.87 0.73 0.96 0.96 0.66 1.06 0.63 1.51 0.83 1.25 0.70 0.94 0.99 0.95 0.71]  time: 2.4835  data: 1.9629  max mem: 7771\nEpoch: [249]  [260/268]  eta: 0:00:19.158686  lr: 0.000798  total_losses: 0.9059 (0.8224) hist: [0.78 0.99 0.89 0.83 0.81 0.76 1.06 0.56 0.78 1.03 0.71 0.61 0.71 1.67 0.64 0.71 0.92 1.00 0.84 0.91]  time: 2.3046  data: 1.7946  max mem: 7771\nEpoch: [249]  [267/268]  eta: 0:00:02.375915  lr: 0.000798  total_losses: 1.0212 (0.8214) hist: [0.56 0.78 1.03 0.71 0.61 0.71 1.67 0.64 0.71 0.92 1.00 0.84 0.91 0.64 0.62 0.52 0.80 0.96 0.94 1.02]  time: 2.1965  data: 1.7042  max mem: 7771\nEpoch: [249] Total time: 0:10:36 (2.3764 s / it)\nTest:   [ 0/67]  eta: 0:06:43.996660  model_time: 0.1709 (0.1709) hist: [0.17]  evaluator_time: 0.0541 (0.0541) hist: [0.05]  time: 6.0298  data: 5.7643  max mem: 7771\nTest:   [66/67]  eta: 0:00:02.269745  model_time: 0.1450 (0.1792) hist: [0.17 0.18 0.17 0.17 0.17 0.20 0.19 0.20 0.17 0.17 0.17 0.17 0.18 0.20 0.17 0.17 0.20 0.17 0.16 0.15]  evaluator_time: 0.0261 (0.0831) hist: [0.05 0.30 0.05 0.06 0.12 0.05 0.06 0.09 0.04 0.07 0.05 0.04 0.09 0.12 0.07 0.07 0.11 0.27 0.03 0.03]  time: 2.1522  data: 1.8530  max mem: 7771\nTest:  Total time: 0:02:32 (2.2712 s / it)\nAveraged stats: model_time: 0.1450 (0.1792) hist: [0.17 0.18 0.17 0.17 0.17 0.20 0.19 0.20 0.17 0.17 0.17 0.17 0.18 0.20 0.17 0.17 0.20 0.17 0.16 0.15]  evaluator_time: 0.0261 (0.0831) hist: [0.05 0.30 0.05 0.06 0.12 0.05 0.06 0.09 0.04 0.07 0.05 0.04 0.09 0.12 0.07 0.07 0.11 0.27 0.03 0.03]\nAccumulating evaluation results...\nDONE (t=0.86s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.559\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\nsuccessful save loss curve! \nsuccessful save mAP curve!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}